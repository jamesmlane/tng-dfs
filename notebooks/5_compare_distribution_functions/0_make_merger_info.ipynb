{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "#\n",
    "# TITLE - 0_make_merger_data.ipynb\n",
    "# AUTHOR - James Lane\n",
    "# PROJECT - tng-dfs\n",
    "#\n",
    "# ------------------------------------------------------------------------\n",
    "#\n",
    "# Docstrings and metadata:\n",
    "'''Make some convenient data files for the merger & DF analysis\n",
    "'''\n",
    "\n",
    "__author__ = \"James Lane\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../src/nb_modules/nb_imports.txt\n",
    "### Imports\n",
    "\n",
    "## Basic\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import h5py, dill as pickle\n",
    "import pdb, copy, glob, time, subprocess, warnings, multiprocessing\n",
    "\n",
    "## Matplotlib\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "## Astropy\n",
    "from astropy import units as apu\n",
    "\n",
    "## Analysis\n",
    "import scipy.stats\n",
    "import scipy.interpolate\n",
    "import emcee\n",
    "import corner\n",
    "\n",
    "## Project-specific\n",
    "src_path = 'src/'\n",
    "while True:\n",
    "    if os.path.exists(src_path): break\n",
    "    if os.path.realpath(src_path).split('/')[-1] in ['tng-dfs','/']:\n",
    "            raise FileNotFoundError('Failed to find src/ directory.')\n",
    "    src_path = os.path.join('..',src_path)\n",
    "sys.path.insert(0,src_path)\n",
    "from tng_dfs import cutout as pcutout\n",
    "from tng_dfs import densprofile as pdens\n",
    "from tng_dfs import fitting as pfit\n",
    "from tng_dfs import io as pio\n",
    "from tng_dfs import kinematics as pkin\n",
    "from tng_dfs import plot as pplot\n",
    "from tng_dfs import tree as ptree\n",
    "from tng_dfs import util as putil\n",
    "\n",
    "### Notebook setup\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(os.path.join(src_path,'mpl/project.mplstyle')) # This must be exactly here\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords, loading, pathing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../src/nb_modules/nb_setup.txt\n",
    "# Keywords\n",
    "cdict = putil.load_config_to_dict()\n",
    "keywords = ['DATA_DIR','MW_ANALOG_DIR','FIG_DIR_BASE','FITTING_DIR_BASE',\n",
    "            'RO','VO','ZO','LITTLE_H','MW_MASS_RANGE']\n",
    "data_dir,mw_analog_dir,fig_dir_base,fitting_dir_base,ro,vo,zo,h,\\\n",
    "    mw_mass_range = putil.parse_config_dict(cdict,keywords)\n",
    "\n",
    "# MW Analog \n",
    "mwsubs,mwsubs_vars = putil.prepare_mwsubs(mw_analog_dir,h=h,\n",
    "    mw_mass_range=mw_mass_range,return_vars=True,force_mwsubs=False,\n",
    "    bulge_disk_fraction_cuts=True)\n",
    "\n",
    "# Load tree data\n",
    "tree_primary_filename = os.path.join(mw_analog_dir,\n",
    "    'major_mergers/tree_primaries.pkl')\n",
    "with open(tree_primary_filename,'rb') as handle: \n",
    "    tree_primaries = pickle.load(handle)\n",
    "tree_major_mergers_filename = os.path.join(mw_analog_dir,\n",
    "    'major_mergers/tree_major_mergers.pkl')\n",
    "with open(tree_major_mergers_filename,'rb') as handle:\n",
    "    tree_major_mergers = pickle.load(handle)\n",
    "n_mw = len(tree_primaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versions for the analysis\n",
    "analysis_version = 'v1.1'\n",
    "\n",
    "# Versions for density profiles\n",
    "stellar_halo_density_version = 'poisson_twopower_softening'\n",
    "stellar_halo_rotation_dftype = 'tanh_rotation'\n",
    "stellar_halo_rotation_version = 'asymmetry_fit'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a large structured array with all the information about the mergers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keywords and paths\n",
    "verbose = True\n",
    "force_compute = False\n",
    "analysis_dir = os.path.join(mw_analog_dir,'analysis',analysis_version)\n",
    "os.makedirs(analysis_dir,exist_ok=True)\n",
    "merger_data_filename = os.path.join(analysis_dir,'merger_data.npy')\n",
    "dens_fitting_dir = os.path.join(fitting_dir_base,'density_profile')\n",
    "df_fitting_dir = os.path.join(fitting_dir_base,'distribution_function')\n",
    "\n",
    "# Stellar halo density information\n",
    "stellar_halo_density_ncut = 500\n",
    "stellar_halo_rotation_ncut = 500\n",
    "\n",
    "# DF information\n",
    "df_type = ['constant_beta','osipkov_merritt','osipkov_merritt_2_combination']\n",
    "fit_version = ['anisotropy_params_softening','anisotropy_params_softening',\n",
    "               'ra_N10_01_to_300_softening']\n",
    "df_ncut = 500\n",
    "\n",
    "# Densfunc\n",
    "stellar_halo_densfunc = pdens.TwoPowerSpherical()\n",
    "\n",
    "# Array to hold merger data\n",
    "merger_data = []\n",
    "\n",
    "for i in range(n_mw):\n",
    "\n",
    "    # Get the primary\n",
    "    primary = tree_primaries[i]\n",
    "    z0_sid = primary.subfind_id[0]\n",
    "    major_mergers = primary.tree_major_mergers\n",
    "    n_major = primary.n_major_mergers\n",
    "    primary_filename = primary.get_cutout_filename(mw_analog_dir,\n",
    "    snapnum=primary.snapnum[0])\n",
    "\n",
    "    # Get DM and star particle IDs and masses for the primary\n",
    "    co = pcutout.TNGCutout(primary_filename)\n",
    "    dmpid = co.get_property('dm','ParticleIDs')\n",
    "    dmass = co.get_masses('dm').to_value(apu.Msun)\n",
    "    spid = co.get_property('stars','ParticleIDs')\n",
    "    smass = co.get_masses('stars').to_value(apu.Msun)\n",
    "\n",
    "    # Loop over major mergers\n",
    "    for j in range(n_major):\n",
    "        if verbose:\n",
    "            print(f'Processing major merger {j+1}/{n_major} '\n",
    "                  f'for MW analog {i+1}/{n_mw}', end='\\r')\n",
    "        \n",
    "        # Get the merger\n",
    "        major_merger = primary.tree_major_mergers[j]\n",
    "        major_acc_sid = major_merger.subfind_id[0]\n",
    "        major_mlpid = major_merger.secondary_mlpid\n",
    "        merger_number = j+1\n",
    "\n",
    "        # Get the unique PIDs for the merger\n",
    "        dmupid = major_merger.get_unique_particle_ids('dm',data_dir=data_dir)\n",
    "        supid = major_merger.get_unique_particle_ids('stars',data_dir=data_dir)\n",
    "        dmindx = np.isin(dmpid, dmupid)\n",
    "        sindx = np.isin(spid, supid)\n",
    "        star_mass = np.sum(smass[sindx])\n",
    "        dm_mass = np.sum(dmass[dmindx])\n",
    "\n",
    "        # Information about the merger\n",
    "        star_mass_ratio = major_merger.star_mass_ratio\n",
    "        star_mass_ratio_snapnum = major_merger.star_mass_ratio_snapnum\n",
    "        dm_mass_ratio = major_merger.dm_mass_ratio\n",
    "        dm_mass_ratio_snapnum = major_merger.dm_mass_ratio_snapnum\n",
    "        merger_snapnum = major_merger.merger_snapnum\n",
    "        merger_redshift = putil.snapshot_to_redshift(merger_snapnum)\n",
    "\n",
    "        # Get the stellar halo density profile (denspot for the DF)\n",
    "        stellar_halo_density_filename = os.path.join(dens_fitting_dir,\n",
    "            'stellar_halo/',stellar_halo_density_version,str(z0_sid),\n",
    "            'merger_'+str(j+1)+'/', 'sampler.pkl')\n",
    "        denspot = pfit.construct_pot_from_fit(\n",
    "            stellar_halo_density_filename, stellar_halo_densfunc, \n",
    "            stellar_halo_density_ncut, ro=ro, vo=vo)\n",
    "        alpha = denspot.alpha\n",
    "        beta = denspot.beta\n",
    "        a = denspot.a*ro\n",
    "\n",
    "        # Get the stellar halo rotation kernel\n",
    "        stellar_halo_rotation_filename = os.path.join(df_fitting_dir,\n",
    "            stellar_halo_rotation_dftype,stellar_halo_rotation_version,\n",
    "            str(z0_sid),'merger_'+str(j+1)+'/', 'sampler.pkl')\n",
    "        krot, chi = \\\n",
    "            pio.median_params_from_emcee_sampler(stellar_halo_rotation_filename,\n",
    "                ncut=stellar_halo_rotation_ncut)\n",
    "\n",
    "        # Load the constant beta information\n",
    "        anisotropy_dir = os.path.join(df_fitting_dir, df_type[0],\n",
    "            fit_version[0],str(z0_sid),'merger_'+str(j+1))\n",
    "        anisotropy_filename = os.path.join(anisotropy_dir,'sampler.pkl')\n",
    "        assert os.path.exists(anisotropy_filename)\n",
    "        with open(anisotropy_filename,'rb') as handle:\n",
    "            beta_sampler = pickle.load(handle)\n",
    "        anisotropy_samples = beta_sampler.get_chain(discard=df_ncut,flat=True)\n",
    "        anisotropy = np.median(anisotropy_samples,axis=0)[0]\n",
    "\n",
    "        # Load the Osipkov-Merritt information\n",
    "        om_dir = os.path.join(df_fitting_dir, df_type[1],\n",
    "            fit_version[1],str(z0_sid),'merger_'+str(j+1))\n",
    "        om_filename = os.path.join(om_dir,'sampler.pkl')\n",
    "        assert os.path.exists(om_filename)\n",
    "        with open(om_filename,'rb') as handle:\n",
    "            om_sampler = pickle.load(handle)\n",
    "        ra_samples = om_sampler.get_chain(discard=df_ncut, flat=True)\n",
    "        ra = np.median(ra_samples,axis=0)[0]\n",
    "\n",
    "        # Load the combined Osipkov-Merritt information\n",
    "        om2_dir = os.path.join(df_fitting_dir, df_type[2],\n",
    "            fit_version[2],str(z0_sid),'merger_'+str(j+1))\n",
    "        om2_filename = os.path.join(om2_dir,'sampler.pkl')\n",
    "        assert os.path.exists(om2_filename)\n",
    "        with open(om2_filename,'rb') as handle:\n",
    "            om2_sampler = pickle.load(handle)\n",
    "        om2_samples = om2_sampler.get_chain(discard=df_ncut, flat=True)\n",
    "        ra1,ra2,kom = np.median(om2_samples,axis=0)\n",
    "\n",
    "        # Construct the tuple of merger data\n",
    "        merger_data.append((\n",
    "            z0_sid,\n",
    "            major_acc_sid,\n",
    "            major_mlpid,\n",
    "            merger_number,\n",
    "            star_mass_ratio,\n",
    "            star_mass_ratio_snapnum,\n",
    "            dm_mass_ratio,\n",
    "            dm_mass_ratio_snapnum,\n",
    "            merger_snapnum,\n",
    "            merger_redshift,\n",
    "            star_mass,\n",
    "            dm_mass,\n",
    "            alpha,\n",
    "            beta,\n",
    "            krot,\n",
    "            chi,\n",
    "            a,\n",
    "            anisotropy,\n",
    "            ra,\n",
    "            ra1,\n",
    "            ra2,\n",
    "            kom\n",
    "            ))\n",
    "        \n",
    "# Create the structured array dtype\n",
    "merger_dtype = np.dtype([\n",
    "    ('z0_sid', np.int64),\n",
    "    ('major_acc_sid', np.int64),\n",
    "    ('major_mlpid', np.int64),\n",
    "    ('merger_number', np.int64),\n",
    "    ('star_mass_ratio', np.float64),\n",
    "    ('star_mass_ratio_snapnum', np.int64),\n",
    "    ('dm_mass_ratio', np.float64),\n",
    "    ('dm_mass_ratio_snapnum', np.int64),\n",
    "    ('merger_snapnum', np.int64),\n",
    "    ('merger_redshift', np.float64),\n",
    "    ('star_mass', np.float64),\n",
    "    ('dm_mass', np.float64),\n",
    "    ('alpha', np.float64),\n",
    "    ('beta', np.float64),\n",
    "    ('krot', np.float64),\n",
    "    ('chi', np.float64),\n",
    "    ('a', np.float64),\n",
    "    ('anisotropy', np.float64),\n",
    "    ('ra', np.float64),\n",
    "    ('ra1', np.float64),\n",
    "    ('ra2', np.float64),\n",
    "    ('kom', np.float64)\n",
    "])\n",
    "\n",
    "merger_data = np.array(merger_data,dtype=merger_dtype)\n",
    "np.save(merger_data_filename,merger_data)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "nteract": {
   "version": "0.28.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
