{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "#\n",
    "# TITLE - 4_anisotropic_df_jeans.ipynb\n",
    "# AUTHOR - James Lane\n",
    "# PROJECT - tng-dfs\n",
    "#\n",
    "# ------------------------------------------------------------------------\n",
    "#\n",
    "# Docstrings and metadata:\n",
    "'''Compute Jeans quantities and summary statistics.\n",
    "'''\n",
    "\n",
    "__author__ = \"James Lane\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../src/nb_modules/nb_imports.txt\n",
    "### Imports\n",
    "\n",
    "## Basic\n",
    "import numpy as np\n",
    "import sys, os, dill as pickle\n",
    "import pdb\n",
    "\n",
    "## Matplotlib\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "## Astropy\n",
    "from astropy import units as apu\n",
    "\n",
    "## Analysis\n",
    "import scipy.interpolate\n",
    "\n",
    "## galpy\n",
    "from galpy import potential\n",
    "\n",
    "## Project-specific\n",
    "src_path = 'src/'\n",
    "while True:\n",
    "    if os.path.exists(src_path): break\n",
    "    if os.path.realpath(src_path).split('/')[-1] in ['tng-dfs','/']:\n",
    "            raise FileNotFoundError('Failed to find src/ directory.')\n",
    "    src_path = os.path.join('..',src_path)\n",
    "sys.path.insert(0,src_path)\n",
    "from tng_dfs import cutout as pcutout\n",
    "from tng_dfs import densprofile as pdens\n",
    "from tng_dfs import fitting as pfit\n",
    "from tng_dfs import kinematics as pkin\n",
    "from tng_dfs import util as putil\n",
    "\n",
    "### Notebook setup\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(os.path.join(src_path,'mpl/project.mplstyle')) # This must be exactly here\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords, loading, pathing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../src/nb_modules/nb_setup.txt\n",
    "# Keywords\n",
    "cdict = putil.load_config_to_dict()\n",
    "keywords = ['DATA_DIR','MW_ANALOG_DIR','FIG_DIR_BASE','FITTING_DIR_BASE',\n",
    "            'RO','VO','ZO','LITTLE_H','MW_MASS_RANGE']\n",
    "data_dir,mw_analog_dir,fig_dir_base,fitting_dir_base,ro,vo,zo,h,\\\n",
    "    mw_mass_range = putil.parse_config_dict(cdict,keywords)\n",
    "\n",
    "# MW Analog \n",
    "mwsubs,mwsubs_vars = putil.prepare_mwsubs(mw_analog_dir,h=h,\n",
    "    mw_mass_range=mw_mass_range,return_vars=True,force_mwsubs=False,\n",
    "    bulge_disk_fraction_cuts=True)\n",
    "\n",
    "# Figure path\n",
    "local_fig_dir = './fig/'\n",
    "fig_dir = os.path.join(fig_dir_base, \n",
    "    'notebooks/5_compare_distribution_functions/4_anisotropic_df_jeans/')\n",
    "os.makedirs(fig_dir,exist_ok=True)\n",
    "show_plots = False\n",
    "\n",
    "# Load tree data\n",
    "tree_primary_filename = os.path.join(mw_analog_dir,\n",
    "    'major_mergers/tree_primaries.pkl')\n",
    "with open(tree_primary_filename,'rb') as handle: \n",
    "    tree_primaries = pickle.load(handle)\n",
    "tree_major_mergers_filename = os.path.join(mw_analog_dir,\n",
    "    'major_mergers/tree_major_mergers.pkl')\n",
    "with open(tree_major_mergers_filename,'rb') as handle:\n",
    "    tree_major_mergers = pickle.load(handle)\n",
    "n_mw = len(tree_primaries)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Jeans equation summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_bootstrap = 10\n",
    "verbose = True\n",
    "\n",
    "# Pathing\n",
    "dens_fitting_dir = os.path.join(fitting_dir_base,'density_profile')\n",
    "df_fitting_dir = os.path.join(fitting_dir_base,'distribution_function')\n",
    "analysis_version = 'v1.1'\n",
    "analysis_dir = os.path.join(mw_analog_dir,'analysis',analysis_version)\n",
    "\n",
    "# Get the orbits\n",
    "sample_data_cb = np.load(os.path.join(analysis_dir,'sample_data_cb.npy'),\n",
    "    allow_pickle=True)\n",
    "sample_data_om = np.load(os.path.join(analysis_dir,'sample_data_om.npy'),\n",
    "    allow_pickle=True)\n",
    "sample_data_om2 = np.load(os.path.join(analysis_dir,'sample_data_om2.npy'),\n",
    "    allow_pickle=True)\n",
    "\n",
    "# Potential interpolator version\n",
    "interpot_version = 'all_star_dm_enclosed_mass'\n",
    "\n",
    "# Stellar halo density information\n",
    "stellar_halo_density_version = 'poisson_twopower_softening'\n",
    "stellar_halo_density_ncut = 500\n",
    "\n",
    "# Stellar halo rotation information\n",
    "stellar_halo_rotation_dftype = 'tanh_rotation'\n",
    "stellar_halo_rotation_version = 'asymmetry_fit'\n",
    "stellar_halo_rotation_ncut = 500\n",
    "\n",
    "# Beta information\n",
    "beta_ncut = 500\n",
    "\n",
    "# Define density profiles\n",
    "stellar_halo_densfunc = pdens.TwoPowerSpherical()\n",
    "\n",
    "J_vals = []\n",
    "\n",
    "for i in range(n_mw):\n",
    "    # if i > 0: continue\n",
    "\n",
    "    # Get the primary\n",
    "    primary = tree_primaries[i]\n",
    "    z0_sid = primary.subfind_id[0]\n",
    "    major_mergers = primary.tree_major_mergers\n",
    "    n_major = primary.n_major_mergers\n",
    "    n_snap = len(primary.snapnum)\n",
    "    primary_filename = primary.get_cutout_filename(mw_analog_dir,\n",
    "        snapnum=primary.snapnum[0])\n",
    "    co = pcutout.TNGCutout(primary_filename)\n",
    "    co.center_and_rectify()\n",
    "    pid = co.get_property('stars','ParticleIDs')\n",
    "\n",
    "    # Load the interpolator for the sphericalized potential\n",
    "    interpolator_filename = os.path.join(dens_fitting_dir,\n",
    "        'spherical_interpolated_potential/',interpot_version,\n",
    "        str(z0_sid),'interp_potential.pkl')\n",
    "    with open(interpolator_filename,'rb') as handle:\n",
    "        interpot = pickle.load(handle)\n",
    "\n",
    "    for j in range(n_major):\n",
    "        # if j > 0: continue\n",
    "        if verbose: print(f'Calculating Jeans equation for MW analog '\n",
    "                          f'{i+1}/{n_mw}, merger {j+1}/{n_major}', end='\\r')\n",
    "\n",
    "        # Get the major merger\n",
    "        major_merger = primary.tree_major_mergers[j]\n",
    "        major_acc_sid = major_merger.subfind_id[0]\n",
    "        major_mlpid = major_merger.secondary_mlpid\n",
    "        upid = major_merger.get_unique_particle_ids('stars',data_dir=data_dir)\n",
    "        indx = np.where(np.isin(pid,upid))[0]\n",
    "\n",
    "        # Get energy and angular momentum\n",
    "        orbs = co.get_orbs('stars')[indx]\n",
    "        n_star = len(orbs)\n",
    "        masses = co.get_masses('stars')[indx].to_value(apu.Msun)\n",
    "        rs = orbs.r().to_value(apu.kpc)\n",
    "        pe = co.get_potential_energy('stars')[indx].to_value(apu.km**2/apu.s**2)\n",
    "\n",
    "        # Mask the input orbits to only include those with radius greater\n",
    "        # than the softening length\n",
    "        r_softening = putil.get_softening_length('stars', z=0, physical=True)\n",
    "        mask = rs > r_softening\n",
    "        orbs = orbs[mask]\n",
    "        masses = masses[mask]\n",
    "        rs = rs[mask]\n",
    "        pe = pe[mask]\n",
    "\n",
    "        # Generate the adaptive binning kwargs\n",
    "        rmin = np.max([np.min(rs), r_softening])\n",
    "        n_bin = np.min([500, len(orbs)//10]) # n per bin\n",
    "        adaptive_binning_kwargs = {\n",
    "            'n':n_bin,\n",
    "            'rmin':0.,\n",
    "            'rmax':np.max( orbs.r().to_value(apu.kpc) ),\n",
    "            'bin_mode':'exact numbers',\n",
    "            'bin_equal_n':True,\n",
    "            'end_mode':'ignore',\n",
    "            'bin_cents_mode':'median',\n",
    "        }\n",
    "\n",
    "        # Compute the spherical Jeans equation quantities for N-body\n",
    "        Js_nb,rs_nb,qs_nb = pkin.calculate_spherical_jeans(orbs, pe=pe, \n",
    "            n_bootstrap=n_bootstrap, rs_is_bin_mean_r=True, \n",
    "            adaptive_binning=adaptive_binning_kwargs)\n",
    "        if np.sum(qs_nb[2]) > 0.:\n",
    "            Jw_nb,Jwd_nb = pkin.calculate_weighted_average_J(\n",
    "                Js_nb,rs_nb,qs=qs_nb,handle_nans=True)\n",
    "        else:\n",
    "            Jw_nb,Jwd_nb = np.nan,np.nan\n",
    "        \n",
    "        ### Constant beta DF\n",
    "        mask_cb = (sample_data_cb['z0_sid'] == z0_sid) &\\\n",
    "                  (sample_data_cb['major_acc_sid'] == major_acc_sid) &\\\n",
    "                  (sample_data_cb['major_mlpid'] == major_mlpid) &\\\n",
    "                  (sample_data_cb['merger_number'] == j+1)\n",
    "        indx_cb = np.where(mask_cb)[0]\n",
    "        assert len(indx_cb) == 1, 'Something went wrong'\n",
    "        indx_cb = indx_cb[0]\n",
    "        sample_cb = sample_data_cb['sample'][indx_cb]\n",
    "        pe_sample_cb = potential.evaluatePotentials(interpot, sample_cb.R(), \n",
    "            sample_cb.z()).to_value(apu.km**2/apu.s**2)\n",
    "\n",
    "        # Compute the spherical Jeans equation quantities\n",
    "        Js_cb,rs_cb,qs_cb = pkin.calculate_spherical_jeans(sample_cb, \n",
    "            pe=pe_sample_cb, n_bootstrap=n_bootstrap, rs_is_bin_mean_r=True, \n",
    "            adaptive_binning=adaptive_binning_kwargs)\n",
    "        if np.sum(qs_cb[2]) > 0.:\n",
    "            Jw_sample_cb,Jwd_sample_cb = pkin.calculate_weighted_average_J(\n",
    "                Js_cb,rs_cb,qs=qs_cb,handle_nans=True)\n",
    "        else:\n",
    "            Jw_sample_cb,Jwd_sample_cb = np.nan,np.nan\n",
    "\n",
    "        ### Osipkov-Merritt DF\n",
    "        mask_om = (sample_data_om['z0_sid'] == z0_sid) &\\\n",
    "                  (sample_data_om['major_acc_sid'] == major_acc_sid) &\\\n",
    "                  (sample_data_om['major_mlpid'] == major_mlpid) &\\\n",
    "                  (sample_data_om['merger_number'] == j+1)\n",
    "        indx_om = np.where(mask_om)[0]\n",
    "        assert len(indx_om) == 1, 'Something went wrong'\n",
    "        indx_om = indx_om[0]\n",
    "        sample_om = sample_data_om['sample'][indx_om]\n",
    "        pe_sample_om = potential.evaluatePotentials(interpot, sample_om.R(), \n",
    "            sample_om.z()).to_value(apu.km**2/apu.s**2)\n",
    "\n",
    "        # Compute the spherical Jeans equation quantities\n",
    "        Js_om,rs_om,qs_om = pkin.calculate_spherical_jeans(sample_om, \n",
    "            pe=pe_sample_om, n_bootstrap=n_bootstrap, rs_is_bin_mean_r=True, \n",
    "            adaptive_binning=adaptive_binning_kwargs)\n",
    "        if np.sum(qs_om[2]) > 0.:\n",
    "            Jw_sample_om,Jwd_sample_om = pkin.calculate_weighted_average_J(\n",
    "                Js_om,rs_om,qs=qs_om,handle_nans=True)\n",
    "        else:\n",
    "            Jw_sample_om,Jwd_sample_om = np.nan,np.nan\n",
    "\n",
    "        ### Osipkov-Merritt combination DF\n",
    "        mask_om2 = (sample_data_om2['z0_sid'] == z0_sid) &\\\n",
    "                   (sample_data_om2['major_acc_sid'] == major_acc_sid) &\\\n",
    "                   (sample_data_om2['major_mlpid'] == major_mlpid) &\\\n",
    "                   (sample_data_om2['merger_number'] == j+1)\n",
    "        indx_om2 = np.where(mask_om2)[0]\n",
    "        assert len(indx_om2) == 1, 'Something went wrong'\n",
    "        indx_om2 = indx_om2[0]\n",
    "        sample_om2 = sample_data_om2['sample'][indx_om2]\n",
    "        pe_sample_om2 = potential.evaluatePotentials(interpot, sample_om2.R(), \n",
    "            sample_om2.z()).to_value(apu.km**2/apu.s**2)\n",
    "\n",
    "        # Compute the spherical Jeans equation quantities\n",
    "        Js_om2,rs_om2,qs_om2 = pkin.calculate_spherical_jeans(sample_om2, \n",
    "            pe=pe_sample_om2, n_bootstrap=n_bootstrap, rs_is_bin_mean_r=True, \n",
    "            adaptive_binning=adaptive_binning_kwargs)\n",
    "        if np.sum(qs_om2[2]) > 0.:\n",
    "            Jw_sample_om2,Jwd_sample_om2 = pkin.calculate_weighted_average_J(\n",
    "                Js_om2,rs_om2,qs=qs_om2,handle_nans=True)\n",
    "        else:\n",
    "            Jw_sample_om2,Jwd_sample_om2 = np.nan,np.nan\n",
    "\n",
    "        # Save the values\n",
    "        J_vals.append(\n",
    "            (Jw_nb, Jwd_nb, Js_nb, rs_nb, qs_nb,\n",
    "             Jw_sample_cb, Jwd_sample_cb, Js_cb, rs_cb, qs_cb,\n",
    "             Jw_sample_om, Jwd_sample_om, Js_om, rs_om, qs_om,\n",
    "             Jw_sample_om2, Jwd_sample_om2, Js_om2, rs_om2, qs_om2,\n",
    "             z0_sid, j+1, major_mlpid, np.sum(masses))\n",
    "            )\n",
    "\n",
    "dt = np.dtype([ ('J_mean',float),\n",
    "                ('J2_mean',float),\n",
    "                ('Js',object),\n",
    "                ('rs',object),\n",
    "                ('qs',object),\n",
    "                ('J_mean_cb',float),\n",
    "                ('J2_mean_cb',float),\n",
    "                ('Js_cb',object),\n",
    "                ('rs_cb',object),\n",
    "                ('qs_cb',object),\n",
    "                ('J_mean_om',float),\n",
    "                ('J2_mean_om',float),\n",
    "                ('Js_om',object),\n",
    "                ('rs_om',object),\n",
    "                ('qs_om',object),\n",
    "                ('J_mean_om2',float),\n",
    "                ('J2_mean_om2',float),\n",
    "                ('Js_om2',object),\n",
    "                ('rs_om2',object),\n",
    "                ('qs_om2',object),\n",
    "                ('z0_sid',int),\n",
    "                ('major_merger',int),\n",
    "                ('major_mlpid',int),\n",
    "                ('star_mass',float)\n",
    "                ])\n",
    "J_vals = np.array(J_vals, dtype=dt)\n",
    "\n",
    "np.save(os.path.join(analysis_dir,'J_vals.npy'), J_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrangle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_version = 'v1.1'\n",
    "analysis_dir = os.path.join(mw_analog_dir,'analysis',analysis_version)\n",
    "\n",
    "# Load the structured arrays\n",
    "J_vals = np.load(os.path.join(analysis_dir,'J_vals.npy'), allow_pickle=True)\n",
    "\n",
    "# Load the merger_information\n",
    "merger_data = np.load(os.path.join(analysis_dir,'merger_data.npy'), \n",
    "    allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create plots showing mean J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jm_samples = [J_vals['J_mean_cb'],\n",
    "              J_vals['J_mean_om'],\n",
    "              J_vals['J_mean_om2']]\n",
    "sample_suffix = ['CB','OM','OM2']\n",
    "Jm_lim = [-1.1,1.1]\n",
    "\n",
    "s=10\n",
    "facecolor='none'\n",
    "edgecolor='Black'\n",
    "alpha=0.5\n",
    "annotate_fs = 8\n",
    "\n",
    "# Make the figure\n",
    "fig = plt.figure(figsize=(4,7))\n",
    "gs = mpl.gridspec.GridSpec(nrows=10,ncols=4,figure=fig)\n",
    "\n",
    "# Main axes\n",
    "axs = [fig.add_subplot(gs[1:4,0:3]),\n",
    "       fig.add_subplot(gs[4:7,0:3]),\n",
    "       fig.add_subplot(gs[7:10,0:3])\n",
    "        ]\n",
    "# Top histogram axes\n",
    "tax = fig.add_subplot(gs[0,0:3])\n",
    "# Right histogram axes\n",
    "raxs = [fig.add_subplot(gs[1:4,3]),\n",
    "        fig.add_subplot(gs[4:7,3]),\n",
    "        fig.add_subplot(gs[7:10,3])\n",
    "        ]\n",
    "\n",
    "# Loop over main axes\n",
    "for i in range(3):\n",
    "    axs[i].scatter(J_vals['J_mean'], Jm_samples[i], s=s, facecolor=facecolor,\n",
    "        edgecolor=edgecolor, alpha=alpha)\n",
    "    axs[i].set_xlim(Jm_lim)\n",
    "    axs[i].set_ylim(Jm_lim)\n",
    "    # axs[i].set_aspect('equal')\n",
    "    if i == 2:\n",
    "        axs[i].set_xlabel(r'$\\overline{\\mathcal{J}}_{\\mathrm{data}}$')\n",
    "    else:\n",
    "        axs[i].tick_params(labelbottom=False)\n",
    "    axs[i].set_ylabel(r'$\\overline{\\mathcal{J}}_{\\mathrm{'+sample_suffix[i]+'}}$')\n",
    "    axs[i].axhline(0., color='Black', linestyle='--')\n",
    "    axs[i].axvline(0., color='Black', linestyle='--')\n",
    "\n",
    "# Do the top histogram\n",
    "tax.hist(J_vals['J_mean'], bins=21, range=Jm_lim, histtype='step', \n",
    "    color='Black', orientation='vertical')\n",
    "tax.tick_params(labelbottom=False)\n",
    "tax.set_xlim(Jm_lim)\n",
    "tax.set_ylabel(r'$N$')\n",
    "tax.axvline(0, color='Black', linestyle='--')\n",
    "Jm_mean, Jm_std = np.mean(J_vals['J_mean']), np.std(J_vals['J_mean'])\n",
    "tax.text(0.1, 0.5, r'$\\mu = $'+str(round(Jm_mean,2))+'\\n'+r'$\\sigma = $'+str(round(Jm_std,2)),\n",
    "    transform=tax.transAxes, fontsize=annotate_fs)\n",
    "\n",
    "# Do the right histograms\n",
    "for i in range(3):\n",
    "    raxs[i].hist(Jm_samples[i], bins=21, range=Jm_lim, histtype='step', \n",
    "        color='Black', orientation='horizontal')\n",
    "    raxs[i].tick_params(labelleft=False)\n",
    "    raxs[i].set_xlabel(r'$N$')\n",
    "    if i == 0:\n",
    "        raxs[i].set_xlabel(r'$N$')\n",
    "        raxs[i].xaxis.set_label_position('top')\n",
    "        raxs[i].tick_params(labelbottom=False, labeltop=True)\n",
    "    raxs[i].set_ylim(Jm_lim)\n",
    "    raxs[i].axhline(0, color='Black', linestyle='--')\n",
    "    mean_std_mask = (Jm_samples[i] > -5) &\\\n",
    "                    (Jm_samples[i] < 5)\n",
    "    Jm_mean = np.mean(Jm_samples[i][mean_std_mask])\n",
    "    Jm_std = np.std(Jm_samples[i][mean_std_mask])\n",
    "    raxs[i].text(0.25, 0.8, r'$\\mu = $'+str(round(Jm_mean,2))+'\\n'+r'$\\sigma = $'+str(round(Jm_std,2)),\n",
    "        transform=raxs[i].transAxes, fontsize=annotate_fs)\n",
    "\n",
    "# Set ticks properly\n",
    "ticks = [-1,-0.5,0,0.5,1]\n",
    "tax.set_xticks(ticks)\n",
    "for i in range(3):\n",
    "    axs[i].set_xticks(ticks)\n",
    "    axs[i].set_yticks(ticks)\n",
    "    raxs[i].set_yticks(ticks)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "fig.savefig('./fig/J_mean.pdf')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create plots showing J variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jwd_samples = [J_vals['J2_mean_cb'], \n",
    "               J_vals['J2_mean_om'],\n",
    "               J_vals['J2_mean_om2']]\n",
    "sample_suffix = ['CB','OM','OM2']\n",
    "Jwd_lim = [0.5,50]\n",
    "\n",
    "s=10\n",
    "facecolor='none'\n",
    "edgecolor='Black'\n",
    "alpha=0.5\n",
    "\n",
    "# Make the figure\n",
    "fig = plt.figure(figsize=(4,7))\n",
    "axs = fig.subplots(nrows=3, ncols=1)\n",
    "\n",
    "# Loop over main axes\n",
    "for i in range(3):\n",
    "    axs[i].scatter(J_vals['J2_mean'], Jwd_samples[i], s=s, facecolor=facecolor,\n",
    "        edgecolor=edgecolor, alpha=alpha)\n",
    "    axs[i].set_xlim(Jwd_lim)\n",
    "    axs[i].set_ylim(Jwd_lim)\n",
    "    # axs[i].set_aspect('equal')\n",
    "    if i == 2:\n",
    "        axs[i].set_xlabel(r'$\\sigma(\\mathcal{J}_{\\mathrm{data}})$')\n",
    "    else:\n",
    "        axs[i].tick_params(labelbottom=False)\n",
    "    axs[i].set_ylabel(r'$\\sigma(\\mathcal{J}_{\\mathrm{'+sample_suffix[i]+'}})$')\n",
    "    axs[i].axline((0,0),(1,1), color='Black', linestyle='--', alpha=0.5, \n",
    "        transform=axs[i].transAxes)\n",
    "    n_low = np.sum(Jwd_samples[i] > J_vals['J2_mean'])\n",
    "    n_high = np.sum(Jwd_samples[i] < J_vals['J2_mean'])\n",
    "    axs[i].text(0.75, 0.90, str(n_low), transform=axs[i].transAxes)\n",
    "    axs[i].text(0.90, 0.75, str(n_high), transform=axs[i].transAxes)\n",
    "    axs[i].set_xscale('log')\n",
    "    axs[i].set_yscale('log')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.05)\n",
    "fig.savefig('./fig/J_dispersion.pdf')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same figure, but show it as a fractional difference rather than relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jwd_samples = [J_vals['J2_mean_cb'],\n",
    "               J_vals['J2_mean_om'],\n",
    "               J_vals['J2_mean_om2']\n",
    "                ]\n",
    "sample_suffix = ['CB','OM','OM2']\n",
    "Jwd_lim = [0.5,50]\n",
    "\n",
    "s=10\n",
    "facecolor='none'\n",
    "edgecolor='Black'\n",
    "alpha=0.5\n",
    "\n",
    "# Make the figure\n",
    "fig = plt.figure(figsize=(4,7))\n",
    "axs = fig.subplots(nrows=3, ncols=1)\n",
    "\n",
    "# Assign colours to the points\n",
    "np.all(J_vals['z0_sid'] == merger_data['z0_sid'])\n",
    "\n",
    "# Loop over main axes\n",
    "for i in range(3):\n",
    "    difference = (Jwd_samples[i] - J_vals['J2_mean']) / J_vals['J2_mean']\n",
    "    axs[i].scatter(J_vals['J2_mean'], difference, s=s, \n",
    "        facecolor=facecolor, edgecolor=edgecolor, alpha=alpha)\n",
    "    axs[i].set_xlim(Jwd_lim)\n",
    "    # axs[i].set_ylim(-1,1)\n",
    "    # axs[i].set_aspect('equal')\n",
    "    if i == 2:\n",
    "        axs[i].set_xlabel(r'$\\sigma(\\mathcal{J}_{\\mathrm{data}})$')\n",
    "    else:\n",
    "        axs[i].tick_params(labelbottom=False)\n",
    "    axs[i].set_ylabel(r'fractional $\\Delta \\sigma(\\mathcal{J}_{\\mathrm{'+sample_suffix[i]+'}})$')\n",
    "    axs[i].axhline(0, color='Black', linestyle='--', alpha=0.5)\n",
    "    # n_low = np.sum(Jwd_samples[i] > J_vals['J2_mean'])\n",
    "    # n_high = np.sum(Jwd_samples[i] < J_vals['J2_mean'])\n",
    "    # axs[i].text(0.80, 0.90, str(n_low), transform=axs[i].transAxes)\n",
    "    # axs[i].text(0.90, 0.80, str(n_high), transform=axs[i].transAxes)\n",
    "    axs[i].set_xscale('log')\n",
    "    # axs[i].set_yscale('log')\n",
    "    axs[i].set_ylim(-1,2.5)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.05)\n",
    "fig.savefig('./fig/J_dispersion.pdf')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "nteract": {
   "version": "0.28.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
