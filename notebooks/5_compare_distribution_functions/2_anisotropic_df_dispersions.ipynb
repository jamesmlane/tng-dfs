{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "#\n",
    "# TITLE - 2_anisotropic_df_dispersions.ipynb\n",
    "# AUTHOR - James Lane\n",
    "# PROJECT - tng-dfs\n",
    "#\n",
    "# ------------------------------------------------------------------------\n",
    "#\n",
    "# Docstrings and metadata:\n",
    "'''Use DF samples + N-body data to calculate and compare the dispersion and \n",
    "anisotropy profiles.\n",
    "'''\n",
    "\n",
    "__author__ = \"James Lane\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../src/nb_modules/nb_imports.txt\n",
    "### Imports\n",
    "\n",
    "## Basic\n",
    "import numpy as np\n",
    "import sys, os, dill as pickle\n",
    "\n",
    "## Matplotlib\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "## Astropy\n",
    "from astropy import units as apu\n",
    "from astropy import constants as apc\n",
    "\n",
    "## Analysis\n",
    "import scipy.stats\n",
    "import scipy.interpolate\n",
    "\n",
    "## galpy\n",
    "from galpy import orbit\n",
    "from galpy import potential\n",
    "\n",
    "## Project-specific\n",
    "src_path = 'src/'\n",
    "while True:\n",
    "    if os.path.exists(src_path): break\n",
    "    if os.path.realpath(src_path).split('/')[-1] in ['tng-dfs','/']:\n",
    "            raise FileNotFoundError('Failed to find src/ directory.')\n",
    "    src_path = os.path.join('..',src_path)\n",
    "sys.path.insert(0,src_path)\n",
    "from tng_dfs import cutout as pcutout\n",
    "from tng_dfs import densprofile as pdens\n",
    "from tng_dfs import fitting as pfit\n",
    "from tng_dfs import kinematics as pkin\n",
    "from tng_dfs import plot as pplot\n",
    "from tng_dfs import util as putil\n",
    "\n",
    "### Notebook setup\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(os.path.join(src_path,'mpl/project.mplstyle')) # This must be exactly here\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keywords, loading, pathing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../src/nb_modules/nb_setup.txt\n",
    "# Keywords\n",
    "cdict = putil.load_config_to_dict()\n",
    "keywords = ['DATA_DIR','MW_ANALOG_DIR','FIG_DIR_BASE','FITTING_DIR_BASE',\n",
    "            'RO','VO','ZO','LITTLE_H','MW_MASS_RANGE']\n",
    "data_dir,mw_analog_dir,fig_dir_base,fitting_dir_base,ro,vo,zo,h,\\\n",
    "    mw_mass_range = putil.parse_config_dict(cdict,keywords)\n",
    "\n",
    "# MW Analog \n",
    "mwsubs,mwsubs_vars = putil.prepare_mwsubs(mw_analog_dir,h=h,\n",
    "    mw_mass_range=mw_mass_range,return_vars=True,force_mwsubs=False,\n",
    "    bulge_disk_fraction_cuts=True)\n",
    "\n",
    "# Figure path\n",
    "local_fig_dir = './fig/'\n",
    "fig_dir = os.path.join(fig_dir_base, \n",
    "    'notebooks/5_compare_distribution_functions/2_anisotropic_df_dispersions/')\n",
    "os.makedirs(local_fig_dir,exist_ok=True)\n",
    "os.makedirs(fig_dir,exist_ok=True)\n",
    "show_plots = False\n",
    "\n",
    "# Load tree data\n",
    "tree_primary_filename = os.path.join(mw_analog_dir,\n",
    "    'major_mergers/tree_primaries.pkl')\n",
    "with open(tree_primary_filename,'rb') as handle: \n",
    "    tree_primaries = pickle.load(handle)\n",
    "tree_major_mergers_filename = os.path.join(mw_analog_dir,\n",
    "    'major_mergers/tree_major_mergers.pkl')\n",
    "with open(tree_major_mergers_filename,'rb') as handle:\n",
    "    tree_major_mergers = pickle.load(handle)\n",
    "n_mw = len(tree_primaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mass_error_weighted_deviation_beta_vdisp(nbody_orbs, sample_orbs, \n",
    "    nbody_mass, n_bs=100, adaptive_binning_kwargs={}, \n",
    "    velocity_quantities_squared=False):\n",
    "    '''compute_mass_error_weighted_deviation_beta_vdisp:\n",
    "    \n",
    "    Compute the mass- and uncertainty-weighted deviation of the N-body \n",
    "    velocity dispersion / beta trend from the DF samples. \n",
    "\n",
    "    For the binning scheme the default kwargs are:\n",
    "    - n: min(500, number of N-body particles//10)\n",
    "    - rmin: 0.\n",
    "    - rmax: max(N-body particle radii)\n",
    "    - bin_mode: 'exact numbers'\n",
    "    - bin_equal_n: True\n",
    "    - end_mode: 'ignore'\n",
    "    - bin_cents_mode: 'median'\n",
    "\n",
    "    Args:\n",
    "        nbody_orbs (galpy.orbit.Orbit): N-body orbits\n",
    "        sample_orbs (galpy.orbit.Orbit): DF samples\n",
    "        nbody_mass (np.ndarray): N-body particle masses\n",
    "        n_bs (int): Number of times to bootstrap the DF/N-body samples\n",
    "            to compute the deviation statistic for error estimation\n",
    "        adaptive_binning_kwargs (dict): kwargs for get_radius_binning(), will\n",
    "            be populated with defaults listed above if not provided.\n",
    "        velocity_quantities_squared (bool): If True, use the squared velocity \n",
    "            dispersions/mean squares that are output from \n",
    "            pkin.compute_betas_bootstrap(). If False, take the square root of\n",
    "            these quantities.\n",
    "    \n",
    "    Returns:\n",
    "        mwed_[beta,vr2,vp2,vt2] (np.ndarray): Mass-weighted error deviation\n",
    "    '''\n",
    "    # Binning for velocity dispersions and betas\n",
    "    n_bin = np.min([500, len(nbody_orbs)//10]) # n per bin\n",
    "    if 'n' not in adaptive_binning_kwargs.keys():\n",
    "        adaptive_binning_kwargs['n'] = n_bin\n",
    "    if 'rmin' not in adaptive_binning_kwargs.keys():\n",
    "        adaptive_binning_kwargs['rmin'] = 0.\n",
    "    if 'rmax' not in adaptive_binning_kwargs.keys():\n",
    "        adaptive_binning_kwargs['rmax'] = np.max( nbody_orbs.r().to_value(apu.kpc) )\n",
    "    if 'bin_mode' not in adaptive_binning_kwargs.keys():\n",
    "        adaptive_binning_kwargs['bin_mode'] = 'exact numbers'\n",
    "    if 'bin_equal_n' not in adaptive_binning_kwargs.keys():\n",
    "        adaptive_binning_kwargs['bin_equal_n'] = True\n",
    "    if 'end_mode' not in adaptive_binning_kwargs.keys():\n",
    "        adaptive_binning_kwargs['end_mode'] = 'ignore'\n",
    "    if 'bin_cents_mode' not in adaptive_binning_kwargs.keys():\n",
    "        adaptive_binning_kwargs['bin_cents_mode'] = 'median'\n",
    "\n",
    "    bin_edges, bin_cents, _ = pkin.get_radius_binning(nbody_orbs, \n",
    "        **adaptive_binning_kwargs)\n",
    "    bin_size = bin_edges[1:] - bin_edges[:-1]\n",
    "\n",
    "    # Compute velocity dispersions for N-body\n",
    "    compute_betas_kwargs = {'use_dispersions':True,\n",
    "                            'return_kinematics':True}\n",
    "    nbody_beta, nbody_vr2, nbody_vp2, nbody_vt2 = \\\n",
    "        pkin.compute_betas_bootstrap(nbody_orbs, bin_edges, n_bootstrap=n_bs, \n",
    "        compute_betas_kwargs=compute_betas_kwargs)\n",
    "\n",
    "    # Compute velocity dispersions for the DF samples\n",
    "    compute_betas_kwargs = {'use_dispersions':True,\n",
    "                            'return_kinematics':True}\n",
    "    sample_beta, sample_vr2, sample_vp2, sample_vt2 = \\\n",
    "        pkin.compute_betas_bootstrap(sample_orbs, bin_edges, n_bootstrap=n_bs, \n",
    "        compute_betas_kwargs=compute_betas_kwargs)\n",
    "\n",
    "    if not velocity_quantities_squared:\n",
    "        nbody_vr2 = np.sqrt(nbody_vr2)\n",
    "        nbody_vp2 = np.sqrt(nbody_vp2)\n",
    "        nbody_vt2 = np.sqrt(nbody_vt2)\n",
    "        sample_vr2 = np.sqrt(sample_vr2)\n",
    "        sample_vp2 = np.sqrt(sample_vp2)\n",
    "        sample_vt2 = np.sqrt(sample_vt2)\n",
    "\n",
    "    # Compute the mass profile for the N-body data\n",
    "    mass_profile = np.zeros(len(bin_cents))\n",
    "    rs = nbody_orbs.r().to_value(apu.kpc)\n",
    "    for i in range(len(bin_cents)):\n",
    "        mass_profile[i] = np.sum(nbody_mass[(rs > bin_edges[i]) &\\\n",
    "                                            (rs < bin_edges[i+1])])\n",
    "\n",
    "    # Compute the inter-sigma range for the N-body data, which will be the error\n",
    "    nbody_beta_err = np.percentile(nbody_beta, 84, axis=0) - \\\n",
    "                     np.percentile(nbody_beta, 16, axis=0)\n",
    "    nbody_vr2_err = np.percentile(nbody_vr2, 84, axis=0) - \\\n",
    "                    np.percentile(nbody_vr2, 16, axis=0)\n",
    "    nbody_vp2_err = np.percentile(nbody_vp2, 84, axis=0) - \\\n",
    "                    np.percentile(nbody_vp2, 16, axis=0)\n",
    "    nbody_vt2_err = np.percentile(nbody_vt2, 84, axis=0) - \\\n",
    "                    np.percentile(nbody_vt2, 16, axis=0)\n",
    "\n",
    "    # Compute the mass-error-weighted deviation between the N-body and DF \n",
    "    # sample trends\n",
    "    mewd_beta = np.sum( np.abs(nbody_beta - sample_beta)*\\\n",
    "                        mass_profile/nbody_beta_err, axis=1 )/\\\n",
    "                np.sum(mass_profile)\n",
    "    mewd_vr2 = np.sum( np.abs(nbody_vr2 - sample_vr2)*\\\n",
    "                        mass_profile/nbody_vr2_err, axis=1 )/\\\n",
    "                np.sum(mass_profile)\n",
    "    mewd_vp2 = np.sum( np.abs(nbody_vp2 - sample_vp2)*\\\n",
    "                        mass_profile/nbody_vp2_err, axis=1 )/\\\n",
    "                np.sum(mass_profile)\n",
    "    mewd_vt2 = np.sum( np.abs(nbody_vt2 - sample_vt2)*\\\n",
    "                        mass_profile/nbody_vt2_err, axis=1 )/\\\n",
    "                np.sum(mass_profile)\n",
    "\n",
    "    return mewd_beta, mewd_vr2, mewd_vp2, mewd_vt2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the dispersions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "verbose = True\n",
    "\n",
    "# Pathing\n",
    "dens_fitting_dir = os.path.join(fitting_dir_base,'density_profile')\n",
    "df_fitting_dir = os.path.join(fitting_dir_base,'distribution_function')\n",
    "analysis_version = 'v1.1'\n",
    "analysis_dir = os.path.join(mw_analog_dir,'analysis',analysis_version)\n",
    "\n",
    "# Anisotropy profile calculation keywords\n",
    "n_bs = 100\n",
    "\n",
    "# Get the sample orbits\n",
    "sample_data_cb = np.load(os.path.join(analysis_dir,'sample_data_cb.npy'),\n",
    "    allow_pickle=True)\n",
    "sample_data_om = np.load(os.path.join(analysis_dir,'sample_data_om.npy'),\n",
    "    allow_pickle=True)\n",
    "sample_data_om2 = np.load(os.path.join(analysis_dir,'sample_data_om2.npy'),\n",
    "    allow_pickle=True)\n",
    "\n",
    "mewd_data_cb = []\n",
    "mewd_data_om = []\n",
    "mewd_data_om2 = []\n",
    "\n",
    "for i in range(n_mw):\n",
    "    # if i != 1: continue\n",
    "\n",
    "    # Get the primary\n",
    "    primary = tree_primaries[i]\n",
    "    z0_sid = primary.subfind_id[0]\n",
    "    major_mergers = primary.tree_major_mergers\n",
    "    n_major = primary.n_major_mergers\n",
    "    n_snap = len(primary.snapnum)\n",
    "    primary_filename = primary.get_cutout_filename(mw_analog_dir,\n",
    "        snapnum=primary.snapnum[0])\n",
    "    co = pcutout.TNGCutout(primary_filename)\n",
    "    co.center_and_rectify()\n",
    "    pid = co.get_property('stars','ParticleIDs')\n",
    "\n",
    "    for j in range(n_major):\n",
    "        # if j > 0: continue\n",
    "        if verbose: print(f'Calculating anisotropy profiles for MW analog '\n",
    "                          f'{i+1}/{n_mw}, merger {j+1}/{n_major}', end='\\r')\n",
    "\n",
    "        # Get the major merger\n",
    "        major_merger = primary.tree_major_mergers[j]\n",
    "        major_acc_sid = major_merger.subfind_id[0]\n",
    "        major_mlpid = major_merger.secondary_mlpid\n",
    "        upid = major_merger.get_unique_particle_ids('stars',data_dir=data_dir)\n",
    "        indx = np.where(np.isin(pid,upid))[0]\n",
    "        orbs = co.get_orbs('stars')[indx]\n",
    "        n_star = len(orbs)\n",
    "        star_mass = co.get_masses('stars')[indx].to_value(apu.Msun)\n",
    "        r = orbs.r().to_value(apu.kpc)\n",
    "        r_softening = putil.get_softening_length('stars', z=0, physical=True)\n",
    "        rmin = np.max([np.min(r), r_softening])\n",
    "\n",
    "        ### Compute the mass-weighted error deviation for constant beta ###\n",
    "        mask = (sample_data_cb['z0_sid'] == z0_sid) &\\\n",
    "               (sample_data_cb['major_acc_sid'] == major_acc_sid) &\\\n",
    "               (sample_data_cb['major_mlpid'] == major_mlpid) &\\\n",
    "               (sample_data_cb['merger_number'] == j+1)\n",
    "        indx = np.where(mask)[0]\n",
    "        assert len(indx) == 1, 'Something went wrong'\n",
    "        indx = indx[0]\n",
    "\n",
    "        sample = sample_data_cb['sample'][indx]\n",
    "\n",
    "        adaptive_binning_kwargs = {'rmin':rmin}\n",
    "        mewd = compute_mass_error_weighted_deviation_beta_vdisp(orbs, \n",
    "            sample, star_mass, n_bs=n_bs, \n",
    "            adaptive_binning_kwargs=adaptive_binning_kwargs, \n",
    "            velocity_quantities_squared=False)\n",
    "        mewd_self = compute_mass_error_weighted_deviation_beta_vdisp(orbs,\n",
    "            orbs, star_mass, n_bs=n_bs,\n",
    "            adaptive_binning_kwargs=adaptive_binning_kwargs, \n",
    "            velocity_quantities_squared=False)\n",
    "\n",
    "        _data = (\n",
    "            z0_sid,\n",
    "            major_acc_sid,\n",
    "            major_mlpid,\n",
    "            j+1,\n",
    "            mewd[0],\n",
    "            mewd[1],\n",
    "            mewd[2],\n",
    "            mewd[3],\n",
    "            mewd_self[0],\n",
    "            mewd_self[1],\n",
    "            mewd_self[2],\n",
    "            mewd_self[3],\n",
    "        )\n",
    "        mewd_data_cb.append(_data)\n",
    "\n",
    "        ### Compute the mass-weighted error deviation for Osipkov-Merritt ###\n",
    "        mask = (sample_data_om['z0_sid'] == z0_sid) &\\\n",
    "               (sample_data_om['major_acc_sid'] == major_acc_sid) &\\\n",
    "               (sample_data_om['major_mlpid'] == major_mlpid) &\\\n",
    "               (sample_data_om['merger_number'] == j+1)\n",
    "        indx = np.where(mask)[0]\n",
    "        assert len(indx) == 1, 'Something went wrong'\n",
    "        indx = indx[0]\n",
    "\n",
    "        sample = sample_data_om['sample'][indx]\n",
    "\n",
    "        adaptive_binning_kwargs = {'rmin':rmin}\n",
    "        mewd = compute_mass_error_weighted_deviation_beta_vdisp(orbs, \n",
    "            sample, star_mass, n_bs=n_bs, \n",
    "            adaptive_binning_kwargs=adaptive_binning_kwargs, \n",
    "            velocity_quantities_squared=False)\n",
    "        mewd_self = compute_mass_error_weighted_deviation_beta_vdisp(orbs,\n",
    "            orbs, star_mass, n_bs=n_bs, \n",
    "            adaptive_binning_kwargs=adaptive_binning_kwargs, \n",
    "            velocity_quantities_squared=False)\n",
    "\n",
    "        _data = (\n",
    "            z0_sid,\n",
    "            major_acc_sid,\n",
    "            major_mlpid,\n",
    "            j+1,\n",
    "            mewd[0],\n",
    "            mewd[1],\n",
    "            mewd[2],\n",
    "            mewd[3],\n",
    "            mewd_self[0],\n",
    "            mewd_self[1],\n",
    "            mewd_self[2],\n",
    "            mewd_self[3],\n",
    "        )\n",
    "        mewd_data_om.append(_data)\n",
    "\n",
    "        ### Compute the mass-weighted error deviation for OM2 ###\n",
    "        mask = (sample_data_om2['z0_sid'] == z0_sid) &\\\n",
    "               (sample_data_om2['major_acc_sid'] == major_acc_sid) &\\\n",
    "               (sample_data_om2['major_mlpid'] == major_mlpid) &\\\n",
    "               (sample_data_om2['merger_number'] == j+1)\n",
    "        indx = np.where(mask)[0]\n",
    "        assert len(indx) == 1, 'Something went wrong'\n",
    "        indx = indx[0]\n",
    "\n",
    "        sample = sample_data_om2['sample'][indx]\n",
    "\n",
    "        adaptive_binning_kwargs = {'rmin':rmin}\n",
    "        mewd = compute_mass_error_weighted_deviation_beta_vdisp(orbs,\n",
    "            sample, star_mass, n_bs=n_bs,\n",
    "            adaptive_binning_kwargs=adaptive_binning_kwargs,\n",
    "            velocity_quantities_squared=False)\n",
    "        mewd_self = compute_mass_error_weighted_deviation_beta_vdisp(orbs,\n",
    "            orbs, star_mass, n_bs=n_bs,\n",
    "            adaptive_binning_kwargs=adaptive_binning_kwargs,\n",
    "            velocity_quantities_squared=False)\n",
    "        \n",
    "        _data = (\n",
    "            z0_sid,\n",
    "            major_acc_sid,\n",
    "            major_mlpid,\n",
    "            j+1,\n",
    "            mewd[0],\n",
    "            mewd[1],\n",
    "            mewd[2],\n",
    "            mewd[3],\n",
    "            mewd_self[0],\n",
    "            mewd_self[1],\n",
    "            mewd_self[2],\n",
    "            mewd_self[3],\n",
    "        )\n",
    "        mewd_data_om2.append(_data)\n",
    "\n",
    "# Save the data as a pickle\n",
    "header = ['z0_sid','major_acc_sid','major_mlpid','merger_number',\n",
    "          'mewd_beta','mewd_vr2','mewd_vp2','mewd_vt2',\n",
    "          'mewd_self_beta','mewd_self_vr2','mewd_self_vp2','mewd_self_vt2']\n",
    "with open(os.path.join(analysis_dir,'mewd_data_cb.pkl'),'wb') as handle:\n",
    "    pickle.dump([header,mewd_data_cb], handle)\n",
    "with open(os.path.join(analysis_dir,'mewd_data_om.pkl'),'wb') as handle:\n",
    "    pickle.dump([header,mewd_data_om], handle)\n",
    "with open(os.path.join(analysis_dir,'mewd_data_om2.pkl'),'wb') as handle:\n",
    "    pickle.dump([header,mewd_data_om2], handle)\n",
    "\n",
    "# Also save as a structured array\n",
    "mewd_data_dtype = np.dtype([\n",
    "    ('z0_sid',int),\n",
    "    ('major_acc_sid',int),\n",
    "    ('major_mlpid',int),\n",
    "    ('merger_number',int),\n",
    "    ('mewd_beta',object),\n",
    "    ('mewd_vr2',object),\n",
    "    ('mewd_vp2',object),\n",
    "    ('mewd_vt2',object),\n",
    "    ('mewd_self_beta',object),\n",
    "    ('mewd_self_vr2',object),\n",
    "    ('mewd_self_vp2',object),\n",
    "    ('mewd_self_vt2',object)])\n",
    "mewd_data_cb = np.array(mewd_data_cb, dtype=mewd_data_dtype)\n",
    "mewd_data_om = np.array(mewd_data_om, dtype=mewd_data_dtype)\n",
    "mewd_data_om2 = np.array(mewd_data_om2, dtype=mewd_data_dtype)\n",
    "np.save(os.path.join(analysis_dir,'mewd_data_cb.npy'), mewd_data_cb)\n",
    "np.save(os.path.join(analysis_dir,'mewd_data_om.npy'), mewd_data_om)\n",
    "np.save(os.path.join(analysis_dir,'mewd_data_om2.npy'), mewd_data_om2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the stashed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_version = 'v1.1'\n",
    "analysis_dir = os.path.join(mw_analog_dir,'analysis',analysis_version)\n",
    "\n",
    "# Or load the structured arrays\n",
    "mewd_data_cb = np.load(os.path.join(analysis_dir,'mewd_data_cb.npy'),\n",
    "    allow_pickle=True)\n",
    "mewd_data_om = np.load(os.path.join(analysis_dir,'mewd_data_om.npy'),\n",
    "    allow_pickle=True)\n",
    "mewd_data_om2 = np.load(os.path.join(analysis_dir,'mewd_data_om2.npy'),\n",
    "    allow_pickle=True)\n",
    "\n",
    "# Load the merger information\n",
    "merger_data = np.load(os.path.join(analysis_dir,'merger_data.npy'), \n",
    "    allow_pickle=True)\n",
    "\n",
    "checks = True\n",
    "if checks:\n",
    "    assert np.all( mewd_data_cb['z0_sid'] == mewd_data_om['z0_sid'] ), \\\n",
    "        'Something went wrong'\n",
    "    assert np.all( mewd_data_cb['major_acc_sid'] == mewd_data_om['major_acc_sid'] ), \\\n",
    "        'Something went wrong'\n",
    "    assert np.all( mewd_data_cb['major_mlpid'] == mewd_data_om['major_mlpid'] ), \\\n",
    "        'Something went wrong'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the typical MEWD value for the sample self-comparison, as well as the \n",
    "# 16th and 84th percentiles\n",
    "mewd_keys = ['mewd_self_beta','mewd_self_vr2','mewd_self_vp2','mewd_self_vt2']\n",
    "mwd_cb_self_percs = np.zeros((4,3))\n",
    "for i in range(4):\n",
    "    p = np.array([])\n",
    "    for j in range(n_mw):\n",
    "        p = np.append(p, mewd_data_cb[mewd_keys[i]][j])\n",
    "    mwd_cb_self_percs[i] = np.percentile(p, [16,50,84])\n",
    "\n",
    "mwd_om_self_percs = np.zeros((4,3))\n",
    "for i in range(4):\n",
    "    p = np.array([])\n",
    "    for j in range(n_mw):\n",
    "        p = np.append(p, mewd_data_om[mewd_keys[i]][j])\n",
    "    mwd_om_self_percs[i] = np.percentile(p, [16,50,84])\n",
    "\n",
    "mwd_om2_self_percs = np.zeros((4,3))\n",
    "for i in range(4):\n",
    "    p = np.array([])\n",
    "    for j in range(n_mw):\n",
    "        p = np.append(p, mewd_data_om2[mewd_keys[i]][j])\n",
    "    mwd_om2_self_percs[i] = np.percentile(p, [16,50,84])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the paper figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot keywords\n",
    "columnwidth, textwidth = pplot.get_latex_columnwidth_textwidth_inches()\n",
    "key_suffixes = ['beta','vr2','vp2','vt2']\n",
    "ticklabel_fs = 6\n",
    "label_fs = 10\n",
    "# facecolor='none'\n",
    "marker_s = 10\n",
    "marker_linewidth = 0.5\n",
    "marker_zorder = 4\n",
    "marker_edgecolor='Black'\n",
    "data_range = [0.4,20]\n",
    "panel_labels = [r'$\\beta$', r'$\\sigma_{r}$', r'$\\sigma_{\\phi}$', \n",
    "    r'$\\sigma_{\\theta}$']\n",
    "panel_label_fs = 10\n",
    "one_to_one_line_numbers = True\n",
    "\n",
    "# Colormap for constant anisotropy\n",
    "cmap = pplot.colors().colourmap('rainbow')\n",
    "norm = mpl.colors.Normalize(vmin=-0.1, vmax=1.0)\n",
    "\n",
    "# Make the figure\n",
    "fig = plt.figure(figsize=(textwidth,3.5))\n",
    "axs = fig.subplots(nrows=2, ncols=4)\n",
    "n_merger = len(merger_data)\n",
    "\n",
    "# Plot the panels, top row CB vs OM, bottom row OM2 vs OM\n",
    "for i in range(n_merger):\n",
    "    # Color is the value of the anisotropy\n",
    "    anisotropy = merger_data['anisotropy'][i]\n",
    "    c = cmap(norm(anisotropy))\n",
    "    if anisotropy > 0.5:\n",
    "        this_zorder = marker_zorder + 1\n",
    "    else:\n",
    "        this_zorder = marker_zorder - 1\n",
    "    # Loop over beta, vr2, vp2, vt2\n",
    "    for j in range(4):\n",
    "        key = f'mewd_{key_suffixes[j]}'\n",
    "        axs[0,j].scatter(np.nanmedian(mewd_data_cb[key][i]),\n",
    "                         np.nanmedian(mewd_data_om[key][i]),\n",
    "                         marker='o', s=marker_s, zorder=this_zorder, \n",
    "                         linewidth=marker_linewidth, facecolor=c, \n",
    "                         edgecolor=marker_edgecolor)\n",
    "        axs[1,j].scatter(np.nanmedian(mewd_data_cb[key][i]),\n",
    "                         np.nanmedian(mewd_data_om2[key][i]),\n",
    "                         marker='o', s=marker_s, zorder=this_zorder, \n",
    "                         linewidth=marker_linewidth, facecolor=c, \n",
    "                         edgecolor=marker_edgecolor)\n",
    "\n",
    "# Assess the typical errors\n",
    "mewd_cb_self_percs = np.zeros((4,3))\n",
    "mewd_om_self_percs = np.zeros((4,3))\n",
    "mewd_om2_self_percs = np.zeros((4,3))\n",
    "key_suffixes = ['beta','vr2','vp2','vt2']\n",
    "\n",
    "for i in range(4):\n",
    "    key = 'mewd_self_'+key_suffixes[i]\n",
    "    p_cb = np.array([])\n",
    "    p_om = np.array([])\n",
    "    p_om2 = np.array([])\n",
    "    for j in range(n_merger):\n",
    "        p_cb = np.concatenate( (p_cb, mewd_data_om[key][j]) )\n",
    "        p_om = np.concatenate( (p_om, mewd_data_om2[key][j]) )\n",
    "        p_om2 = np.concatenate( (p_om2, mewd_data_om2[key][j]) )\n",
    "    mewd_cb_self_percs[i] = np.nanpercentile(p_cb, [16,50,84])\n",
    "    mewd_om_self_percs[i] = np.nanpercentile(p_om, [16,50,84])\n",
    "    mewd_om2_self_percs[i] = np.nanpercentile(p_om2, [16,50,84])\n",
    "\n",
    "# Labels and limits\n",
    "axs[0,0].set_ylabel(r'$\\delta_\\mathrm{OM}$', fontsize=label_fs)\n",
    "axs[1,0].set_ylabel(r'$\\delta_\\mathrm{OM2}$', fontsize=label_fs)\n",
    "for i in range(4):\n",
    "    # Bottom row has x-axis labels\n",
    "    axs[1,i].set_xlabel(r'$\\delta_\\mathrm{CB}$', fontsize=label_fs)\n",
    "\n",
    "    # Limits\n",
    "    axs[0,i].set_xlim(data_range)\n",
    "    axs[0,i].set_ylim(data_range)\n",
    "    axs[1,i].set_xlim(data_range)\n",
    "    axs[1,i].set_ylim(data_range)\n",
    "\n",
    "    # Panel labels\n",
    "    axs[0,i].text(0.2, 0.9, panel_labels[i], transform=axs[0,i].transAxes,\n",
    "        ha='left', va='top', fontsize=panel_label_fs, \n",
    "        bbox=dict(facecolor='white', edgecolor='Black'))\n",
    "    axs[1,i].text(0.2, 0.9, panel_labels[i], transform=axs[1,i].transAxes,\n",
    "        ha='left', va='top', fontsize=panel_label_fs,\n",
    "        bbox=dict(facecolor='white', edgecolor='Black'))\n",
    "\n",
    "    # Scale and ticks\n",
    "    for j in range(2):\n",
    "        axs[j,i].set_xscale('log')\n",
    "        axs[j,i].set_yscale('log')\n",
    "        axs[j,i].tick_params(axis='both', labelsize=ticklabel_fs)\n",
    "        if i > 0:\n",
    "            axs[j,i].tick_params(labelleft=False)\n",
    "    axs[0,i].tick_params(labelbottom=False)\n",
    "\n",
    "    # Self-consistent errors\n",
    "    axs[0,i].axline(xy1=[0,0], xy2=[1,1], color='k', ls='--')\n",
    "    axs[0,i].axvline(mewd_cb_self_percs[i,1], color='Black', ls='solid')\n",
    "    axs[0,i].axvspan(mewd_cb_self_percs[i,0], mewd_cb_self_percs[i,2], \n",
    "        color='Black', alpha=0.25)\n",
    "    axs[0,i].axhline(mewd_om_self_percs[i,1], color='Black', ls='solid')\n",
    "    axs[0,i].axhspan(mewd_om_self_percs[i,0], mewd_om_self_percs[i,2], \n",
    "        color='Black', alpha=0.25)\n",
    "    for fac in [2,4]:\n",
    "        axs[0,i].axvline(fac*mewd_cb_self_percs[i,1], color='Gray', \n",
    "            ls='dotted')\n",
    "        axs[0,i].axhline(fac*mewd_om_self_percs[i,1], color='Gray', \n",
    "            ls='dotted')\n",
    "    \n",
    "    axs[1,i].axline(xy1=[0,0], xy2=[1,1], color='k', ls='--')\n",
    "    axs[1,i].axvline(mewd_cb_self_percs[i,1], color='Black', ls='solid')\n",
    "    axs[1,i].axvspan(mewd_cb_self_percs[i,0], mewd_cb_self_percs[i,2], \n",
    "        color='Black', alpha=0.25)\n",
    "    axs[1,i].axhline(mewd_om2_self_percs[i,1], color='Black', ls='solid')\n",
    "    axs[1,i].axhspan(mewd_om2_self_percs[i,0], mewd_om2_self_percs[i,2], \n",
    "        color='Black', alpha=0.25)\n",
    "    for fac in [2,4]:\n",
    "        axs[1,i].axvline(fac*mewd_cb_self_percs[i,1], color='Gray', \n",
    "            ls='dotted')\n",
    "        axs[1,i].axhline(fac*mewd_om2_self_percs[i,1], color='Gray', \n",
    "            ls='dotted')\n",
    "    \n",
    "    # One-to-one line\n",
    "    if one_to_one_line_numbers:\n",
    "        n_cb = 0\n",
    "        n_om = 0\n",
    "        key = 'mewd_'+key_suffixes[i]\n",
    "        for j in range(n_merger):\n",
    "            om_gt_cb = np.nanmedian( mewd_data_om[key][j] ) > \\\n",
    "                       np.nanmedian( mewd_data_cb[key][j] )\n",
    "            if om_gt_cb: # Opposite because greater means worse\n",
    "                n_cb += 1\n",
    "            else:\n",
    "                n_om += 1\n",
    "        axs[0,i].text(0.925, 0.825, str(n_om), transform=axs[0,i].transAxes, \n",
    "            ha='center', va='center', fontsize=ticklabel_fs)\n",
    "        axs[0,i].text(0.825, 0.925, str(n_cb), transform=axs[0,i].transAxes, \n",
    "            ha='center', va='center', fontsize=ticklabel_fs)\n",
    "\n",
    "        n_cb = 0\n",
    "        n_om2 = 0\n",
    "        key = 'mewd_'+key_suffixes[i]\n",
    "        for j in range(n_merger):\n",
    "            om2_gt_cb = np.median( mewd_data_om2[key][j] ) > \\\n",
    "                        np.median( mewd_data_cb[key][j] )\n",
    "            if om2_gt_cb: # Opposite because greater means worse\n",
    "                n_cb += 1\n",
    "            else:\n",
    "                n_om2 += 1\n",
    "        axs[1,i].text(0.925, 0.825, str(n_om2), transform=axs[1,i].transAxes, \n",
    "            ha='center', va='center', fontsize=ticklabel_fs)\n",
    "        axs[1,i].text(0.825, 0.925, str(n_cb), transform=axs[1,i].transAxes, \n",
    "            ha='center', va='center', fontsize=ticklabel_fs)\n",
    "\n",
    "# Colorbar\n",
    "cax = fig.add_axes([0.92, 0.2, 0.02, 0.7])\n",
    "cbar = fig.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=cmap), cax=cax)\n",
    "cbar.set_label(r'$\\beta$', fontsize=label_fs)\n",
    "cbar.ax.tick_params(labelsize=ticklabel_fs)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.1, right=0.91)\n",
    "fig.savefig(os.path.join(local_fig_dir,'delta_comparison.pdf'), dpi=300, \n",
    "    bbox_inches='tight')\n",
    "fig.savefig(os.path.join(local_fig_dir,'delta_comparison.png'), dpi=300, \n",
    "    bbox_inches='tight')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also make the figures individually\n",
    "\n",
    "These are older plots than the one above, which has been updated to use space more efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column-sized figure width\n",
    "columnwidth = 244./72.27 # In inches, from pt\n",
    "# Full-sized figure width\n",
    "textwidth = 508./72.27 # In inches, from pt\n",
    "\n",
    "# Plot params\n",
    "ylabels = [r'$\\beta$', r'$\\sigma_{r},$', r'$\\sigma_{\\phi},$', r'$\\sigma_{\\theta},$']\n",
    "label_fs = 9\n",
    "key_suffixes = ['beta','vr2','vp2','vt2']\n",
    "# beta_ticks = [0,2,4,6,8,10]\n",
    "beta_range = [0.4,20]\n",
    "# vdisp_ticks = [0,2,4,6,8,10,12,14,16]\n",
    "vdisp_range = [0.4,20]\n",
    "# ticks = [beta_ticks, vdisp_ticks, vdisp_ticks, vdisp_ticks]\n",
    "ticklabel_fs = 6\n",
    "# facecolor='none'\n",
    "edgecolor='Black'\n",
    "s = 12\n",
    "one_to_one_line_numbers = True\n",
    "\n",
    "fig = plt.figure(figsize=(textwidth, 2.0))\n",
    "axs = fig.subplots(nrows=1, ncols=4)\n",
    "\n",
    "cmap = pplot.colors().colourmap('rainbow')\n",
    "norm = mpl.colors.Normalize(vmin=-0.1, vmax=1.0)\n",
    "\n",
    "# Plot the data\n",
    "n_merger = len(merger_data)\n",
    "for i in range(n_merger):\n",
    "    # if merger_data['anisotropy'][i] > 0.8:\n",
    "    #     edgecolor = 'Red'\n",
    "    #     zorder = 4\n",
    "    # # else:\n",
    "    # #     edgecolor = 'Black'\n",
    "    # #     zorder = 1\n",
    "    # elif np.abs(merger_data['anisotropy'][i]) < 0.2:\n",
    "    #     edgecolor = 'MediumBlue'\n",
    "    #     zorder = 3\n",
    "    # else:\n",
    "    #     edgecolor = 'Black'\n",
    "    #     zorder = 1\n",
    "\n",
    "    c = cmap(norm(merger_data['anisotropy'][i]))\n",
    "\n",
    "    for j in range(4):\n",
    "        \n",
    "        key = 'mewd_'+key_suffixes[j]\n",
    "        axs[j].scatter(np.median( mewd_data_om[key][i] ), \n",
    "                       np.median( mewd_data_cb[key][i] ),\n",
    "                       facecolor=c, edgecolor=edgecolor, s=s,\n",
    "                       marker='o', zorder=3, linewidth=0.5)\n",
    "\n",
    "# Colorbar\n",
    "cax = fig.add_axes([0.92, 0.23, 0.02, 0.7])\n",
    "cbar = fig.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=cmap), cax=cax)\n",
    "cbar.set_label(r'$\\beta$', fontsize=label_fs)\n",
    "cbar.ax.tick_params(labelsize=ticklabel_fs)\n",
    "\n",
    "# Assess the typical errors for the self-consistent case\n",
    "mewd_cb_self_percs = np.zeros((4,3))\n",
    "mewd_om_self_percs = np.zeros((4,3))\n",
    "key_suffixes = ['beta','vr2','vp2','vt2']\n",
    "\n",
    "n_merger = len(merger_data)\n",
    "for i in range(4):\n",
    "    key = 'mewd_self_'+key_suffixes[i]\n",
    "    p_cb = np.array([])\n",
    "    p_om = np.array([])\n",
    "    for j in range(n_merger):\n",
    "        p_cb = np.concatenate( (p_cb, mewd_data_om[key][j]) )\n",
    "        p_om = np.concatenate( (p_om, mewd_data_om2[key][j]) )\n",
    "    mewd_cb_self_percs[i] = np.percentile(p_cb, [16,50,84])\n",
    "    mewd_om_self_percs[i] = np.percentile(p_om, [16,50,84])\n",
    "\n",
    "# Labels and limits\n",
    "for i in range(4):\n",
    "    axs[i].set_xlabel(r'$\\delta($'+ylabels[i]+r'$_{\\mathrm{OM}})$',\n",
    "        fontsize=label_fs)\n",
    "    axs[i].set_ylabel(r'$\\delta($'+ylabels[i]+r'$_{\\mathrm{CB}})$',\n",
    "        fontsize=label_fs)\n",
    "    if i == 0:\n",
    "        axs[i].set_xlim(beta_range)\n",
    "        axs[i].set_ylim(beta_range)\n",
    "    else:\n",
    "        axs[i].set_xlim(vdisp_range)\n",
    "        axs[i].set_ylim(vdisp_range)\n",
    "\n",
    "    # Self-consistent errors\n",
    "    axs[i].axline(xy1 = [0,0], slope=1., color='k', ls='--')\n",
    "    axs[i].axvline(mewd_om_self_percs[i,1], color='Black', ls='solid')\n",
    "    axs[i].axvspan(mewd_om_self_percs[i,0], mewd_om_self_percs[i,2], \n",
    "        color='Black', alpha=0.25)\n",
    "    axs[i].axhline(mewd_cb_self_percs[i,1], color='Black', ls='solid')\n",
    "    axs[i].axhspan(mewd_cb_self_percs[i,0], mewd_cb_self_percs[i,2], \n",
    "        color='Black', alpha=0.25)\n",
    "    for fac in [2,4]:\n",
    "        axs[i].axvline(fac*mewd_om_self_percs[i,1], color='Gray', \n",
    "            ls='dotted')\n",
    "        axs[i].axhline(fac*mewd_cb_self_percs[i,1], color='Gray', \n",
    "            ls='dotted')\n",
    "        \n",
    "    # Scale and ticks\n",
    "    axs[i].set_xscale('log')\n",
    "    axs[i].set_yscale('log')\n",
    "    axs[i].xaxis.set_major_formatter(plt.FormatStrFormatter('%.0f'))\n",
    "    axs[i].yaxis.set_major_formatter(plt.FormatStrFormatter('%.0f'))\n",
    "    axs[i].tick_params(axis='both', labelsize=ticklabel_fs)\n",
    "    # axs[i].set_xticks(ticks[i])\n",
    "    # axs[i].set_yticks(ticks[i])\n",
    "\n",
    "    # One-to-one line\n",
    "    if one_to_one_line_numbers:\n",
    "        n_cb = 0\n",
    "        n_om = 0\n",
    "        key = 'mewd_'+key_suffixes[i]\n",
    "        for j in range(n_merger):\n",
    "            cb_gt_om = np.median( mewd_data_om[key][j] ) > \\\n",
    "                       np.median( mewd_data_cb[key][j] )\n",
    "            if cb_gt_om:\n",
    "                n_cb += 1\n",
    "            else:\n",
    "                n_om += 1\n",
    "\n",
    "        axs[i].text(0.925, 0.825, str(n_om), transform=axs[i].transAxes, \n",
    "            ha='center', va='center', fontsize=ticklabel_fs)\n",
    "        axs[i].text(0.825, 0.925, str(n_cb), transform=axs[i].transAxes, \n",
    "            ha='center', va='center', fontsize=ticklabel_fs)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.3, right=0.91)\n",
    "fig.savefig('./fig/delta_comparison_om_cb.pdf', dpi=300)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column-sized figure width\n",
    "columnwidth = 244./72.27 # In inches, from pt\n",
    "# Full-sized figure width\n",
    "textwidth = 508./72.27 # In inches, from pt\n",
    "\n",
    "# Plot params\n",
    "ylabels = [r'$\\beta$', r'$\\sigma_{r},$', r'$\\sigma_{\\phi},$', r'$\\sigma_{\\theta},$']\n",
    "label_fs = 9\n",
    "key_suffixes = ['beta','vr2','vp2','vt2']\n",
    "# beta_ticks = [0,2,4,6,8,10]\n",
    "beta_range = [0.4,20]\n",
    "# vdisp_ticks = [0,2,4,6,8,10,12,14,16]\n",
    "vdisp_range = [0.4,20]\n",
    "# ticks = [beta_ticks, vdisp_ticks, vdisp_ticks, vdisp_ticks]\n",
    "ticklabel_fs = 6\n",
    "# facecolor='none'\n",
    "edgecolor='Black'\n",
    "s = 12\n",
    "one_to_one_line_numbers = True\n",
    "\n",
    "fig = plt.figure(figsize=(textwidth, 2.0))\n",
    "axs = fig.subplots(nrows=1, ncols=4)\n",
    "\n",
    "cmap = pplot.colors().colourmap('rainbow')\n",
    "norm = mpl.colors.Normalize(vmin=-0.1, vmax=1.0)\n",
    "\n",
    "# Plot the data\n",
    "n_merger = len(merger_data)\n",
    "for i in range(n_merger):\n",
    "    # if merger_data['anisotropy'][i] > 0.8:\n",
    "    #     edgecolor = 'Red'\n",
    "    #     zorder = 4\n",
    "    # # else:\n",
    "    # #     edgecolor = 'Black'\n",
    "    # #     zorder = 1\n",
    "    # elif np.abs(merger_data['anisotropy'][i]) < 0.2:\n",
    "    #     edgecolor = 'MediumBlue'\n",
    "    #     zorder = 3\n",
    "    # else:\n",
    "    #     edgecolor = 'Black'\n",
    "    #     zorder = 1\n",
    "\n",
    "    c = cmap(norm(merger_data['anisotropy'][i]))\n",
    "\n",
    "    for j in range(4):\n",
    "        \n",
    "        key = 'mewd_'+key_suffixes[j]\n",
    "        axs[j].scatter(np.median( mewd_data_om[key][i] ), \n",
    "                       np.median( mewd_data_om2[key][i] ),\n",
    "                       facecolor=c, edgecolor=edgecolor, s=s,\n",
    "                       marker='o', zorder=3, linewidth=0.5)\n",
    "\n",
    "# Colorbar\n",
    "cax = fig.add_axes([0.92, 0.23, 0.02, 0.7])\n",
    "cbar = fig.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=cmap), cax=cax)\n",
    "cbar.set_label(r'$\\beta$', fontsize=label_fs)\n",
    "cbar.ax.tick_params(labelsize=ticklabel_fs)\n",
    "\n",
    "# Assess the typical errors for the self-consistent case\n",
    "mewd_om2_self_percs = np.zeros((4,3))\n",
    "mewd_om_self_percs = np.zeros((4,3))\n",
    "key_suffixes = ['beta','vr2','vp2','vt2']\n",
    "\n",
    "n_merger = len(merger_data)\n",
    "for i in range(4):\n",
    "    key = 'mewd_self_'+key_suffixes[i]\n",
    "    p_om2 = np.array([])\n",
    "    p_om = np.array([])\n",
    "    for j in range(n_merger):\n",
    "        p_om2 = np.concatenate( (p_om2, mewd_data_om[key][j]) )\n",
    "        p_om = np.concatenate( (p_om, mewd_data_om2[key][j]) )\n",
    "    mewd_om2_self_percs[i] = np.percentile(p_om2, [16,50,84])\n",
    "    mewd_om_self_percs[i] = np.percentile(p_om, [16,50,84])\n",
    "\n",
    "# Labels and limits\n",
    "for i in range(4):\n",
    "    axs[i].set_xlabel(r'$\\delta($'+ylabels[i]+r'$_{\\mathrm{OM}})$',\n",
    "        fontsize=label_fs)\n",
    "    axs[i].set_ylabel(r'$\\delta($'+ylabels[i]+r'$_{\\mathrm{OM2}})$',\n",
    "        fontsize=label_fs)\n",
    "    if i == 0:\n",
    "        axs[i].set_xlim(beta_range)\n",
    "        axs[i].set_ylim(beta_range)\n",
    "    else:\n",
    "        axs[i].set_xlim(vdisp_range)\n",
    "        axs[i].set_ylim(vdisp_range)\n",
    "\n",
    "    # Self-consistent errors\n",
    "    axs[i].axline(xy1 = [0,0], slope=1., color='k', ls='--')\n",
    "    axs[i].axvline(mewd_om_self_percs[i,1], color='Black', ls='solid')\n",
    "    axs[i].axvspan(mewd_om_self_percs[i,0], mewd_om_self_percs[i,2], \n",
    "        color='Black', alpha=0.25)\n",
    "    axs[i].axhline(mewd_om2_self_percs[i,1], color='Black', ls='solid')\n",
    "    axs[i].axhspan(mewd_om2_self_percs[i,0], mewd_om2_self_percs[i,2], \n",
    "        color='Black', alpha=0.25)\n",
    "    for fac in [2,4]:\n",
    "        axs[i].axvline(fac*mewd_om_self_percs[i,1], color='Gray', \n",
    "            ls='dotted')\n",
    "        axs[i].axhline(fac*mewd_om2_self_percs[i,1], color='Gray', \n",
    "            ls='dotted')\n",
    "        \n",
    "    # Scale and ticks\n",
    "    axs[i].set_xscale('log')\n",
    "    axs[i].set_yscale('log')\n",
    "    axs[i].xaxis.set_major_formatter(plt.FormatStrFormatter('%.0f'))\n",
    "    axs[i].yaxis.set_major_formatter(plt.FormatStrFormatter('%.0f'))\n",
    "    axs[i].tick_params(axis='both', labelsize=ticklabel_fs)\n",
    "    # axs[i].set_xticks(ticks[i])\n",
    "    # axs[i].set_yticks(ticks[i])\n",
    "\n",
    "    # One-to-one line\n",
    "    if one_to_one_line_numbers:\n",
    "        n_om2 = 0\n",
    "        n_om = 0\n",
    "        key = 'mewd_'+key_suffixes[i]\n",
    "        for j in range(n_merger):\n",
    "            om2_gt_om = np.median( mewd_data_om[key][j] ) > \\\n",
    "                        np.median( mewd_data_om2[key][j] )\n",
    "            if om2_gt_om:\n",
    "                n_om2 += 1\n",
    "            else:\n",
    "                n_om += 1\n",
    "\n",
    "        axs[i].text(0.925, 0.825, str(n_om), transform=axs[i].transAxes, \n",
    "            ha='center', va='center', fontsize=ticklabel_fs)\n",
    "        axs[i].text(0.825, 0.925, str(n_om2), transform=axs[i].transAxes, \n",
    "            ha='center', va='center', fontsize=ticklabel_fs)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.3, right=0.91)\n",
    "fig.savefig('./fig/delta_comparison_om_om2.pdf', dpi=300)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "nteract": {
   "version": "0.28.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
