{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "#\n",
    "# TITLE - jeans_through_time.ipynb\n",
    "# AUTHOR - James Lane\n",
    "# PROJECT - tng-dfs\n",
    "#\n",
    "# ------------------------------------------------------------------------\n",
    "#\n",
    "# Docstring:\n",
    "'''Examine candidate remnants and z=0 stellar halos in the context of the Jeans \n",
    "equation\n",
    "'''\n",
    "\n",
    "__author__ = \"James Lane\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "\n",
    "## Basic\n",
    "import numpy as np\n",
    "import sys, os, pdb\n",
    "import h5py\n",
    "import glob\n",
    "import copy\n",
    "import dill as pickle\n",
    "from astropy import units as apu\n",
    "\n",
    "## Matplotlib\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "## Galpy\n",
    "from galpy import orbit, potential, df\n",
    "import galpy.util\n",
    "\n",
    "## Scipy\n",
    "import scipy.interpolate\n",
    "\n",
    "sys.path.insert(0,'../../src/')\n",
    "from tng_dfs import util as putil\n",
    "from tng_dfs import tree as ptree\n",
    "from tng_dfs import cutout as pcutout\n",
    "from tng_dfs.util import get\n",
    "\n",
    "### Notebook setup\n",
    "%matplotlib inline\n",
    "plt.style.use('../../src/mpl/project.mplstyle') # This must be exactly here\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keywords\n",
    "cdict = putil.load_config_to_dict()\n",
    "keywords = ['DATA_DIR','RO','VO','ZO','LITTLE_H']\n",
    "data_dir,ro,vo,zo,h = putil.parse_config_dict(cdict,keywords)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_spherical_jeans_quantities(orbs,pe,r_range=[0,100],n_bin=10,\n",
    "    norm_by_galpy_scale_units=False,calculate_pe_with_pot=False,ro=ro,vo=vo):\n",
    "    '''calculate_spherical_jeans_quantities:\n",
    "    \n",
    "    Calculate the quantities used in the spherical Jeans equation.\n",
    "    \n",
    "    Args:\n",
    "        orbs (Orbits) - Orbits object containing particles / kinematic sample\n",
    "        pe (array) - Potential energy of each particle in the sample\n",
    "        r_range (optional, list) - Range of radii to consider, in kpc \n",
    "            [default: [0,100]]\n",
    "        n_bin (optional, int) - Number of bins to use in calculating Jeans\n",
    "            equation, note derivative quantities will be calculated with \n",
    "            n_bin+1 bins [default: 10]\n",
    "        norm_by_galpy_scale_units (optional, bool) - If True, normalize the\n",
    "            Jeans equation by galpy scale units [default: False]\n",
    "        calculate_pe_with_pot (optional, bool) - If True, calculate the \n",
    "            potential at the bin centers, rather than the mean potential of the \n",
    "            orbs in the bin [default: False]\n",
    "        ro (optional, float) - Distance scale in kpc [default: 8.275]\n",
    "        vo (optional, float) - Velocity scale in km/s [default: 220.]\n",
    "    \n",
    "    Returns:\n",
    "        qs (tuple) - Tuple of kinematic quantities used to calculate Jeans\n",
    "            equation, output from calculate_spherical_jeans_quantities, \n",
    "            in order: dnuvr2dr,dphidr,nu,vr2,vp2,vt2,rs\n",
    "    '''\n",
    "    orbs = copy.deepcopy(orbs)\n",
    "    orbs.turn_physical_on(ro=ro,vo=vo)\n",
    "\n",
    "    ## Determine bins for kinematic properties\n",
    "    \n",
    "    # First need bins for derivatives, one more bin than for the data itself, \n",
    "    # since we're taking derivatives\n",
    "    n_dr_bin = n_bin+1\n",
    "    dr_bin_edge = np.linspace(r_range[0],r_range[1],n_dr_bin+1)\n",
    "    dr_bin_cents = (dr_bin_edge[1:]+dr_bin_edge[:-1])/2\n",
    "    # dr_bin_delta = dr_bin_edge[1:]-dr_bin_edge[:-1]\n",
    "\n",
    "    # One fewer bin for data, since we're taking derivatives. The edges are \n",
    "    # the derivative bin centers\n",
    "    bin_edge = copy.deepcopy(dr_bin_cents)\n",
    "    bin_cents = (bin_edge[1:]+bin_edge[:-1])/2\n",
    "    # bin_delta = bin_edge[1:]-bin_edge[:-1]\n",
    "\n",
    "    # Bin the data, derivative quantities first\n",
    "    nuvr2 = np.zeros_like(dr_bin_cents)\n",
    "    phi = np.zeros_like(dr_bin_cents)\n",
    "    # Non-derivative quantities\n",
    "    nu = np.zeros_like(bin_cents)\n",
    "    vr2 = np.zeros_like(bin_cents)\n",
    "    vt2 = np.zeros_like(bin_cents)\n",
    "    vp2 = np.zeros_like(bin_cents)\n",
    "\n",
    "    rs = orbs.r(use_physical=True).to(apu.kpc).value\n",
    "    pe = pe.to(apu.km**2/apu.s**2).value\n",
    "    # pe = potential.evaluatePotentials(pot,orbs.R(),orbs.z(),\n",
    "    #     use_physical=True).to(apu.km**2/apu.s**2).value\n",
    "    # pe_bin_cents = potential.evaluatePotentials(pot,dr_bin_cents*apu.kpc,\n",
    "    #     0*apu.kpc,use_physical=True).to(apu.km**2/apu.s**2).value\n",
    "\n",
    "    # Derivative quantities\n",
    "    for i in range(len(dr_bin_cents)):\n",
    "        bin_mask = (rs>=dr_bin_edge[i]) & (rs<dr_bin_edge[i+1])\n",
    "        n_in_bin = np.sum( bin_mask )\n",
    "        bin_vol = 4*np.pi/3*(dr_bin_edge[i+1]**3-dr_bin_edge[i]**3)\n",
    "        dr_nu = n_in_bin/bin_vol\n",
    "        dr_vr2 = np.mean(orbs.vr(use_physical=True).to(apu.km/apu.s).value\n",
    "            [bin_mask]**2.)\n",
    "        if calculate_pe_with_pot:\n",
    "            phi[i] = pe_bin_cents[i]\n",
    "        else:\n",
    "            phi[i] = np.mean(pe[bin_mask])\n",
    "        nuvr2[i] = dr_nu*dr_vr2\n",
    "    dphidr = np.diff(phi)/np.diff(dr_bin_cents)\n",
    "    dnuvr2dr = np.diff(nuvr2)/np.diff(dr_bin_cents)\n",
    "\n",
    "    # Non-derivative quantities\n",
    "    for i in range(len(bin_cents)):\n",
    "        bin_mask = (rs>=bin_edge[i]) & (rs<bin_edge[i+1])\n",
    "        n_in_bin = np.sum( bin_mask )\n",
    "        bin_vol = 4*np.pi/3*(bin_edge[i+1]**3-bin_edge[i]**3)\n",
    "        nu[i] = n_in_bin/bin_vol\n",
    "        vr2[i] = np.mean(orbs.vr(use_physical=True).to(apu.km/apu.s).value\n",
    "            [bin_mask]**2.)\n",
    "        vp2[i] = np.mean(orbs.vtheta(use_physical=True).to(apu.km/apu.s).value\n",
    "            [bin_mask]**2.)\n",
    "        vt2[i] = np.mean(orbs.vT(use_physical=True).to(apu.km/apu.s).value\n",
    "            [bin_mask]**2.)\n",
    "    \n",
    "    # Normalize densities by number of orbits so they're proper number \n",
    "    # densities\n",
    "    nu /= len(orbs)\n",
    "    dnuvr2dr /= len(orbs)\n",
    "\n",
    "    if norm_by_galpy_scale_units:\n",
    "        nu = nu*(ro**3)\n",
    "        vr2 = vr2/(vo**2)\n",
    "        vp2 = vp2/(vo**2)\n",
    "        vt2 = vt2/(vo**2)\n",
    "        bin_cents = bin_cents/ro\n",
    "        dphidr = dphidr*ro/(vo**2)\n",
    "        dnuvr2dr = dnuvr2dr*(ro**4)/(vo**2)\n",
    "\n",
    "    return dnuvr2dr,dphidr,nu,vr2,vp2,vt2,bin_cents\n",
    "\n",
    "def calculate_spherical_jeans(orbs,pe,n_bootstrap=1,r_range=[0,100],n_bin=10,\n",
    "    norm_by_galpy_scale_units=False,norm_by_nuvr2_r=True,\n",
    "    calculate_pe_with_pot=False,return_kinematics=True,ro=ro,vo=vo):\n",
    "    '''calculate_spherical_jeans:\n",
    "\n",
    "    Calculate the spherical Jeans equation for a given kinematic sample\n",
    "\n",
    "    Args:\n",
    "        orbs (Orbits) - Orbits object containing particles / kinematic sample\n",
    "        pe (array) - Potential energy of each particle in the sample\n",
    "        n_bootstrap (optional, int) - Number of bootstrap samples to calculate \n",
    "            the Jeans equation for, if 1, then don't bootstrap [default: 1]\n",
    "        r_range (optional, list) - Range of radii to consider, in kpc \n",
    "            [default: [0,100]]\n",
    "        n_bin (optional, int) - Number of bins to use in calculating Jeans\n",
    "            equation, note derivative quantities will be calculated with \n",
    "            n_bin+1 bins [default: 10]\n",
    "        norm_by_galpy_scale_units (optional, bool) - If True, normalize the\n",
    "            Jeans equation by galpy scale units [default: False]\n",
    "        norm_by_nuvr2_r (optional, bool) - If True, normalize the Jeans equation\n",
    "            by nu*vr^2/r [default: True]\n",
    "        calculate_pe_with_pot (optional, bool) - If True, calculate the \n",
    "            potential at the bin centers, rather than the mean potential of the \n",
    "            orbs in the bin [default: False]\n",
    "        return_kinematics (optional, bool) - If True, return the kinematics\n",
    "            used to calculate the Jeans equation [default: True]\n",
    "        ro (optional, float) - Distance scale in kpc [default: 8.275]\n",
    "        vo (optional, float) - Velocity scale in km/s [default: 220.]\n",
    "    \n",
    "    Returns:\n",
    "        J (np.ndarray) - Jeans equation, may be normalized\n",
    "        rs (np.ndarray) - Radii at which Jeans equation is calculated\n",
    "        qs (tuple) - Tuple of kinematic quantities used to calculate Jeans\n",
    "            equation, output from calculate_spherical_jeans_quantities, \n",
    "            in order: dnuvr2dr,dphidr,nu,vr2,vp2,vt2,rs\n",
    "    '''\n",
    "    # Compute the quantities for the spherical Jeans equation\n",
    "    if n_bootstrap>1:\n",
    "        qs = np.zeros((7,n_bootstrap,n_bin))\n",
    "        for i in range(n_bootstrap):\n",
    "            # Random bootstrap index\n",
    "            indx = np.random.choice(np.arange(len(orbs),dtype=int),\n",
    "                size=len(orbs)-1,replace=False)\n",
    "            # Bootstrap sample\n",
    "            _qs = calculate_spherical_jeans_quantities(orbs[indx],pe[indx],\n",
    "                r_range=r_range,n_bin=n_bin,\n",
    "                norm_by_galpy_scale_units=norm_by_galpy_scale_units,\n",
    "                calculate_pe_with_pot=calculate_pe_with_pot,ro=ro,vo=vo)\n",
    "            qs[:,i,:] = _qs\n",
    "    else:\n",
    "        qs = calculate_spherical_jeans_quantities(orbs,pe,r_range=r_range,\n",
    "            n_bin=n_bin,norm_by_galpy_scale_units=norm_by_galpy_scale_units,\n",
    "            calculate_pe_with_pot=calculate_pe_with_pot,ro=ro,vo=vo)\n",
    "\n",
    "    dnuvr2dr,dphidr,nu,vr2,vp2,vt2,rs = qs\n",
    "\n",
    "    # Compute the Jeans equation\n",
    "    J = nu*(dphidr + (2*vr2-vp2-vt2)/rs) + dnuvr2dr\n",
    "\n",
    "    # Normalize by nu*vr^2/r if desired. Note that this returns the same \n",
    "    # answer regardless of whether using physical or galpy units.\n",
    "    if norm_by_nuvr2_r and not norm_by_galpy_scale_units:\n",
    "        J = J/(nu*vr2/rs)\n",
    "\n",
    "    if return_kinematics:\n",
    "        return J,rs,qs\n",
    "    else:\n",
    "        return J,rs\n",
    "\n",
    "def plot_jeans_diagnostics(Js,rs,qs,norm_by_nuvr2_r=True):\n",
    "\n",
    "    data_color = 'Black'\n",
    "    data_linewidth = 2.\n",
    "    truth_color = 'Red'\n",
    "    plot_spans = True\n",
    "    if np.ndim(Js)==1:\n",
    "        plot_spans = False\n",
    "\n",
    "    fig = plt.figure(figsize=(12,8))\n",
    "    gs = fig.add_gridspec(nrows=4,ncols=3)\n",
    "    axs = np.array([fig.add_subplot(gs[:2,0]),\n",
    "                    fig.add_subplot(gs[:2,1]),\n",
    "                    fig.add_subplot(gs[:2,2]),\n",
    "                    fig.add_subplot(gs[2:,0]),\n",
    "                    fig.add_subplot(gs[2,1]),\n",
    "                    fig.add_subplot(gs[3,1]),\n",
    "                    fig.add_subplot(gs[2:,2])\n",
    "                    ])\n",
    "    # axs = fig.subplots(nrows=2,ncols=3).flatten()\n",
    "\n",
    "    # J in the first panel\n",
    "    lJ,mJ,uJ = np.percentile(np.atleast_2d(Js), [16,50,84], axis=0)\n",
    "    axs[0].plot(rs, mJ, color=data_color, linewidth=data_linewidth)\n",
    "    if plot_spans:\n",
    "        axs[0].fill_between(rs, lJ, uJ, color='Black', alpha=0.25)\n",
    "    axs[0].axhline(0, color='Black', linestyle='--', linewidth=0.5)\n",
    "    axs[0].set_xlim(0,50)\n",
    "    axs[0].set_xlabel('r [kpc]')\n",
    "    if norm_by_nuvr2_r:\n",
    "        axs[0].set_ylabel(r'$J / (\\nu \\bar{v_{r}^{2}} / r)$')\n",
    "    else:\n",
    "        axs[0].set_ylabel('$J$')\n",
    "\n",
    "    # Density in the second upper panel\n",
    "    fiducial_alphas = [1,2,3,4,5]\n",
    "    lnu,mnu,unu = np.percentile(np.atleast_2d(qs[2]), [16,50,84], axis=0)\n",
    "    axs[1].plot(rs, mnu, color=data_color, linewidth=data_linewidth)\n",
    "    if plot_spans:\n",
    "        axs[1].fill_between(rs, unu, lnu, color='Black', alpha=0.25)\n",
    "    for alpha in fiducial_alphas:\n",
    "        _norm = mnu[0]/rs[0]**-alpha\n",
    "        axs[1].plot(rs, _norm*rs**-alpha, color='DodgerBlue', \n",
    "            linewidth=0.5, linestyle='--')\n",
    "    # axs[1].set_xlim(0,50)\n",
    "    axs[1].set_xscale('log')\n",
    "    axs[1].set_yscale('log')\n",
    "    axs[1].set_xlabel(r'r [kpc]')\n",
    "    axs[1].set_ylabel(r'$\\nu$')\n",
    "\n",
    "    # Beta in the third panel\n",
    "    beta = 1 - (qs[4]+qs[5])/(2*qs[3])\n",
    "    lbeta,mbeta,ubeta = np.percentile(np.atleast_2d(beta), [16,50,84], axis=0)\n",
    "    axs[2].plot(rs, mbeta, color=data_color, linewidth=data_linewidth)\n",
    "    if plot_spans:\n",
    "        axs[2].fill_between(rs, ubeta, lbeta, color='Black', alpha=0.25)\n",
    "    axs[2].axhline(0, color='Black', linestyle='--', linewidth=0.5)\n",
    "    axs[2].set_xlim(0,50)\n",
    "    axs[2].set_xlabel(r'r [kpc]')\n",
    "    axs[2].set_ylabel(r'$\\beta$')\n",
    "\n",
    "    # Radial velocity dispersions in the fourth panel, polar and azimuthal \n",
    "    # in the fifth upper/lower panels\n",
    "    colors = ['DodgerBlue','Crimson','DarkOrange']\n",
    "    v2_names = [r'$\\bar{v_{r}^{2}}$',\n",
    "                r'$\\bar{v_{\\phi}^{2}}$',\n",
    "                r'$\\bar{v_{\\theta}^{2}}$',]\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            lv2,mv2,uv2 = np.percentile(np.atleast_2d(qs[j+3]), [16,50,84], \n",
    "                axis=0)\n",
    "            if i == j:\n",
    "                axs[i+3].plot(rs, mv2, color=colors[j], \n",
    "                    linewidth=data_linewidth+2, zorder=2)\n",
    "                if plot_spans:\n",
    "                    axs[i+3].fill_between(rs, uv2, lv2, color=colors[i], \n",
    "                        alpha=0.25, zorder=1)\n",
    "            else:\n",
    "                axs[i+3].plot(rs, mv2, color=colors[j], alpha=1., \n",
    "                    linestyle='--', linewidth=1., zorder=3)\n",
    "        axs[i+3].set_xlim(0,50)\n",
    "        if i in [0,2]:\n",
    "            axs[i+3].set_xlabel(r'r [kpc]')\n",
    "        axs[i+3].set_ylabel(v2_names[i])\n",
    "        axs[i+3].set_yscale('log')\n",
    "    \n",
    "    # dphi/dr in the sixth panel\n",
    "    ldphidr,mdphidr,udphidr = np.percentile(np.atleast_2d(qs[1]), [16,50,84], \n",
    "        axis=0)\n",
    "    axs[6].plot(rs, mdphidr, color=data_color, linewidth=data_linewidth)\n",
    "    if plot_spans:\n",
    "        axs[6].fill_between(rs, udphidr, ldphidr, color='Black', alpha=0.25)\n",
    "    axs[6].set_xlim(0,50)\n",
    "    axs[6].set_xlabel(r'r [kpc]')\n",
    "    axs[6].set_ylabel(r'$\\mathrm{d}\\Phi/\\mathrm{d}r$')\n",
    "    axs[6].set_yscale('log')\n",
    "    \n",
    "    return fig,axs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Setup & Milky Way Analogs from TNG50-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL\n",
    "baseURL = 'http://www.tng-project.org/api/'\n",
    "# Get list of simulations\n",
    "r = get(baseURL)\n",
    "sim_names = [sim['name'] for sim in r['simulations']]\n",
    "tng50_indices = [sim_names.index('TNG50-'+str(i+1)) for i in range(4)]\n",
    "# Choose the lowest resolution tng50 run\n",
    "tng50_urls = [r['simulations'][i]['url'] for i in tng50_indices]\n",
    "tng50_url = tng50_urls[0]\n",
    "\n",
    "# Get the simulation, snapshots, snapshot redshifts\n",
    "sim = get( tng50_url )\n",
    "snaps = get( sim['snapshots'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../parse_sublink_trees/data/all_major_list.pkl','rb') as f:\n",
    "    all_major_list = pickle.load(f)\n",
    "##wi\n",
    "\n",
    "# Number of primary MW analogs under consideration\n",
    "n_mw = len(all_major_list)\n",
    "\n",
    "# Number that we'll actually analyse for now\n",
    "n_do = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many primaries we actually have data for\n",
    "for i in range(n_mw):\n",
    "    if i > 3: continue\n",
    "\n",
    "    # Get primary particle properties\n",
    "    major_dict = all_major_list[i]\n",
    "    major_list = major_dict['major_list']\n",
    "    n_major = major_dict['n_major']\n",
    "\n",
    "    has_data = np.zeros(n_major+1,dtype=bool)\n",
    "    for j in range(n_major+1):\n",
    "        if j == 0:\n",
    "            assert major_list[j]['is_primary'], 'Index 0 not primary'\n",
    "        \n",
    "        major_snaps = major_list[j]['snaps']\n",
    "        major_subfind_ids = major_list[j]['subfind_ids']\n",
    "        has_file = np.zeros(len(major_snaps),dtype=bool)\n",
    "        for k in range(len(major_snaps)):\n",
    "            snap_path = data_dir+'cutouts/snap_'+str(major_snaps[k])+'/'\n",
    "            snap_filename = snap_path+'cutout_'+str(major_subfind_ids[k])+\\\n",
    "                '.hdf5'\n",
    "            has_file[k] = os.path.isfile(snap_filename)\n",
    "        \n",
    "        # Report the max and min snapshot for which we have data\n",
    "        print('Primary '+str(i)+', major '+str(j))\n",
    "        if not has_file.any():\n",
    "            print('No data for this major')\n",
    "            continue\n",
    "        print('Max snapshot: '+str(major_snaps.max()))\n",
    "        print('Min snapshot: '+str(major_snaps.min()))\n",
    "        print('Max snapshot saved: '+str(major_snaps[has_file].max()))\n",
    "        print('Min snapshot saved: '+str(major_snaps[has_file].min()))\n",
    "        print('--------\\n')\n",
    "    \n",
    "    \n",
    "        if has_file.all(): has_data[j] = True\n",
    "    print('--------------------------------')\n",
    "    if has_data.all():\n",
    "        print('Primary '+str(i)+' has data for all majors')\n",
    "    print('--------------------------------\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get primary particle properties\n",
    "major_dict = all_major_list[0]\n",
    "subfind_id = major_dict['major_list'][0]['subfind_ids'][0]\n",
    "snap = major_dict['major_list'][0]['snaps'][0]\n",
    "primary_path = data_dir+'cutouts/snap_'+str(snap)+'/'\n",
    "primary_filename = primary_path+'cutout_'+str(subfind_id)+'.hdf5'\n",
    "cutout1 = pcutout.TNGCutout(primary_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout1.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get primary particle properties\n",
    "major_dict = all_major_list[0]\n",
    "subfind_id = major_dict['major_list'][0]['subfind_ids'][1]\n",
    "snap = major_dict['major_list'][0]['snaps'][1]\n",
    "primary_path = data_dir+'cutouts/snap_'+str(snap)+'/'\n",
    "primary_filename = primary_path+'cutout_'+str(subfind_id)+'.hdf5'\n",
    "cutout2 = pcutout.TNGCutout(primary_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cr in cutout2.header['CutoutRequest'].split('+'):\n",
    "    c = cr.split('=')\n",
    "    print(c[0],c[1].split(','))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spherical Jeans equation\n",
    "\n",
    "Will compute the spherical Jeans equation to see how well it is satisfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_mw):\n",
    "    if i > n_do: continue\n",
    "\n",
    "    # Get primary particle properties\n",
    "    major_dict = all_major_list[i]\n",
    "    primary_z0_subfind_id = major_dict['primary_z0_subfind_id']\n",
    "    primary_path = data_dir+'cutouts/snap_99/'\n",
    "    primary_filename = primary_path+'cutout_'+str(primary_z0_subfind_id)+'.hdf5'\n",
    "    \n",
    "    # Make the TNGCutout instance\n",
    "    cutout = pcutout.TNGCutout(primary_filename)\n",
    "    # Bounding radii for centering / rectifying in kpc\n",
    "    vcen_rmin = 0.\n",
    "    vcen_rmax = 5.\n",
    "    rot_rmin = 2.\n",
    "    rot_rmax = 10.\n",
    "    # Center and rectify\n",
    "    cutout.center_and_rectify(cen_ptype='PartType4', vcen_ptype='PartType4',\n",
    "        vcen_rmin=vcen_rmin, vcen_rmax=vcen_rmax, rot_ptype='PartType4', \n",
    "        rot_rmin=rot_rmin, rot_rmax=rot_rmax)\n",
    "    \n",
    "    # Get properties, energy, angular momentum\n",
    "    orbs = cutout.get_orbs('PartType4')\n",
    "    rs = orbs.r().value\n",
    "    vels = cutout.get_velocities('PartType4', physical=True)\n",
    "    pot = cutout.get_potential_energy('PartType4', physical=True)\n",
    "    orbs = cutout.get_orbs('PartType4')\n",
    "    kin = 0.5*np.sum(np.square(vels),axis=1)\n",
    "    E = (pot+kin)\n",
    "    J,Jz,Jp = cutout.get_J_Jz_Jp('PartType4',physical=True)\n",
    "    cutout.get_E_Jcirc_spline('PartType4',angmom='J')\n",
    "    Jcirc = cutout.Jcirc(E)\n",
    "    Enorm = E/np.abs(E).max()\n",
    "    Jz_Jcirc = Jz / Jcirc\n",
    "    Jp_Jcirc = Jp / Jcirc\n",
    "    \n",
    "    # Make the figure\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    ### Jz/Jc - Enorm\n",
    "    ax.set_aspect('auto')\n",
    "    hist,_,_ = np.histogram2d(Jz_Jcirc, Enorm, bins=20, range=[[-1,1],[-1,0]])\n",
    "    hist = np.log10(np.rot90(hist))\n",
    "    im = ax.imshow(hist, cmap='Blues', extent=(-1,1,-1,0), aspect='auto',\n",
    "                       vmin=2, vmax=5)\n",
    "    cbar = plt.colorbar(im, ax=ax)\n",
    "    cbar.set_label('log N')\n",
    "    ax.set_xlabel(r'$j_{z}/j_{circ}$', fontsize=16)\n",
    "    ax.set_ylabel(r'$E/ \\vert E_{norm} \\vert$', fontsize=16)\n",
    "    \n",
    "    # Lines\n",
    "    Jz_Jcirc_halo_bound = 0.5\n",
    "    Jz_Jcirc_disk_bound = 0.8\n",
    "    Enorm_bulge_bound = -0.75\n",
    "    ax.axvline(Jz_Jcirc_halo_bound, color='Black', linestyle='dashed')\n",
    "    ax.axvline(Jz_Jcirc_disk_bound, color='Black', linestyle='dashed')\n",
    "    ax.plot([-1,Jz_Jcirc_halo_bound], [Enorm_bulge_bound,Enorm_bulge_bound], \n",
    "            color='Black', linestyle='dashed')\n",
    "    \n",
    "    # Labels\n",
    "    ax.annotate('Halo', xy=(0.02,0.95), xycoords='axes fraction', \n",
    "                    fontsize=12)\n",
    "    ax.annotate('Bulge', xy=(0.02,0.2), xycoords='axes fraction', \n",
    "                    fontsize=12)\n",
    "    ax.annotate('Thick Disk', xy=(0.77,0.75), xycoords='axes fraction', \n",
    "                fontsize=12, rotation='vertical')\n",
    "    ax.annotate('Thin Disk', xy=(0.92,0.75), xycoords='axes fraction', \n",
    "                fontsize=12, rotation='vertical')\n",
    "    \n",
    "    fig.suptitle('primary z=0 subfind id: '+str(primary_z0_subfind_id))\n",
    "    figname = './fig/Enorm_Jcirc_primary_halo_'+str(primary_z0_subfind_id)+'.png'\n",
    "    fig.savefig(figname, dpi=300)\n",
    "    # plt.close(fig)\n",
    "    # fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 10\n",
    "norm_by_nuvr2_r = True\n",
    "norm_by_galpy_scale_units = False\n",
    "\n",
    "for i in range(n_mw):\n",
    "    if i > n_do: continue\n",
    "\n",
    "    # Get primary particle properties\n",
    "    major_dict = all_major_list[i]\n",
    "    primary_z0_subfind_id = major_dict['primary_z0_subfind_id']\n",
    "    primary_path = data_dir+'cutouts/snap_99/'\n",
    "    primary_filename = primary_path+'cutout_'+str(primary_z0_subfind_id)+'.hdf5'\n",
    "    \n",
    "    # Make the TNGCutout instance\n",
    "    cutout = pcutout.TNGCutout(primary_filename)\n",
    "    # Bounding radii for centering / rectifying in kpc\n",
    "    vcen_rmin = 0.\n",
    "    vcen_rmax = 5.\n",
    "    rot_rmin = 2.\n",
    "    rot_rmax = 10.\n",
    "    # Center and rectify\n",
    "    cutout.center_and_rectify(cen_ptype='PartType4', vcen_ptype='PartType4',\n",
    "        vcen_rmin=vcen_rmin, vcen_rmax=vcen_rmax, rot_ptype='PartType4', \n",
    "        rot_rmin=rot_rmin, rot_rmax=rot_rmax)\n",
    "    \n",
    "    # Get properties, energy, angular momentum\n",
    "    orbs = cutout.get_orbs('PartType4')\n",
    "    rs = orbs.r().value\n",
    "    vels = cutout.get_velocities('PartType4', physical=True)\n",
    "    pot = cutout.get_potential_energy('PartType4', physical=True)\n",
    "    kin = 0.5*np.sum(np.square(vels),axis=1)\n",
    "    E = (pot+kin)\n",
    "    J,Jz,Jp = cutout.get_J_Jz_Jp('PartType4',physical=True)\n",
    "    cutout.get_E_Jcirc_spline('PartType4',angmom='J')\n",
    "    Jcirc = cutout.Jcirc(E)\n",
    "    Enorm = E/np.abs(E).max()\n",
    "    Jz_Jcirc = Jz / Jcirc\n",
    "    Jp_Jcirc = Jp / Jcirc\n",
    "    \n",
    "    # Mask the halo using these quantities\n",
    "    Jz_Jcirc_halo_bound = 0.5\n",
    "    Enorm_bulge_bound = -0.75\n",
    "    halo_mask = (Jz_Jcirc < Jz_Jcirc_halo_bound) &\\\n",
    "                (Enorm > Enorm_bulge_bound)\n",
    "    \n",
    "    # Compute the Jeans equation quantities\n",
    "    Js,rs,qs = calculate_spherical_jeans(orbs[halo_mask],pot[halo_mask],\n",
    "        n_bootstrap=1, r_range=[0,50], n_bin=nbins, \n",
    "        norm_by_nuvr2_r=norm_by_nuvr2_r,\n",
    "        norm_by_galpy_scale_units=norm_by_galpy_scale_units)\n",
    "\n",
    "    # Make the Jeans equation figure\n",
    "    fig,axs = plot_jeans_diagnostics(Js,rs,qs)\n",
    "    fig.suptitle('primary z=0 subfind id: '+str(primary_z0_subfind_id))\n",
    "    fig.tight_layout()\n",
    "    figname = './fig/jeans_diagnostics_primary_halo_'+str(primary_z0_subfind_id)+'.png'\n",
    "    fig.savefig(figname, dpi=300)\n",
    "    # plt.close(fig)\n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 10\n",
    "norm_by_nuvr2_r = True\n",
    "norm_by_galpy_scale_units = False\n",
    "snap_analyze = np.array([99,91,84,78,72,67,59,50,40,33,25,21])\n",
    "redshift_analyze = np.array([0.,0.1,0.2,0.3,0.4,0.5,0.7,1.0,1.5,2.0,3.0,4.0])\n",
    "n_snap_analyze = len(snap_analyze)\n",
    "\n",
    "for i in range(n_mw):\n",
    "    if i > n_do: continue\n",
    "\n",
    "    # Get primary particle properties\n",
    "    major_dict = all_major_list[i]\n",
    "    major_list = major_dict['major_list']\n",
    "    analyze_mask = np.isin(major_list[0]['snaps'],snap_analyze)\n",
    "    assert (major_list[0]['snaps'][analyze_mask] == snap_analyze).all()\n",
    "    primary_snaps = major_list[0]['snaps'][analyze_mask]\n",
    "    primary_redshift = np.zeros(n_snap_analyze)\n",
    "    primary_subfind_ids = major_list[0]['subfind_ids'][analyze_mask]\n",
    "    primary_z0_subfind_id = major_dict['primary_z0_subfind_id']\n",
    "    print('Analyzing primary z=0 subfind id: '+str(primary_z0_subfind_id))\n",
    "    print('------------------------------------------')\n",
    "\n",
    "    # Initialize arrays\n",
    "    J_abs_weighted = np.zeros(n_snap_analyze)\n",
    "    J_values = np.zeros((n_snap_analyze,nbins))\n",
    "\n",
    "    for j in range(n_snap_analyze):\n",
    "        primary_path = data_dir+'cutouts/snap_'+str(primary_snaps[j])+'/'\n",
    "        primary_filename = primary_path+'cutout_'+str(primary_subfind_ids[j])+'.hdf5'\n",
    "        print('Analyzing primary subfind id: '+str(primary_subfind_ids[j]))\n",
    "    \n",
    "        # Make the TNGCutout instance\n",
    "        cutout = pcutout.TNGCutout(primary_filename)\n",
    "        primary_redshift[j] = cutout.header['Redshift']\n",
    "        # Bounding radii for centering / rectifying in kpc\n",
    "        vcen_rmin = 0.\n",
    "        vcen_rmax = 5.\n",
    "        rot_rmin = 2.\n",
    "        rot_rmax = 10.\n",
    "        # Center and rectify\n",
    "        cutout.center_and_rectify(cen_ptype='PartType4', vcen_ptype='PartType4',\n",
    "            vcen_rmin=vcen_rmin, vcen_rmax=vcen_rmax, rot_ptype='PartType4', \n",
    "            rot_rmin=rot_rmin, rot_rmax=rot_rmax)\n",
    "    \n",
    "        # Get properties, energy, angular momentum\n",
    "        orbs = cutout.get_orbs('PartType4')\n",
    "        rs = orbs.r().value\n",
    "        vels = cutout.get_velocities('PartType4', physical=True)\n",
    "        pot = cutout.get_potential_energy('PartType4', physical=True)\n",
    "        kin = 0.5*np.sum(np.square(vels),axis=1)\n",
    "        E = (pot+kin)\n",
    "        J,Jz,Jp = cutout.get_J_Jz_Jp('PartType4',physical=True)\n",
    "        cutout.get_E_Jcirc_spline('PartType4',angmom='J')\n",
    "        Jcirc = cutout.Jcirc(E)\n",
    "        Enorm = E/np.abs(E).max()\n",
    "        Jz_Jcirc = Jz / Jcirc\n",
    "        Jp_Jcirc = Jp / Jcirc\n",
    "        \n",
    "        # Mask the halo using these quantities\n",
    "        Jz_Jcirc_halo_bound = 0.5\n",
    "        Enorm_bulge_bound = -0.75\n",
    "        halo_mask = (Jz_Jcirc < Jz_Jcirc_halo_bound) &\\\n",
    "                    (Enorm > Enorm_bulge_bound)\n",
    "    \n",
    "        # Compute the Jeans equation quantities\n",
    "        Js,rs,qs = calculate_spherical_jeans(orbs[halo_mask],pot[halo_mask],\n",
    "            n_bootstrap=1, r_range=[0,50], n_bin=nbins, \n",
    "            norm_by_nuvr2_r=norm_by_nuvr2_r,\n",
    "            norm_by_galpy_scale_units=norm_by_galpy_scale_units)\n",
    "        \n",
    "        J_weights = qs[2]*rs**2 # density * r^2\n",
    "        J_abs_weighted[j] = np.sum(np.abs(Js)*J_weights)/np.sum(J_weights)\n",
    "        J_values[j,:] = Js\n",
    "\n",
    "    # Make the Jeans equation figure\n",
    "    fig = plt.figure()\n",
    "    axs = fig.subplots(nrows=2,ncols=1)\n",
    "    axs[0].plot(primary_redshift,J_abs_weighted,'o-')\n",
    "    axs[0].axhline(0.,color='k',ls='--')\n",
    "    axs[0].set_xlabel('Redshift')\n",
    "    axs[0].set_ylabel(r'weighted $|J_{0}|$')\n",
    "\n",
    "    for j in range(n_snap_analyze):\n",
    "        axs[1].plot(rs,J_values[j,:],'-',color=matplotlib.cm.rainbow(j/n_snap_analyze))\n",
    "    axs[1].axhline(0.,color='k',ls='--')\n",
    "    axs[1].set_xlabel('r [kpc]')\n",
    "    axs[1].set_ylabel(r'$J_{0}$')\n",
    "\n",
    "    fig.suptitle('primary z=0 subfind id: '+str(primary_z0_subfind_id))\n",
    "    fig.tight_layout()\n",
    "    # figname = './fig/jeans_diagnostics_primary_halo_'+str(primary_z0_subfind_id)+'.png'\n",
    "    # fig.savefig(figname, dpi=300)\n",
    "    # plt.close(fig)\n",
    "    fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot some kinematics and distributions of individual merger remnants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all particle IDs that belong with each major merger progenitor\n",
    "\n",
    "unique_particle_ids = []\n",
    "\n",
    "for i in range(n_mw): # Loop over MW analogs\n",
    "    if i > n_do: continue\n",
    "    \n",
    "    major_dict = all_major_list[i]\n",
    "    major_list = major_dict['major_list']\n",
    "    n_major = major_dict['n_major']\n",
    "    \n",
    "    # Hold star particle IDs for this MW analog\n",
    "    analog_unique_particle_ids = []\n",
    "    \n",
    "    for j in range(n_major+1): # Loop over majors + primary (index 0)\n",
    "        if j == 0:\n",
    "            assert major_list[j]['is_primary'], 'Index 0 not primary'\n",
    "            continue\n",
    "        ###j\n",
    "        major_snaps = major_list[j]['snaps']\n",
    "        major_subfind_ids = major_list[j]['subfind_ids']\n",
    "        major_nsnaps = len(major_snaps)\n",
    "        \n",
    "        # Hold star particle IDs for this major merger progenitor\n",
    "        major_unique_particle_ids = np.array([],dtype=int) \n",
    "        \n",
    "        for k in range(major_nsnaps):\n",
    "            \n",
    "            snap_filename = data_dir+'cutouts/snap_'+str(major_snaps[k])+\\\n",
    "                '/cutout_'+str(int(major_subfind_ids[k]))+'.hdf5'\n",
    "            f = h5py.File(snap_filename,'r')\n",
    "            try:\n",
    "                major_unique_particle_ids = np.unique(np.concatenate((\n",
    "                    major_unique_particle_ids,\n",
    "                    np.array(f['PartType4']['ParticleIDs'],dtype=int))))\n",
    "            except KeyError:\n",
    "                pass\n",
    "            f.close()\n",
    "            \n",
    "        analog_unique_particle_ids.append(np.sort(major_unique_particle_ids))\n",
    "    unique_particle_ids.append(analog_unique_particle_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 10\n",
    "norm_by_nuvr2_r = True\n",
    "norm_by_galpy_scale_units = False\n",
    "snap_analyze = np.array([99,91,84,78,72,67,59,50])\n",
    "redshift_analyze = np.array([0.,0.1,0.2,0.3,0.4,0.5,0.7,1.0])\n",
    "n_snap_analyze = len(snap_analyze)\n",
    "\n",
    "for i in range(n_mw):\n",
    "    if i > n_do: continue\n",
    "\n",
    "    # Get primary particle properties\n",
    "    major_dict = all_major_list[i]\n",
    "    major_list = major_dict['major_list']\n",
    "    analyze_mask = np.isin(major_list[0]['snaps'],snap_analyze)\n",
    "    assert (major_list[0]['snaps'][analyze_mask] == snap_analyze).all()\n",
    "    primary_snaps = major_list[0]['snaps'][analyze_mask]\n",
    "    primary_redshift = np.zeros(n_snap_analyze)\n",
    "    primary_subfind_ids = major_list[0]['subfind_ids'][analyze_mask]\n",
    "    primary_z0_subfind_id = major_dict['primary_z0_subfind_id']\n",
    "    n_major = major_dict['n_major']\n",
    "    print('Analyzing primary z=0 subfind id: '+str(primary_z0_subfind_id))\n",
    "    print('------------------------------------------')\n",
    "\n",
    "    # Initialize arrays\n",
    "    J_abs_weighted = np.zeros((n_major,n_snap_analyze))\n",
    "    J_values = np.zeros((n_major,n_snap_analyze,nbins))\n",
    "\n",
    "    for j in range(n_snap_analyze):\n",
    "        primary_path = data_dir+'cutouts/snap_'+str(primary_snaps[j])+'/'\n",
    "        primary_filename = primary_path+'cutout_'+str(primary_subfind_ids[j])+'.hdf5'\n",
    "        print('Analyzing primary subfind id: '+str(primary_subfind_ids[j]))\n",
    "    \n",
    "        # Make the TNGCutout instance\n",
    "        cutout = pcutout.TNGCutout(primary_filename)\n",
    "        primary_redshift[j] = cutout.header['Redshift']\n",
    "        # Bounding radii for centering / rectifying in kpc\n",
    "        vcen_rmin = 0.\n",
    "        vcen_rmax = 5.\n",
    "        rot_rmin = 2.\n",
    "        rot_rmax = 10.\n",
    "        # Center and rectify\n",
    "        cutout.center_and_rectify(cen_ptype='PartType4', vcen_ptype='PartType4',\n",
    "            vcen_rmin=vcen_rmin, vcen_rmax=vcen_rmax, rot_ptype='PartType4', \n",
    "            rot_rmin=rot_rmin, rot_rmax=rot_rmax)\n",
    "        f_primary = h5py.File(primary_filename)\n",
    "        primary_particle_ids = np.array(f_primary['PartType4']['ParticleIDs'])\n",
    "        f_primary.close()\n",
    "    \n",
    "        # Get properties, energy, angular momentum\n",
    "        orbs = cutout.get_orbs('PartType4')\n",
    "        rs = orbs.r().value\n",
    "        vels = cutout.get_velocities('PartType4', physical=True)\n",
    "        pot = cutout.get_potential_energy('PartType4', physical=True)\n",
    "\n",
    "        # Now parse secondary major mergers\n",
    "        major_list = major_dict['major_list']\n",
    "        n_major = major_dict['n_major']\n",
    "        \n",
    "        for k in range(n_major+1): # Loop over majors + primary (index 0)\n",
    "            if k == 0:\n",
    "                assert major_list[k]['is_primary'], 'Index 0 not primary'\n",
    "                continue\n",
    "            \n",
    "            this_unique_ids = unique_particle_ids[i][k-1]\n",
    "            unique_ids_in_primary = np.array([])\n",
    "            this_mlpid = major_list[k]['mlpid']\n",
    "            n_unique = len(this_unique_ids)\n",
    "            \n",
    "            primary_particle_ids_argsort = np.argsort(primary_particle_ids)\n",
    "            primary_particle_ids_sorted = primary_particle_ids[primary_particle_ids_argsort]\n",
    "            where_this_unique_ids_sorted = np.searchsorted(\n",
    "                primary_particle_ids_sorted, this_unique_ids)\n",
    "            where_this_unique_ids = np.take(primary_particle_ids_argsort, \n",
    "                where_this_unique_ids_sorted, mode='clip')\n",
    "            mask = primary_particle_ids[where_this_unique_ids] !=\\\n",
    "                this_unique_ids\n",
    "            result = np.ma.array(where_this_unique_ids, mask=mask)\n",
    "            where_merg = result.data[~result.mask].astype(int)\n",
    "\n",
    "            print('Plotting '+str(this_mlpid)+'...')\n",
    "            # Compute the Jeans equation quantities\n",
    "            Js,rs,qs = calculate_spherical_jeans(orbs[where_merg],pot[where_merg],\n",
    "                n_bootstrap=1, r_range=[0,50], n_bin=nbins, \n",
    "                norm_by_nuvr2_r=norm_by_nuvr2_r,\n",
    "                norm_by_galpy_scale_units=norm_by_galpy_scale_units)\n",
    "            \n",
    "            J_weights = qs[2]*rs**2 # density * r^2\n",
    "            J_abs_weighted[k-1,j] = np.sum(np.abs(Js)*J_weights)/np.sum(J_weights)\n",
    "            J_values[k-1,j,:] = Js\n",
    "\n",
    "    for l in range(n_major):\n",
    "        # Make the Jeans equation figure\n",
    "        fig = plt.figure()\n",
    "        axs = fig.subplots(nrows=2,ncols=1)\n",
    "        axs[0].plot(primary_redshift,J_abs_weighted[l],'o-')\n",
    "        axs[0].axhline(0.,color='k',ls='--')\n",
    "        axs[0].set_xlabel('Redshift')\n",
    "        axs[0].set_ylabel(r'weighted $|J_{0}|$')\n",
    "\n",
    "        for m in range(n_snap_analyze):\n",
    "            axs[1].plot(rs,J_values[l,m,:],'-',color=matplotlib.cm.rainbow(m/n_snap_analyze))\n",
    "        axs[1].axhline(0.,color='k',ls='--')\n",
    "        axs[1].set_xlabel('r [kpc]')\n",
    "        axs[1].set_ylabel(r'$J_{0}$')\n",
    "\n",
    "        fig.suptitle('primary z=0 subfind id: '+str(primary_z0_subfind_id)+', major merger: '+str(l+1))\n",
    "        fig.tight_layout()\n",
    "        # figname = './fig/jeans_diagnostics_primary_halo_'+str(primary_z0_subfind_id)+'.png'\n",
    "        # fig.savefig(figname, dpi=300)\n",
    "        # plt.close(fig)\n",
    "        fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "nteract": {
   "version": "0.28.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
