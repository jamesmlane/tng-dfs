{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "#\n",
    "# TITLE - 1_fit_anisotropy.ipynb\n",
    "# AUTHOR - James Lane\n",
    "# PROJECT - tng-dfs\n",
    "#\n",
    "# ------------------------------------------------------------------------\n",
    "#\n",
    "# Docstrings and metadata:\n",
    "'''Do some fits to the velocity dispersion anisotropy.\n",
    "'''\n",
    "\n",
    "__author__ = \"James Lane\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../src/nb_modules/nb_imports.txt\n",
    "### Imports\n",
    "\n",
    "## Basic\n",
    "import numpy as np\n",
    "import sys, os, dill as pickle, time, pdb, multiprocessing, logging\n",
    "\n",
    "## Plotting\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import corner\n",
    "\n",
    "## Astropy\n",
    "from astropy import units as apu\n",
    "\n",
    "## Analysis\n",
    "import scipy.stats\n",
    "import scipy.interpolate\n",
    "import emcee\n",
    "\n",
    "## Project-specific\n",
    "src_path = 'src/'\n",
    "while True:\n",
    "    if os.path.exists(src_path): break\n",
    "    if os.path.realpath(src_path).split('/')[-1] in ['tng-dfs','/']:\n",
    "            raise FileNotFoundError('Failed to find src/ directory.')\n",
    "    src_path = os.path.join('..',src_path)\n",
    "sys.path.insert(0,src_path)\n",
    "from tng_dfs import cutout as pcutout\n",
    "from tng_dfs import kinematics as pkin\n",
    "from tng_dfs import util as putil\n",
    "\n",
    "### Notebook setup\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(os.path.join(src_path,'mpl/project.mplstyle')) # This must be exactly here\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../src/nb_modules/nb_setup.txt\n",
    "# Keywords\n",
    "cdict = putil.load_config_to_dict()\n",
    "keywords = ['DATA_DIR','MW_ANALOG_DIR','FIG_DIR_BASE','FITTING_DIR_BASE',\n",
    "            'RO','VO','ZO','LITTLE_H','MW_MASS_RANGE']\n",
    "data_dir,mw_analog_dir,fig_dir_base,fitting_dir_base,ro,vo,zo,h,\\\n",
    "    mw_mass_range = putil.parse_config_dict(cdict,keywords)\n",
    "\n",
    "# MW Analog \n",
    "mwsubs,mwsubs_vars = putil.prepare_mwsubs(mw_analog_dir,h=h,\n",
    "    mw_mass_range=mw_mass_range,return_vars=True,force_mwsubs=False,\n",
    "    bulge_disk_fraction_cuts=True)\n",
    "\n",
    "# Figure path\n",
    "local_fig_dir = './fig/'\n",
    "fig_dir = os.path.join(fig_dir_base, \n",
    "    'notebooks/4_fit_distribution_functions/1_fit_anisotropy/')\n",
    "os.makedirs(local_fig_dir,exist_ok=True)\n",
    "os.makedirs(fig_dir,exist_ok=True)\n",
    "show_plots = False\n",
    "\n",
    "# Load tree data\n",
    "tree_primary_filename = os.path.join(mw_analog_dir,\n",
    "    'major_mergers/tree_primaries.pkl')\n",
    "with open(tree_primary_filename,'rb') as handle: \n",
    "    tree_primaries = pickle.load(handle)\n",
    "tree_major_mergers_filename = os.path.join(mw_analog_dir,\n",
    "    'major_mergers/tree_major_mergers.pkl')\n",
    "with open(tree_major_mergers_filename,'rb') as handle:\n",
    "    tree_major_mergers = pickle.load(handle)\n",
    "n_mw = len(tree_primaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the likelihood and any priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likelihood will be Gaussian with mean from the model. The variances will be estimated from the data if provided. Otherwise can proxy variances with bin counts, provided by `mass`. If bin counts are Poisson, then the variance is the bin count, equal to the mass. Since this is $\\beta$, we normalize by the total mass. So the variance for the likelihood is $m_{i}/\\sum_{i} m_{i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mloglike_beta(*args, **kwargs):\n",
    "    return -loglike_beta(*args, **kwargs)\n",
    "\n",
    "def loglike_beta(params, model, r, beta, sigma=None, mass=None, \n",
    "    usr_log_prior=None, usr_log_prior_params=[], parts=False):\n",
    "    # Evaluate the domain prior\n",
    "    if not domain_prior_beta(model, params):\n",
    "        return -np.inf\n",
    "    # Evaluate the prior on the beta model\n",
    "    logprior = logprior_beta(model, params)\n",
    "    # Evaluate any user supplied prior\n",
    "    if callable(usr_log_prior):\n",
    "        usrlogprior = usr_log_prior(params, *usr_log_prior_params)\n",
    "        if np.isinf(usrlogprior):\n",
    "            return -np.inf\n",
    "    else:\n",
    "        usrlogprior = 0\n",
    "    # Evaluate the model\n",
    "    beta_model = model(r, *params)\n",
    "    # Sigma for the likelihood\n",
    "    if sigma is not None:\n",
    "        _sigma = sigma\n",
    "    elif mass is not None:\n",
    "        mass_frac = mass/np.sum(mass)\n",
    "        _sigma = mass_frac\n",
    "    else:\n",
    "        _sigma = 0.1\n",
    "    # Compute the log objective\n",
    "    logobj = -0.5*np.square(beta - beta_model)/_sigma**2\n",
    "    # Compute the log likelihood\n",
    "    loglike = np.sum(logobj) + logprior + usrlogprior\n",
    "    if parts:\n",
    "        return loglike, np.sum(logobj), logprior, usrlogprior\n",
    "    else:\n",
    "        return loglike\n",
    "\n",
    "def logprior_beta(model, params):\n",
    "    if model.__name__ == 'beta_osipkov_merritt':\n",
    "        ra, = params\n",
    "        # log prior on ra\n",
    "        ra_min = 0.0001\n",
    "        ra_max = 10000.\n",
    "        prior_ra = scipy.stats.loguniform.pdf(ra, ra_min, ra_max)\n",
    "        return np.log(prior_ra)\n",
    "    if model.__name__ == 'beta_cuddeford91':\n",
    "        ra, alpha = params\n",
    "        # log prior on ra\n",
    "        ra_min = 0.0001\n",
    "        ra_max = 10000.\n",
    "        prior_ra = scipy.stats.loguniform.pdf(ra, ra_min, ra_max)\n",
    "        return np.log(prior_ra)\n",
    "    return 0.\n",
    "\n",
    "def domain_prior_beta(model, params):\n",
    "    if model.__name__ == 'beta_constant':\n",
    "        beta, = params\n",
    "        if beta >= 1.:\n",
    "            return False\n",
    "    elif model.__name__ == 'beta_osipkov_merritt':\n",
    "        ra, = params\n",
    "        if ra <= 0.:\n",
    "            return False\n",
    "    elif model.__name__ == 'beta_cuddeford91':\n",
    "        ra, alpha = params\n",
    "        if ra <= 0.:\n",
    "            return False\n",
    "        if alpha <= -1.:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load some data and try and do some fits at $z=0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some keywords and properties\n",
    "verbose = True\n",
    "\n",
    "# Paths\n",
    "df_fitting_dir = os.path.join(fitting_dir_base,'distribution_function')\n",
    "os.makedirs(df_fitting_dir,exist_ok=True)\n",
    "\n",
    "# Begin logging\n",
    "log_filename = './log/1_fit_anisotropy.log'\n",
    "if os.path.exists(log_filename):\n",
    "    os.remove(log_filename)\n",
    "logging.basicConfig(filename=log_filename, level=logging.INFO, filemode='w', \n",
    "    force=True)\n",
    "logging.info('Beginning constant anisotropy DF creation. Time: '+\\\n",
    "             time.strftime('%a, %d %b %Y %H:%M:%S',time.localtime()))\n",
    "\n",
    "# Models to fit and fitting params\n",
    "models = [pkin.beta_constant, pkin.beta_osipkov_merritt, pkin.beta_cuddeford91]\n",
    "inits = [[0.], [10.], [10.,0.]]\n",
    "mcmc_labels = [[r'$\\beta$',],\n",
    "               [r'$r_a$',],\n",
    "               [r'$r_a$',r'$\\alpha$',]]\n",
    "param_names = [['beta'],\n",
    "               ['ra'],\n",
    "               ['ra','alpha']]\n",
    "plot_labels = [r'Constant-$\\beta$',\n",
    "               r'Osipkov-Merritt',\n",
    "               r'Cuddeford 1991',]\n",
    "plot_colors = ['DodgerBlue','Crimson','ForestGreen']\n",
    "plot_linestyles = ['solid','dashed','dotted']\n",
    "plot_zorders = [1,2,3]\n",
    "df_type = ['constant_beta','osipkov_merritt','cuddeford91']\n",
    "fit_version = ['anisotropy_params_softening','anisotropy_params_softening',\n",
    "               'anisotropy_params_softening']\n",
    "fig_version = 'anisotropy_params_softening' # Singular because all plotted at same time\n",
    "# MCMC params\n",
    "nwalkers = 100\n",
    "nit = 1000\n",
    "ncut = 500\n",
    "nprocs = 12\n",
    "# Binning params\n",
    "n_bs = 100 # Number of bootstrap samples\n",
    "\n",
    "for i in range(n_mw):\n",
    "    # if i != 0: continue\n",
    "\n",
    "    # Get the primary\n",
    "    primary = tree_primaries[i]\n",
    "    z0_sid = primary.subfind_id[0]\n",
    "    n_snap = len(primary.snapnum)\n",
    "    n_major = primary.n_major_mergers\n",
    "    co = pcutout.TNGCutout(\n",
    "        primary.get_cutout_filename(mw_analog_dir,snapnum=primary.snapnum[0]))\n",
    "    co.center_and_rectify()\n",
    "    pid = co.get_property('stars','ParticleIDs')\n",
    "\n",
    "    # Loop over the major mergers\n",
    "    for j in range(n_major):\n",
    "        # if j > 0: continue\n",
    "        if verbose:\n",
    "            msg = f'Analyzing major merger {j+1}/{n_major} for MW {i+1}/{n_mw}'\n",
    "            logging.info(msg)\n",
    "            print(msg)\n",
    "\n",
    "        # Get the major merger\n",
    "        major_merger = primary.tree_major_mergers[j]\n",
    "        major_acc_sid = major_merger.subfind_id[0]\n",
    "        major_mlpid = major_merger.secondary_mlpid\n",
    "        upid = major_merger.get_unique_particle_ids('stars',data_dir=data_dir)\n",
    "        indx = np.where(np.isin(pid,upid))[0]\n",
    "        orbs = co.get_orbs('stars')[indx]\n",
    "        rs = orbs.r().to(apu.kpc).value\n",
    "        norbs = len(orbs)\n",
    "        # _n_bin = 500 if (len(orbs) > 5000) else round(len(orbs)/10)\n",
    "        n_bin = np.min([500, len(orbs)//10]) # n per bin\n",
    "\n",
    "        # Compute the binning\n",
    "        r_softening = putil.get_softening_length('stars', z=0, physical=True)\n",
    "        rmin = np.max([r_softening, np.min(rs)])\n",
    "        # rmin = 0.\n",
    "        rmax = np.max(rs)\n",
    "        adaptive_binning_kwargs = {\n",
    "            'n':n_bin,\n",
    "            'rmin':rmin,\n",
    "            'rmax':rmax,\n",
    "            'bin_mode':'exact numbers',\n",
    "            'bin_equal_n':True,\n",
    "            'end_mode':'ignore',\n",
    "            'bin_cents_mode':'median',\n",
    "        }\n",
    "        bin_edges, bin_cents, bin_n = pkin.get_radius_binning(orbs, \n",
    "            **adaptive_binning_kwargs)\n",
    "        \n",
    "        # Compute the ingredients for the anisotropy, use dispersions\n",
    "        compute_betas_kwargs = {'use_dispersions':True,\n",
    "                                'return_kinematics':True}\n",
    "        beta, vr2, vp2, vz2 = pkin.compute_betas_bootstrap(orbs,bin_edges,\n",
    "            n_bootstrap=n_bs, compute_betas_kwargs=compute_betas_kwargs)\n",
    "        lbeta, mbeta, ubeta = np.percentile(beta, [16,50,84], axis=0)\n",
    "        sbeta = ubeta-lbeta\n",
    "\n",
    "        # Plotting directory\n",
    "        this_fig_dir = os.path.join(fig_dir, fig_version, str(z0_sid), \n",
    "            'merger_'+str(j+1))\n",
    "        os.makedirs(this_fig_dir, exist_ok=True)\n",
    "\n",
    "        # Make the figure showing the beta profile and the different fits\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.plot(bin_cents, mbeta, color='Black')\n",
    "        ax.fill_between(bin_cents, lbeta, ubeta, color='Black', alpha=0.25)\n",
    "\n",
    "        ## Fit the different models\n",
    "        for k in range(3):\n",
    "            if k == 2: continue\n",
    "            if verbose:\n",
    "                msg = f'Fitting anisotropy model '+df_type[k]\n",
    "                logging.info(msg)\n",
    "                print(msg)\n",
    "            model = models[k]\n",
    "            init = inits[k]\n",
    "            \n",
    "            # Optimizing\n",
    "            opt_fn = lambda params: mloglike_beta(params, model, bin_cents, \n",
    "                mbeta, sigma=sbeta, mass=None, usr_log_prior=None, \n",
    "                usr_log_prior_params=[], parts=False)\n",
    "            opt = scipy.optimize.minimize(opt_fn, init, method='Nelder-Mead',\n",
    "                options={'maxiter':1000,})\n",
    "            \n",
    "            # MCMC\n",
    "            def llfunc(params):\n",
    "                return loglike_beta(params, model, bin_cents, mbeta, \n",
    "                    sigma=sbeta, mass=None, usr_log_prior=None, \n",
    "                    usr_log_prior_params=[], parts=False)\n",
    "            mcmc_init = np.array([\n",
    "                opt.x+0.05*np.random.randn(len(opt.x)) for i in range(nwalkers)\n",
    "            ])\n",
    "            with multiprocessing.Pool(processes=nprocs) as pool:\n",
    "                sampler = emcee.EnsembleSampler(nwalkers, len(mcmc_init[0]), \n",
    "                    llfunc, pool=pool)\n",
    "                sampler.run_mcmc(mcmc_init, nit, progress=True)\n",
    "            chain = sampler.get_chain(flat=True, discard=ncut)\n",
    "            \n",
    "            # Corner plot for these results\n",
    "            figc = corner.corner(chain, labels=mcmc_labels[k], \n",
    "                quantiles=[0.16,0.5,0.84], truths=opt.x, \n",
    "                truth_color='Red')\n",
    "            figname = os.path.join(this_fig_dir,df_type[k]+'_corner.png')\n",
    "            figc.savefig(figname)\n",
    "            plt.close(figc)\n",
    "\n",
    "            # Add the results on the common figure\n",
    "            # indx = np.random.choice(np.arange(len(chain)), size=nplot, replace=True)\n",
    "            beta_model = np.ones((chain.shape[0],len(bin_cents)))\n",
    "            for m in range(len(chain)):\n",
    "                beta_model[m,:] = model(bin_cents, *chain[m])\n",
    "            ax.plot(bin_cents, np.median(beta_model, axis=0), \n",
    "                color=plot_colors[k], label=plot_labels[k], \n",
    "                zorder=plot_zorders[k], linestyle=plot_linestyles[k])\n",
    "            ax.fill_between(bin_cents, np.percentile(beta_model,16,axis=0), \n",
    "                np.percentile(beta_model,84,axis=0), color=plot_colors[k], \n",
    "                alpha=0.25)\n",
    "\n",
    "            # Save the results\n",
    "            this_fitting_dir = os.path.join(df_fitting_dir, df_type[k],\n",
    "                fit_version[k], str(z0_sid),'merger_'+str(j+1))\n",
    "            os.makedirs(this_fitting_dir, exist_ok=True)\n",
    "            opt_filename = os.path.join(this_fitting_dir,'opt.pkl')\n",
    "            with open(opt_filename,'wb') as handle:\n",
    "                pickle.dump(opt, handle)\n",
    "            sampler_filename = os.path.join(this_fitting_dir,'sampler.pkl')\n",
    "            with open(sampler_filename,'wb') as handle:\n",
    "                pickle.dump(sampler, handle)\n",
    "            chain_filename = os.path.join(this_fitting_dir,'chain.pkl')\n",
    "            with open(chain_filename,'wb') as handle:\n",
    "                pickle.dump([chain,param_names[k]], handle)\n",
    "\n",
    "        ax.set_xlabel(r'$r$ [kpc]')\n",
    "        ax.set_ylabel(r'$\\beta$')\n",
    "        ax.legend(loc='best', frameon=False, fontsize=8)\n",
    "        fig.tight_layout()\n",
    "        figname = os.path.join(this_fig_dir,'beta_fits.png')\n",
    "        fig.savefig(figname)\n",
    "        plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "nteract": {
   "version": "0.28.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "39281e2d1d208f5d5f10b92e49c40383b657448f443f22dc78686b7e0f8179a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
