{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "#\n",
    "# TITLE - 3_fit_stellar_halo_rotation.ipynb\n",
    "# AUTHOR - James Lane\n",
    "# PROJECT - ges-mass\n",
    "#\n",
    "# ------------------------------------------------------------------------\n",
    "#\n",
    "# Docstrings and metadata:\n",
    "'''Fit rotation DF wrappers to remnants in stellar halos at z=0\n",
    "'''\n",
    "\n",
    "__author__ = \"James Lane\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "\n",
    "## Basic\n",
    "import numpy as np\n",
    "import sys, os, pdb, copy, time, dill as pickle, logging\n",
    "\n",
    "## Matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "## Astropy\n",
    "from astropy import units as apu\n",
    "\n",
    "## Fitting\n",
    "import emcee\n",
    "import corner\n",
    "import multiprocessing\n",
    "import scipy.optimize\n",
    "\n",
    "## Project-specific\n",
    "sys.path.insert(0,'../../src/')\n",
    "from tng_dfs import util as putil\n",
    "from tng_dfs import cutout as pcutout\n",
    "\n",
    "### Notebook setup\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('../../src/mpl/project.mplstyle') # This must be exactly here\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../src/nb_modules/nb_setup.txt\n",
    "# Keywords\n",
    "cdict = putil.load_config_to_dict()\n",
    "keywords = ['DATA_DIR','MW_ANALOG_DIR','FIG_DIR_BASE','FITTING_DIR_BASE',\n",
    "            'RO','VO','ZO','LITTLE_H','MW_MASS_RANGE']\n",
    "data_dir,mw_analog_dir,fig_dir_base,fitting_dir_base,ro,vo,zo,h,\\\n",
    "    mw_mass_range = putil.parse_config_dict(cdict,keywords)\n",
    "\n",
    "# MW Analog \n",
    "mwsubs,mwsubs_vars = putil.prepare_mwsubs(mw_analog_dir,h=h,\n",
    "    mw_mass_range=mw_mass_range,return_vars=True,force_mwsubs=False,\n",
    "    bulge_disk_fraction_cuts=True)\n",
    "\n",
    "# Figure path\n",
    "local_fig_dir = './fig/'\n",
    "fig_dir = os.path.join(fig_dir_base,\n",
    "    'notebooks/3_fit_density_profiles/3_fit_stellar_halo_rotation/')\n",
    "os.makedirs(local_fig_dir,exist_ok=True)\n",
    "os.makedirs(fig_dir,exist_ok=True)\n",
    "show_plots = False\n",
    "\n",
    "# Load tree data\n",
    "tree_primary_filename = os.path.join(mw_analog_dir,\n",
    "    'major_mergers/tree_primaries.pkl')\n",
    "with open(tree_primary_filename,'rb') as handle: \n",
    "    tree_primaries = pickle.load(handle)\n",
    "tree_major_mergers_filename = os.path.join(mw_analog_dir,\n",
    "    'major_mergers/tree_major_mergers.pkl')\n",
    "with open(tree_major_mergers_filename,'rb') as handle:\n",
    "    tree_major_mergers = pickle.load(handle)\n",
    "n_mw = len(tree_primaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh_rotation_function(Lz,frot=0.,chi=1.):\n",
    "    if isinstance(Lz,apu.Quantity):\n",
    "        Lz = Lz.to(apu.kpc*apu.km/apu.s).value\n",
    "    if isinstance(chi,apu.Quantity):\n",
    "        chi = chi.to(apu.kpc*apu.km/apu.s).value\n",
    "    gLz = np.tanh(Lz/chi)\n",
    "    k = frot/2.\n",
    "    return 1-k+k*gLz\n",
    "\n",
    "def tanh_rotation_effvol(params, Lzmin, Lzmax):\n",
    "    frot, chi = params\n",
    "    term1 = (Lzmax-Lzmin)*(1-frot)\n",
    "    # term2 = frot*chi*(np.log(np.cosh(Lzmax/chi)) - np.log(np.cosh(Lzmin/chi)))\n",
    "    term2 = 0.5*frot*(Lzmax-Lzmin)\n",
    "    return term1 + term2\n",
    "\n",
    "def mloglike_tanh_rotation(*args, **kwargs):\n",
    "    return -loglike_tanh_rotation(*args, **kwargs)\n",
    "\n",
    "def loglike_tanh_rotation(params, Lz, usr_log_prior=None, \n",
    "    usr_log_prior_params=[], effvol_params=[], parts=False):\n",
    "    # Evaluate the domain prior\n",
    "    if not domain_prior_tanh_rotation(params):\n",
    "        return -np.inf\n",
    "    # Evaluate the prior on the density profile\n",
    "    logprior = logprior_tanh_rotation(params)\n",
    "    # Evaluate any user supplied prior\n",
    "    if callable(usr_log_prior):\n",
    "        usrlogprior = usr_log_prior(params, *usr_log_prior_params)\n",
    "        if np.isinf(usrlogprior):\n",
    "            return -np.inf\n",
    "    else:\n",
    "        usrlogprior = 0\n",
    "    # Evaluate the tanh kernel\n",
    "    frot, chi = params\n",
    "    logkernel = np.log(tanh_rotation_function(Lz, frot=frot, chi=chi))\n",
    "    if np.any(np.isnan(logkernel)):\n",
    "        return -np.inf\n",
    "    # Evaluate the effective volume\n",
    "    effvol = tanh_rotation_effvol(params, *effvol_params)\n",
    "    # Evaluate the log likelihood\n",
    "    loglike = np.sum(logkernel) - effvol + logprior + usrlogprior\n",
    "    if parts:\n",
    "        return loglike, np.sum(logkernel), effvol, logprior, usrlogprior\n",
    "    else:\n",
    "        return loglike\n",
    "\n",
    "def logprior_tanh_rotation(params):\n",
    "    # frot, chi = params\n",
    "    return 0.\n",
    "\n",
    "def domain_prior_tanh_rotation(params):\n",
    "    frot, chi = params\n",
    "    if frot < 0.: return False\n",
    "    if frot > 1.: return False\n",
    "    if chi < 0.: return False\n",
    "    return True\n",
    "\n",
    "# Also define likelihoods for fitting tanh rotation in terms of the asymmetry\n",
    "# of angular momentum counts.\n",
    "\n",
    "def tanh_rotation_function_asymmetry(Lz,frot=0.,chi=1.):\n",
    "    if isinstance(Lz,apu.Quantity):\n",
    "        Lz = Lz.to(apu.kpc*apu.km/apu.s).value\n",
    "    if isinstance(chi,apu.Quantity):\n",
    "        chi = chi.to(apu.kpc*apu.km/apu.s).value\n",
    "    return frot*np.tanh(Lz/chi)/2. + 0.5\n",
    "\n",
    "def mloglike_tanh_rotation_asym(*args, **kwargs):\n",
    "    return -loglike_tanh_rotation_asym(*args, **kwargs)\n",
    "\n",
    "def loglike_tanh_rotation_asym(params, Lz, usr_log_prior=None, \n",
    "    usr_log_prior_params=[], parts=False):\n",
    "    # Evaluate the domain prior\n",
    "    if not domain_prior_tanh_rotation_asym(params):\n",
    "        return -np.inf\n",
    "    # Evaluate the prior on the density profile\n",
    "    logprior = logprior_tanh_rotation_asym(params)\n",
    "    # Evaluate any user supplied prior\n",
    "    if callable(usr_log_prior):\n",
    "        usrlogprior = usr_log_prior(params, *usr_log_prior_params)\n",
    "        if np.isinf(usrlogprior):\n",
    "            return -np.inf\n",
    "    else:\n",
    "        usrlogprior = 0\n",
    "    # Determine the Lz asymmetry\n",
    "    n_bin = int(np.min([50,len(Lz)/20]))\n",
    "    Lz_max = np.percentile(np.abs(Lz), 80)\n",
    "    Lz_min = -Lz_max\n",
    "    Lz_N, Lz_edges = np.histogram( Lz, bins=n_bin, range=(Lz_min, Lz_max) )\n",
    "    Lz_centers = 0.5*(Lz_edges[1:] + Lz_edges[:-1])\n",
    "    Lz_mirror_sum = (Lz_N + Lz_N[::-1])\n",
    "    Lz_asym_mask = Lz_mirror_sum > 0\n",
    "    Lz_asym = np.ones_like(Lz_centers)\n",
    "    Lz_asym = Lz_N[Lz_asym_mask] / Lz_mirror_sum[Lz_asym_mask]\n",
    "    # Evaluate the tanh rotation asymmetry and the objective function\n",
    "    frot, chi = params\n",
    "    Lz_asym_model = tanh_rotation_function_asymmetry(Lz_centers, frot=frot, \n",
    "        chi=chi)\n",
    "    # Mass fraction\n",
    "    mass_frac = Lz_N/np.sum(Lz_N)\n",
    "    # Squared objective\n",
    "    # obj = np.square(Lz_asym[Lz_asym_mask] - Lz_asym_model[Lz_asym_mask])\n",
    "    # Gaussian objective\n",
    "    _sigma = mass_frac[Lz_asym_mask]\n",
    "    logobj = -0.5*np.square(Lz_asym[Lz_asym_mask] - Lz_asym_model[Lz_asym_mask])/_sigma**2\n",
    "    # logobj = np.log(obj)\n",
    "    # if np.any(np.isnan(obj)):\n",
    "    #     return -np.inf\n",
    "    # Evaluate the effective volume\n",
    "    # Evaluate the log likelihood\n",
    "    loglike = np.sum(logobj) + logprior + usrlogprior\n",
    "    if parts:\n",
    "        return loglike, np.sum(logobj), logprior, usrlogprior\n",
    "    else:\n",
    "        return loglike\n",
    "\n",
    "def logprior_tanh_rotation_asym(params):\n",
    "    frot, chi = params\n",
    "    # log prior on chi\n",
    "    chi_min = 0.001\n",
    "    chi_max = 10000.\n",
    "    prior_chi = scipy.stats.loguniform.pdf(chi, chi_min, chi_max)\n",
    "    return np.log(prior_chi)\n",
    "    # return 0.\n",
    "\n",
    "def domain_prior_tanh_rotation_asym(params):\n",
    "    frot, chi = params\n",
    "    if frot < -1.: return False\n",
    "    if frot > 1.: return False\n",
    "    if chi < 0.001: return False\n",
    "    if chi > 10000: return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the rotation of remnants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tanh_rotation_fit(Lz, chain):\n",
    "    '''\n",
    "    '''\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    # Bin up Lz\n",
    "    n_bin = int(np.min([50,len(Lz)/20]))\n",
    "    Lz_max = np.percentile(np.abs(Lz), 80)\n",
    "    Lz_min = -Lz_max\n",
    "    Lz_N, Lz_edges = np.histogram( Lz, bins=n_bin, range=(Lz_min, Lz_max) )\n",
    "    Lz_centers = 0.5*(Lz_edges[1:] + Lz_edges[:-1])\n",
    "    Lz_mirror_sum = (Lz_N + Lz_N[::-1])\n",
    "    Lz_asym_mask = Lz_mirror_sum > 0\n",
    "    Lz_asym = np.ones_like(Lz_centers)\n",
    "    Lz_asym = Lz_N[Lz_asym_mask] / Lz_mirror_sum[Lz_asym_mask]\n",
    "    # Evaluate the tanh rotation asymmetry and the objective function\n",
    "\n",
    "    ax.plot(Lz_centers, Lz_asym, color='Grey', linewidth=2.)\n",
    "    nit = 100\n",
    "    indx = np.random.choice(np.arange(len(chain),dtype=int), size=nit, \n",
    "        replace=False)\n",
    "    for i in range(nit):\n",
    "        frot, chi = chain[indx[i],:]\n",
    "        Lz_asym_model = tanh_rotation_function_asymmetry(Lz_centers, frot=frot, \n",
    "            chi=chi)\n",
    "        ax.plot(Lz_centers, Lz_asym_model, color='Red', linewidth=1., \n",
    "            linestyle='solid', alpha=5/nit)\n",
    "    ax.set_xlabel(r'$L_z$')\n",
    "    ax.set_ylabel(r'$A(L_z)$')\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Properties\n",
    "df_fitting_dir = os.path.join(fitting_dir_base,'distribution_function/')\n",
    "stellar_halo_rotation_dftype = 'tanh_rotation'\n",
    "stellar_halo_rotation_version = 'asymmetry_fit'\n",
    "verbose = True\n",
    "force_fit = False\n",
    "nwalkers = 100\n",
    "nit = 2000\n",
    "ncut = 500\n",
    "nprocs = 10\n",
    "\n",
    "# Begin logging\n",
    "log_filename = './log/3_fit_stellar_halo_rotation.log'\n",
    "if os.path.exists(log_filename):\n",
    "    os.remove(log_filename)\n",
    "logging.basicConfig(filename=log_filename, level=logging.INFO, filemode='w', \n",
    "    force=True)\n",
    "logging.info('Beginning rotation kernel fitting for stellar halos. Time: '+\\\n",
    "             time.strftime('%a, %d %b %Y %H:%M:%S',time.localtime()))\n",
    "\n",
    "for i in range(n_mw):\n",
    "    if i != 0: continue\n",
    "\n",
    "    # Get the primary\n",
    "    primary = tree_primaries[i]\n",
    "    z0_sid = primary.subfind_id[0]\n",
    "    # n_snap = len(primary.snapnum)\n",
    "    n_major = primary.n_major_mergers\n",
    "    primary_filename = primary.get_cutout_filename(mw_analog_dir,\n",
    "        snapnum=primary.snapnum[0])\n",
    "    co = pcutout.TNGCutout(primary_filename)\n",
    "    co.center_and_rectify()\n",
    "\n",
    "    # Get the tree major merger object\n",
    "    major_mergers = primary.tree_major_mergers\n",
    "    n_major = primary.n_major_mergers\n",
    "    # _unique_particle_ids = []\n",
    "\n",
    "    for j in range(n_major):\n",
    "        if j != 0: continue\n",
    "        \n",
    "        if verbose: \n",
    "            msg = f'Fitting merger {j+1}/{n_major}, of analog {i+1}/{n_mw}'\n",
    "            logging.info(msg)\n",
    "            print(msg)\n",
    "\n",
    "        # Fitting dir, check if already exists\n",
    "        this_fitting_dir = os.path.join(df_fitting_dir,\n",
    "            stellar_halo_rotation_dftype,stellar_halo_rotation_version,\n",
    "            str(z0_sid),'merger_'+str(j+1))\n",
    "        os.makedirs(this_fitting_dir,exist_ok=True)\n",
    "        sampler_filename = os.path.join(this_fitting_dir,'sampler.pkl')\n",
    "        if os.path.exists(sampler_filename) and not force_fit:\n",
    "            if verbose:\n",
    "                msg = f'Fitting already exists for {z0_sid}, merger {j+1}'\n",
    "                logging.info(msg)\n",
    "                print(msg)\n",
    "            continue\n",
    "\n",
    "        # Get the major merger\n",
    "        major_merger = primary.tree_major_mergers[j]\n",
    "        upid = major_merger.get_unique_particle_ids('stars',data_dir=data_dir)\n",
    "        pid = co.get_property('stars','ParticleIDs')\n",
    "        indx = np.where(np.isin(pid,upid))[0]\n",
    "        orbs = co.get_orbs('stars')[indx]\n",
    "        \n",
    "        # Properties for fitting\n",
    "        Lz = orbs.Lz().value\n",
    "        usr_log_prior_params = []\n",
    "\n",
    "        # Pare down the data for fitting\n",
    "        # if len(masses) > 1e5:\n",
    "        #     npts = 1e5\n",
    "        #     inds = np.random.choice(np.arange(len(masses),dtype=int), \n",
    "        #         size=int(npts), replace=False)\n",
    "        #     fac = len(masses)/npts\n",
    "        #     Lz = Lz[inds]\n",
    "\n",
    "        # Remove data outside the fitting range, null for now\n",
    "        mask = np.ones_like(Lz, dtype=bool)\n",
    "        Lz_fit = Lz[mask]\n",
    "\n",
    "        # Get the initial conditions\n",
    "        init = np.array([0.25, 425.])\n",
    "\n",
    "        # Do an optimization to get the initial conditions\n",
    "        if verbose:\n",
    "            msg = 'Optimizing initial conditions'\n",
    "            logging.info(msg)\n",
    "            print(msg)\n",
    "        opt_fn = lambda params: mloglike_tanh_rotation_asym(params, \n",
    "            Lz_fit, usr_log_prior=None, \n",
    "            usr_log_prior_params=usr_log_prior_params)\n",
    "        opt = scipy.optimize.minimize(opt_fn, init, method='Nelder-Mead',\n",
    "            options={'maxiter':2000,})\n",
    "        \n",
    "        # Do the MCMC\n",
    "        if verbose:\n",
    "            msg = 'Running MCMC'\n",
    "            logging.info(msg)\n",
    "            print(msg)\n",
    "        def llfunc(params):\n",
    "            return loglike_tanh_rotation_asym(params, \n",
    "            Lz_fit, usr_log_prior=None, \n",
    "            usr_log_prior_params=usr_log_prior_params)\n",
    "        mcmc_init = np.array([\n",
    "            opt.x+0.1*np.random.randn(len(opt.x)) for i in range(nwalkers)\n",
    "            ])\n",
    "        # mcmc_init = np.array([\n",
    "        #     init+0.1*np.random.randn(len(init)) for i in range(nwalkers)\n",
    "        #     ])\n",
    "        with multiprocessing.Pool(processes=nprocs) as pool:\n",
    "            sampler = emcee.EnsembleSampler(nwalkers, len(mcmc_init[0]), llfunc,\n",
    "                pool=pool)\n",
    "            sampler.run_mcmc(mcmc_init, nit, progress=True)\n",
    "        _chain = sampler.get_chain(flat=True, discard=ncut)\n",
    "        chain = copy.deepcopy(_chain)\n",
    "\n",
    "        # Remove all points outside of the domain\n",
    "        mask = np.ones(len(chain), dtype=bool)\n",
    "        for k in range(len(chain)):\n",
    "            if not domain_prior_tanh_rotation_asym(chain[k,:]):\n",
    "                mask[k] = False\n",
    "        chain = chain[mask,:]\n",
    "\n",
    "        # Plotting\n",
    "        this_fig_dir = os.path.join(fig_dir,stellar_halo_rotation_dftype,\n",
    "            stellar_halo_rotation_version,str(z0_sid),'merger_'+str(j+1))\n",
    "        os.makedirs(this_fig_dir, exist_ok=True)\n",
    "\n",
    "        # Density profile\n",
    "        fig, axs = plot_tanh_rotation_fit(Lz, chain)\n",
    "        figname = os.path.join(this_fig_dir,'asymmetry.png')\n",
    "        fig.savefig(figname,dpi=300)\n",
    "        plt.close(fig)\n",
    "\n",
    "        # Corner\n",
    "        fig = corner.corner(chain, \n",
    "            labels=[r'$f_{rot}$',r'$\\chi$'], quantiles=[0.16,0.5,0.84])\n",
    "        corner.overplot_lines(fig, np.median(chain,axis=0), color='Black')\n",
    "        figname = os.path.join(this_fig_dir,'corner.png')\n",
    "        print(figname)\n",
    "        fig.savefig(figname, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "        # Save the results\n",
    "        opt_filename = os.path.join(this_fitting_dir,'opt.pkl')\n",
    "        with open(opt_filename,'wb') as handle:\n",
    "            pickle.dump(opt,handle)\n",
    "        sampler_filename = os.path.join(this_fitting_dir,'sampler.pkl')\n",
    "        with open(sampler_filename,'wb') as handle:\n",
    "            pickle.dump(sampler,handle)\n",
    "        chain_filename = os.path.join(this_fitting_dir,'chain.pkl')\n",
    "        with open(chain_filename,'wb') as handle:\n",
    "            pickle.dump([chain,['frot','chi']],handle)\n",
    "\n",
    "        if verbose:\n",
    "            msg = 'Done with this merger'\n",
    "            logging.info(msg)\n",
    "            print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some extra diagnostic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primary = tree_primaries[1]\n",
    "# z0_sid = primary.subfind_id[0]\n",
    "# # n_snap = len(primary.snapnum)\n",
    "# n_major = primary.n_major_mergers\n",
    "# primary_filename = primary.get_cutout_filename(mw_analog_dir,\n",
    "#     snapnum=primary.snapnum[0])\n",
    "# co = pcutout.TNGCutout(primary_filename)\n",
    "# co.center_and_rectify()\n",
    "\n",
    "# # Get the tree major merger object\n",
    "# major_mergers = primary.tree_major_mergers\n",
    "# n_major = primary.n_major_mergers\n",
    "# # _unique_particle_ids = []\n",
    "\n",
    "# # Get the major merger\n",
    "# major_merger = primary.tree_major_mergers[0]\n",
    "# upid = major_merger.get_unique_particle_ids('stars',data_dir=data_dir)\n",
    "# pid = co.get_property('stars','ParticleIDs')\n",
    "# indx = np.where(np.isin(pid,upid))[0]\n",
    "# orbs = co.get_orbs('stars')[indx]\n",
    "\n",
    "# # Properties for fitting\n",
    "# Lz = orbs.Lz().value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "\n",
    "# # Lz_max = np.percentile(np.abs(Lz), 90)\n",
    "# # Lz_min = -Lz_max\n",
    "# # Lz_N, Lz_edges = np.histogram( Lz, bins=50, range=(Lz_min, Lz_max) )\n",
    "# # Lz_centers = 0.5*(Lz_edges[1:] + Lz_edges[:-1])\n",
    "\n",
    "# Lz_max = np.percentile(np.abs(Lz), 80)\n",
    "# Lz_min = -Lz_max\n",
    "# Lz_N, Lz_edges = np.histogram( Lz, bins=50, range=(Lz_min, Lz_max) )\n",
    "# Lz_centers = 0.5*(Lz_edges[1:] + Lz_edges[:-1])\n",
    "# Lz_mirror_sum = (Lz_N + Lz_N[::-1])\n",
    "# Lz_asym_mask = Lz_mirror_sum > 0\n",
    "# Lz_asym = np.ones_like(Lz_centers)\n",
    "# Lz_asym = Lz_N[Lz_asym_mask] / Lz_mirror_sum[Lz_asym_mask]\n",
    "# # Evaluate the tanh rotation asymmetry and the objective function\n",
    "\n",
    "# ax.scatter(Lz_centers, Lz_N / (Lz_N + Lz_N[::-1]), color='Grey')\n",
    "\n",
    "# frot, chi = [0.95, 200]\n",
    "# ax.scatter(Lz_centers, \n",
    "#     tanh_rotation_function_asymmetry(Lz_centers, frot=frot, chi=chi), \n",
    "#     color='Red')\n",
    "# frot, chi = [0.25, 10.]\n",
    "# # ax.scatter(Lz_centers, \n",
    "# #     tanh_rotation_function_asymmetry(Lz_centers, frot=frot, chi=chi), \n",
    "# #     color='Blue')\n",
    "# # ax.plot(Lz_centers, \n",
    "# #     tanh_rotation_function_asymmetry(Lz_centers, frot=0.5, chi=1000), \n",
    "# #     color='Blue')\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "\n",
    "# # Lz_max = np.percentile(np.abs(Lz), 90)\n",
    "# # Lz_min = -Lz_max\n",
    "# # Lz_N, Lz_edges = np.histogram( Lz, bins=50, range=(Lz_min, Lz_max) )\n",
    "# # Lz_centers = 0.5*(Lz_edges[1:] + Lz_edges[:-1])\n",
    "\n",
    "# Lz_max = np.percentile(np.abs(Lz), 90)\n",
    "# Lz_min = -Lz_max\n",
    "# Lz_N, Lz_edges = np.histogram( Lz, bins=50, range=(Lz_min, Lz_max) )\n",
    "# Lz_centers = 0.5*(Lz_edges[1:] + Lz_edges[:-1])\n",
    "# Lz_mirror_sum = (Lz_N + Lz_N[::-1])\n",
    "# Lz_asym_mask = Lz_mirror_sum > 0\n",
    "# Lz_asym = np.ones_like(Lz_centers)\n",
    "# Lz_asym = Lz_N[Lz_asym_mask] / Lz_mirror_sum[Lz_asym_mask]\n",
    "# # Evaluate the tanh rotation asymmetry and the objective function\n",
    "\n",
    "# params = [0.95, 200.]\n",
    "# frot, chi = params\n",
    "# Lz_asym_model = tanh_rotation_function_asymmetry(Lz_centers, frot=frot, \n",
    "#     chi=chi)\n",
    "# # logobj = np.log(np.square(Lz_asym[Lz_asym_mask] - Lz_asym_model[Lz_asym_mask]))*Lz_N[Lz_asym_mask]/np.sum(Lz_N[Lz_asym_mask])\n",
    "# mass_frac = Lz_N/np.sum(Lz_N)\n",
    "# _sigma = mass_frac[Lz_asym_mask]\n",
    "# obj = np.exp(-0.5*np.square(Lz_asym[Lz_asym_mask] - Lz_asym_model[Lz_asym_mask])/_sigma**2)\n",
    "# logobj = np.log(obj)\n",
    "# print(params, np.sum(logobj))\n",
    "# ax.scatter(Lz_centers, logobj, color='Grey')\n",
    "# ax.axhline(np.average(logobj), color='Grey', linestyle='dashed')\n",
    "\n",
    "# params = [0.25, 500.]\n",
    "# frot, chi = params\n",
    "# Lz_asym_model = tanh_rotation_function_asymmetry(Lz_centers, frot=frot, \n",
    "#     chi=chi)\n",
    "# # logobj = np.log(np.square(Lz_asym[Lz_asym_mask] - Lz_asym_model[Lz_asym_mask]))*Lz_N[Lz_asym_mask]/np.sum(Lz_N[Lz_asym_mask])\n",
    "# mass_frac = Lz_N/np.sum(Lz_N)\n",
    "# _sigma = mass_frac[Lz_asym_mask]\n",
    "# obj = np.exp(-0.5*np.square(Lz_asym[Lz_asym_mask] - Lz_asym_model[Lz_asym_mask])/_sigma**2)\n",
    "# logobj = np.log(obj)\n",
    "# print(params, np.sum(logobj))\n",
    "# ax.scatter(Lz_centers, logobj, color='Blue')\n",
    "# ax.axhline(np.average(logobj), color='Blue', linestyle='dashed')\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frots = np.linspace(0., 1., 50)\n",
    "# loglikes = np.zeros_like(frots)\n",
    "# for i in range(len(frots)):\n",
    "#     loglikes[i] = loglike_tanh_rotation_asym([frots[i], 500], Lz, \n",
    "#         usr_log_prior=None, usr_log_prior_params=[], parts=False)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "# ax.plot(frots, loglikes, color='Grey')\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chis = np.linspace(0., 1000, 50)\n",
    "# loglikes = np.zeros_like(chis)\n",
    "# for i in range(len(chis)):\n",
    "#     loglikes[i] = loglike_tanh_rotation_asym([0.25, chis[i]], Lz, \n",
    "#         usr_log_prior=None, usr_log_prior_params=[], parts=False)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "# ax.plot(chis, loglikes, color='Grey')\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frots = np.linspace(0., 1., 100)\n",
    "# chis = np.linspace(0, 1000, 100)\n",
    "\n",
    "# loglikes = np.zeros((len(frots), len(chis)))\n",
    "# min_loglike = 0.\n",
    "# for i in range(len(frots)):\n",
    "#     for j in range(len(chis)):\n",
    "#         loglikes[i,j] = mloglike_tanh_rotation_asym([frots[i], chis[j]], \n",
    "#             Lz_fit, usr_log_prior=None, usr_log_prior_params=[], parts=False)\n",
    "#         if loglikes[i,j] < min_loglike:\n",
    "#             min_loglike = loglikes[i,j]\n",
    "#             min_chi = chis[j]\n",
    "#             min_frot = frots[i]\n",
    "        \n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "# img = ax.pcolormesh(chis, frots, loglikes, vmin=-80, vmax=-50)\n",
    "# ax.scatter(min_chi, min_frot, facecolor='none', edgecolor='Black', s=40)\n",
    "# ax.set_xlabel(r'$\\chi$')\n",
    "# ax.set_ylabel(r'$f_{rot}$')\n",
    "# fig.colorbar(img)\n",
    "# fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "nteract": {
   "version": "0.28.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
