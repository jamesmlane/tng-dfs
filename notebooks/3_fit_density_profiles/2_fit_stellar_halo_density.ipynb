{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "#\n",
    "# TITLE - 2_fit_stellar_halo_density.ipynb\n",
    "# AUTHOR - James Lane\n",
    "# PROJECT - ges-mass\n",
    "#\n",
    "# ------------------------------------------------------------------------\n",
    "#\n",
    "# Docstrings and metadata:\n",
    "'''Fit density profiles to remnants in stellar halos at z=0\n",
    "'''\n",
    "\n",
    "__author__ = \"James Lane\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "\n",
    "## Basic\n",
    "import numpy as np\n",
    "import sys, os, pdb, copy, time, dill as pickle, logging\n",
    "\n",
    "## Matplotlib\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "## Astropy\n",
    "from astropy import units as apu\n",
    "\n",
    "## Fitting\n",
    "import emcee\n",
    "import corner\n",
    "import multiprocessing\n",
    "import scipy.optimize\n",
    "\n",
    "## Project-specific\n",
    "sys.path.insert(0,'../../src/')\n",
    "from tng_dfs import fitting as pfit\n",
    "from tng_dfs import densprofile as pdens\n",
    "from tng_dfs import util as putil\n",
    "from tng_dfs import cutout as pcutout\n",
    "\n",
    "### Notebook setup\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('../../src/mpl/project.mplstyle') # This must be exactly here\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../src/nb_modules/nb_setup.txt\n",
    "# Keywords\n",
    "cdict = putil.load_config_to_dict()\n",
    "keywords = ['DATA_DIR','MW_ANALOG_DIR','RO','VO','ZO','LITTLE_H',\n",
    "            'MW_MASS_RANGE']\n",
    "data_dir,mw_analog_dir,ro,vo,zo,h,mw_mass_range = \\\n",
    "    putil.parse_config_dict(cdict,keywords)\n",
    "\n",
    "# MW Analog \n",
    "mwsubs,mwsubs_vars = putil.prepare_mwsubs(mw_analog_dir,h=h,\n",
    "    mw_mass_range=mw_mass_range,return_vars=True,force_mwsubs=False,\n",
    "    bulge_disk_fraction_cuts=True)\n",
    "\n",
    "# Figure path\n",
    "fig_dir = './fig/stellar_halo'\n",
    "epsen_fig_dir = '/epsen_data/scr/lane/projects/tng-dfs/figs/notebooks/'+\\\n",
    "    '3_fit_density_profiles/3_fit_stellar_halo_density/'\n",
    "epsen_fitting_dir = '/epsen_data/scr/lane/projects/tng-dfs/fitting/'+\\\n",
    "    'density_profile/stellar_halo/'\n",
    "os.makedirs(fig_dir,exist_ok=True)\n",
    "os.makedirs(epsen_fig_dir,exist_ok=True)\n",
    "os.makedirs(epsen_fitting_dir,exist_ok=True)\n",
    "show_plots = False\n",
    "\n",
    "# Load tree data\n",
    "tree_primary_filename = os.path.join(mw_analog_dir,\n",
    "    'major_mergers/tree_primaries.pkl')\n",
    "with open(tree_primary_filename,'rb') as handle: \n",
    "    tree_primaries = pickle.load(handle)\n",
    "tree_major_mergers_filename = os.path.join(mw_analog_dir,\n",
    "    'major_mergers/tree_major_mergers.pkl')\n",
    "with open(tree_major_mergers_filename,'rb') as handle:\n",
    "    tree_major_mergers = pickle.load(handle)\n",
    "n_mw = len(tree_primaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters, preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fit_density(r, masses, chain, rmin, rmax, densfunc):\n",
    "    nbin = 50\n",
    "    log_redges = np.linspace(np.log10(rmin), np.log10(rmax), nbin+1)\n",
    "    log_rcents = 0.5*(log_redges[1:] + log_redges[:-1])\n",
    "    redges = 10**log_redges\n",
    "    rcents = 10**log_rcents\n",
    "    dens = np.zeros(nbin)\n",
    "    for k in range(nbin):\n",
    "        vol = 4*np.pi/3 * (redges[k+1]**3 - redges[k]**3)\n",
    "        mask = (r >= redges[k]) & (r < redges[k+1])\n",
    "        dens[k] = np.sum(masses[mask]) / vol\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(np.log10(rcents), np.log10(dens), color='Grey', linewidth=4., zorder=2, \n",
    "        label='Data')\n",
    "    nrand = 100\n",
    "    inds = np.random.choice(np.arange(len(chain),dtype=int), size=nrand, \n",
    "        replace=False)\n",
    "    for k in range(nrand):\n",
    "        fdens = densfunc(rcents, 0., 0., chain[inds[k],:])\n",
    "        ax.plot(np.log10(rcents), np.log10(fdens), color='Red', linewidth=1., \n",
    "            zorder=3, linestyle='solid', alpha=5/nrand)\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def usr_log_prior_twopower(densfunc, params, rmin, rmax):\n",
    "    assert isinstance(densfunc, pdens.TwoPowerSpherical)\n",
    "    # Unpack params\n",
    "    alpha, beta, a, amp = densfunc._parse_params(params)\n",
    "\n",
    "    # Domain checks\n",
    "    # Check that a is not outside of the maximum radius\n",
    "    if a < rmin:\n",
    "        return -np.inf\n",
    "    if a > rmax:\n",
    "        return -np.inf\n",
    "    if beta <= 0:\n",
    "        return -np.inf\n",
    "    \n",
    "    # Priors\n",
    "    # Place a log-uniform prior on beta\n",
    "    beta_min = 0.001\n",
    "    beta_max = 1000.\n",
    "    prior_beta = scipy.stats.loguniform.pdf(beta, beta_min, beta_max)\n",
    "    # Place a log-uniform prior on a\n",
    "    a_min = 0.001\n",
    "    a_max = 1000.\n",
    "    prior_a = scipy.stats.loguniform.pdf(a, a_min, a_max)\n",
    "    if (prior_a == 0) or (prior_beta == 0):\n",
    "        return -np.inf\n",
    "    \n",
    "    # Return the prior\n",
    "    return np.log(prior_beta*prior_a)\n",
    "\n",
    "def generate_mcmc_init(init, nwalkers, densfunc, usr_log_prior, \n",
    "    usr_log_prior_params, scale=0.1):\n",
    "    '''generate_mcmc_init:\n",
    "\n",
    "    Generate a set of initial parameters for the MCMC chain that satisfies the \n",
    "    user-defined log prior function, as well as the domain and log prior \n",
    "    functions in src/tng_dfs/fitting.py\n",
    "\n",
    "    Args:\n",
    "        init (array): Initial parameters to sample around. Probably output of \n",
    "            scipy.optimize.minimize. Length of init is equal to the dimension\n",
    "            of the MCMC parameter space.\n",
    "        nwalkers (int): Number of walkers to use in the MCMC chain\n",
    "        usr_log_prior (function): User-defined log prior function\n",
    "        usr_log_prior_params (tuple): User-defined log prior function parameters\n",
    "\n",
    "    Returns:\n",
    "        mcmc_init\n",
    "    '''\n",
    "    # Starting point\n",
    "    mcmc_init = np.array([\n",
    "            init+scale*np.random.randn(len(init)) for i in range(nwalkers)\n",
    "            ])\n",
    "    # Check each point, and if needed resample\n",
    "    for i in range(nwalkers):\n",
    "        counter = 0\n",
    "        while not np.isfinite(usr_log_prior(densfunc, mcmc_init[i], \n",
    "                                            *usr_log_prior_params))\\\n",
    "            or not np.isfinite(pfit.logprior_dens(densfunc, mcmc_init[i]))\\\n",
    "            or (pfit.domain_prior_dens(densfunc, mcmc_init[i]) == False):\n",
    "            \n",
    "            mcmc_init[i] = init+scale*np.random.randn(len(init))\n",
    "            counter += 1\n",
    "            if counter > 100:\n",
    "                raise RuntimeError('Could not find a valid starting point '+\\\n",
    "                    'for walker '+str(i))\n",
    "    return mcmc_init\n",
    "\n",
    "densfunc = pdens.TwoPowerSpherical()\n",
    "verbose = True\n",
    "show_plots = False\n",
    "nwalkers = 50\n",
    "nit = 2000\n",
    "ncut = 500\n",
    "nprocs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "densfunc = pdens.TwoPowerSpherical()\n",
    "verbose = True\n",
    "show_plots = False\n",
    "nwalkers = 50\n",
    "nit = 2000\n",
    "ncut = 500\n",
    "nprocs = 12\n",
    "force_fit = False\n",
    "version_prefix = 'poisson_twopower_softening'\n",
    "\n",
    "# Begin logging\n",
    "log_filename = './log/2_fit_stellar_halo_density.log'\n",
    "if os.path.exists(log_filename):\n",
    "    os.remove(log_filename)\n",
    "logging.basicConfig(filename=log_filename, level=logging.INFO, filemode='w', \n",
    "    force=True)\n",
    "logging.info('Beginning density profile fitting for stellar halos. Time: '+\\\n",
    "             time.strftime('%a, %d %b %Y %H:%M:%S',time.localtime()))\n",
    "\n",
    "for i in range(n_mw):\n",
    "    # if i > 5: continue\n",
    "\n",
    "    # Get the primary\n",
    "    primary = tree_primaries[i]\n",
    "    z0_sid = primary.subfind_id[0]\n",
    "    # n_snap = len(primary.snapnum)\n",
    "    n_major = primary.n_major_mergers\n",
    "    primary_filename = primary.get_cutout_filename(mw_analog_dir,\n",
    "        snapnum=primary.snapnum[0])\n",
    "    co = pcutout.TNGCutout(primary_filename)\n",
    "    co.center_and_rectify()\n",
    "\n",
    "    # Get the tree major merger object\n",
    "    major_mergers = primary.tree_major_mergers\n",
    "    n_major = primary.n_major_mergers\n",
    "    # _unique_particle_ids = []\n",
    "\n",
    "    for j in range(n_major):\n",
    "        # if j != 0: continue\n",
    "\n",
    "        if verbose: \n",
    "            msg = f'Fitting merger {j+1}/{n_major}, of analog {i+1}/{n_mw}'\n",
    "            logging.info(msg)\n",
    "            print(msg)\n",
    "\n",
    "        # Fitting dir, check if already exists\n",
    "        this_fitting_dir = os.path.join(epsen_fitting_dir,version_prefix,\n",
    "            str(z0_sid),'merger_'+str(j+1))\n",
    "        os.makedirs(this_fitting_dir,exist_ok=True)\n",
    "        sampler_filename = os.path.join(this_fitting_dir,'sampler.pkl')\n",
    "        if os.path.exists(sampler_filename) and not force_fit:\n",
    "            if verbose:\n",
    "                msg = f'Fitting already exists for {z0_sid}, merger {j+1}'\n",
    "                logging.info(msg)\n",
    "                print(msg)\n",
    "            continue \n",
    "\n",
    "        # Get the major merger\n",
    "        major_merger = primary.tree_major_mergers[j]\n",
    "        upid = major_merger.get_unique_particle_ids('stars',data_dir=data_dir)\n",
    "        pid = co.get_property('stars','ParticleIDs')\n",
    "        indx = np.where(np.isin(pid,upid))[0]\n",
    "        orbs = co.get_orbs('stars')[indx]\n",
    "        masses = co.get_masses('stars')[indx].value\n",
    "\n",
    "        # Properties for fitting\n",
    "        r, R, phi, z = orbs.r().value, orbs.R().value, orbs.phi().value, orbs.z().value\n",
    "        rmin = np.max([putil.get_softening_length('stars', z=0, physical=True),\n",
    "                       np.min(r)])\n",
    "        rmax = np.max(r)\n",
    "        effvol_params = [rmin, rmax]\n",
    "        usr_log_prior_params = [rmin, rmax]\n",
    "\n",
    "        # # Pare down the data for fitting\n",
    "        # if len(masses) > 1e5:\n",
    "        #     npts = 1e5\n",
    "        #     inds = np.random.choice(np.arange(len(masses),dtype=int), \n",
    "        #         size=int(npts), replace=False)\n",
    "        #     fac = len(masses)/npts\n",
    "        #     r = r[inds]\n",
    "        #     R = R[inds]\n",
    "        #     phi = phi[inds]\n",
    "        #     z = z[inds]\n",
    "        #     masses = masses[inds]\n",
    "        #     masses *= fac # Increase the mass to compensate for the decrease in points\n",
    "\n",
    "        # Remove data outside the fitting range, null for now\n",
    "        mask = (r >= rmin) & (r <= rmax)\n",
    "        r_fit, R_fit, phi_fit, z_fit = r[mask], R[mask], phi[mask], z[mask]\n",
    "        masses_fit = masses[mask]\n",
    "\n",
    "        # Get the initial conditions\n",
    "        _alpha = 1.\n",
    "        _beta = 4.\n",
    "        _a = np.min([10., np.max(r_fit)])\n",
    "        _amp = np.sum(masses)/densfunc.mass(1e8, [_alpha, _beta, _a, 1.])\n",
    "        init = np.array([_alpha, _beta, _a, _amp])\n",
    "\n",
    "        # Do an optimization to get the initial conditions\n",
    "        if verbose:\n",
    "            msg = 'Running optimization'\n",
    "            logging.info(msg)\n",
    "            print(msg)\n",
    "        opt_fn = lambda params: pfit.mloglike_dens(params, densfunc,\n",
    "            R_fit, phi_fit, z_fit, mass=masses_fit, \n",
    "            usr_log_prior=usr_log_prior_twopower, \n",
    "            usr_log_prior_params=usr_log_prior_params,\n",
    "            effvol_params=effvol_params)\n",
    "        opt = scipy.optimize.minimize(opt_fn, init, method='Nelder-Mead',\n",
    "            options={'maxiter':2000,})\n",
    "        \n",
    "        # Run the MCMC\n",
    "        if verbose:\n",
    "            msg = 'Running MCMC'\n",
    "            logging.info(msg)\n",
    "            print(msg)\n",
    "        def llfunc(params):\n",
    "            return pfit.loglike_dens(params, densfunc, R_fit, phi_fit, z_fit,\n",
    "                mass=masses_fit, effvol_params=effvol_params, \n",
    "                usr_log_prior=usr_log_prior_twopower, \n",
    "                usr_log_prior_params=usr_log_prior_params)\n",
    "        # mcmc_init = np.array([\n",
    "        #     opt.x+0.1*np.random.randn(len(opt.x)) for i in range(nwalkers)\n",
    "        #     ])\n",
    "        mcmc_init = generate_mcmc_init(opt.x, nwalkers, densfunc, \n",
    "            usr_log_prior_twopower, usr_log_prior_params)\n",
    "        with multiprocessing.Pool(processes=nprocs) as pool:\n",
    "            sampler = emcee.EnsembleSampler(nwalkers, len(mcmc_init[0]), llfunc,\n",
    "                pool=pool)\n",
    "            sampler.run_mcmc(mcmc_init, nit, progress=True)\n",
    "        _chain = sampler.get_chain(flat=True, discard=ncut)\n",
    "        chain = copy.deepcopy(_chain)\n",
    "        chain[:,3] = np.log10(chain[:,3])\n",
    "\n",
    "        # Compute masses for the whole chain\n",
    "        ms = np.zeros(len(chain))\n",
    "        for k in range(len(chain)):\n",
    "            ms[k] = densfunc.effective_volume(_chain[k,:], *effvol_params)\n",
    "        chain = np.append(chain, np.log10(ms[:,None]), axis=1)\n",
    "        mtot = np.sum(masses)\n",
    "\n",
    "        # Plotting\n",
    "        this_fig_dir = os.path.join(epsen_fig_dir,version_prefix,str(z0_sid),\n",
    "            'merger_'+str(j+1))\n",
    "        os.makedirs(this_fig_dir, exist_ok=True)\n",
    "\n",
    "        # Density profile\n",
    "        fig, axs = plot_fit_density(r, masses, _chain, rmin, rmax, densfunc)\n",
    "        axs.axvline(np.log10(rmin), color='Grey', linestyle='dashed')\n",
    "        figname = os.path.join(this_fig_dir,\n",
    "            str(z0_sid)+'_merger_'+str(j+1)+'_two_power_fit_dens.png')\n",
    "        fig.savefig(figname,dpi=300)\n",
    "        plt.close(fig)\n",
    "\n",
    "        # Corner plot\n",
    "        fig = corner.corner(chain, \n",
    "        labels=[r'$\\alpha$', r'$\\beta$', r'$a$ [kpc]',\n",
    "            r'$\\log_{10}(\\mathrm{amp}/\\mathrm{M}_\\odot\\,\\mathrm{kpc}^{-3}))$',\n",
    "            r'$\\log_{10}(M$ [$\\mathrm{M}_\\odot)$]'],\n",
    "        truths=[None, None, None, None, np.log10(mtot)]\n",
    "        )\n",
    "        figname = os.path.join(this_fig_dir,\n",
    "            str(z0_sid)+'_merger_'+str(j+1)+'_two_power_fit_corner.png')\n",
    "        print(figname)\n",
    "        fig.savefig(figname, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "        # Save the results\n",
    "        opt_filename = os.path.join(this_fitting_dir,'opt.pkl')\n",
    "        with open(opt_filename,'wb') as handle:\n",
    "            pickle.dump(opt,handle)\n",
    "        sampler_filename = os.path.join(this_fitting_dir,'sampler.pkl')\n",
    "        with open(sampler_filename,'wb') as handle:\n",
    "            pickle.dump(sampler,handle)\n",
    "        chain_filename = os.path.join(this_fitting_dir,'chain.pkl')\n",
    "        with open(chain_filename,'wb') as handle:\n",
    "            pickle.dump([chain,['a','log10(amp)','mvir']],handle)\n",
    "\n",
    "        if verbose:\n",
    "            msg = 'Done with this merger'\n",
    "            logging.info(msg)\n",
    "            print(msg)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "nteract": {
   "version": "0.28.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
