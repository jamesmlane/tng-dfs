{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "#\n",
    "# TITLE - fit_ossipkov_merrit_df.ipynb\n",
    "# AUTHOR - James Lane\n",
    "# PROJECT - sample_project\n",
    "#\n",
    "# ------------------------------------------------------------------------\n",
    "#\n",
    "# Docstrings and metadata:\n",
    "'''Try and do some fits with Ossipkov-Merrit distribution functions.\n",
    "'''\n",
    "\n",
    "__author__ = \"James Lane\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "\n",
    "## Basic\n",
    "import numpy as np\n",
    "import sys, os, pdb, copy, glob, subprocess, warnings, dill as pickle\n",
    "\n",
    "## Matplotlib\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "## Astropy\n",
    "from astropy import units as apu\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "## Scipy\n",
    "import scipy.optimize\n",
    "\n",
    "## galpy\n",
    "# from galpy import orbit\n",
    "# from galpy import potential\n",
    "# from galpy import actionAngle as aA\n",
    "# from galpy import df\n",
    "\n",
    "## Project-specific\n",
    "sys.path.insert(0,'../../src/')\n",
    "import tng_dfs.util as putil\n",
    "import tng_dfs.kinematics as pkin\n",
    "import tng_dfs.cutout as pcutout\n",
    "import tng_dfs.tree as ptree\n",
    "\n",
    "### Notebook setup\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('../../src/mpl/project.mplstyle') # This must be exactly here\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keywords\n",
    "cdict = putil.load_config_to_dict()\n",
    "keywords = ['DATA_DIR','MW_ANALOG_DIR','RO','VO','ZO','LITTLE_H','MW_MASS_RANGE']\n",
    "data_dir,mw_analog_dir,ro,vo,zo,h,mw_mass_range = putil.parse_config_dict(cdict,keywords)\n",
    "\n",
    "fig_dir = './fig/fit_ossipkov_merrit_dfs/'\n",
    "os.makedirs(fig_dir,exist_ok=True)\n",
    "show_plots = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some plots of Ossipkov-Merrit DF anisotropy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard anisotropy as a function of radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "rs = np.logspace(-2,2,num=1001)\n",
    "ra = np.logspace(-1,1,num=10)\n",
    "\n",
    "for i in range(len(ra)):\n",
    "    beta = pkin.beta_ossipkov_merrit(rs,ra=ra[i])\n",
    "    ax.plot(rs, beta, color='Black')\n",
    "    ax.axvline(ra[i], color='Black', linestyle='dashed')\n",
    "\n",
    "# cbar = plt.colorbar()\n",
    "ax.set_xlabel('r [kpc]')\n",
    "ax.set_ylabel('beta')\n",
    "ax.set_xscale('log')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flexible anisotropy as a function of radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "rs = np.logspace(-2,2,num=1001)\n",
    "ra = 1\n",
    "alpha = np.linspace(-0.5,0.5,num=10)\n",
    "\n",
    "for i in range(len(alpha)):\n",
    "    beta = pkin.beta_any_alpha_cuddeford91(rs,ra=ra,alpha=alpha[i])\n",
    "    ax.plot(rs, beta, color='Black')\n",
    "    ax.axhline(alpha[i], color='Black', linestyle='dashed')\n",
    "\n",
    "ax.set_xlabel('r [kpc]')\n",
    "ax.set_ylabel('beta')\n",
    "ax.set_xscale('log')\n",
    "ax.axvline(ra, color='Black', linestyle='dotted')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load some data and try and do some fits at $z=0$\n",
    "\n",
    "What likelihood to use? Perhaps just use weighted least squares on the binned \n",
    "data to begin with\n",
    "\n",
    "\n",
    "Then compute the reduced chi square statistic on the binned data.\n",
    "\n",
    "$\\Chi^{2}_{\\nu} = \\Chi^{2}/\\nu$\n",
    "\n",
    "$\\nu = m - n$\n",
    "\n",
    "\n",
    "$n$ is the number of observations, $m$ is the number of fitted parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../parse_sublink_trees/data/tree_primaries.pkl','rb') as handle:\n",
    "    tree_primaries = pickle.load(handle)\n",
    "\n",
    "with open('../parse_sublink_trees/data/tree_major_mergers.pkl','rb') as handle:\n",
    "    tree_major_mergers = pickle.load(handle)\n",
    "\n",
    "# Number of primary MW analogs under consideration\n",
    "n_mw = len(tree_primaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all particle IDs that belong with each major merger progenitor\n",
    "unique_particle_ids = []\n",
    "\n",
    "for i in range(n_mw): # Loop over MW analogs\n",
    "    # if i > n_do: continue\n",
    "    \n",
    "    major_dict = all_major_list[i]\n",
    "    major_list = major_dict['major_list']\n",
    "    n_major = major_dict['n_major']\n",
    "    \n",
    "    # Hold star particle IDs for this MW analog\n",
    "    analog_unique_particle_ids = []\n",
    "    \n",
    "    for j in range(n_major+1): # Loop over majors + primary (index 0)\n",
    "        if j == 0:\n",
    "            assert major_list[j]['is_primary'], 'Index 0 not primary'\n",
    "            continue\n",
    "        ###j\n",
    "        major_snaps = major_list[j]['snaps']\n",
    "        major_subfind_ids = major_list[j]['subfind_ids']\n",
    "        major_nsnaps = len(major_snaps)\n",
    "        \n",
    "        # Hold star particle IDs for this major merger progenitor\n",
    "        major_unique_particle_ids = np.array([],dtype=int) \n",
    "        \n",
    "        for k in range(major_nsnaps):\n",
    "            \n",
    "            snap_filename = data_dir+'cutouts/snap_'+str(major_snaps[k])+\\\n",
    "                '/cutout_'+str(int(major_subfind_ids[k]))+'.hdf5'\n",
    "            f = h5py.File(snap_filename,'r')\n",
    "            try:\n",
    "                major_unique_particle_ids = np.unique(np.concatenate((\n",
    "                    major_unique_particle_ids,\n",
    "                    np.array(f['PartType4']['ParticleIDs'],dtype=int))))\n",
    "            except KeyError:\n",
    "                pass\n",
    "            f.close()\n",
    "            \n",
    "        analog_unique_particle_ids.append(np.sort(major_unique_particle_ids))\n",
    "    unique_particle_ids.append(analog_unique_particle_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_merger.secondary_mlpid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make plots of the path of the major mergers compared with the primary, \n",
    "# checks for consistency.\n",
    "verbose = True\n",
    "this_fig_dir = fig_dir+'major_merger_fits/'\n",
    "os.makedirs(this_fig_dir,exist_ok=True)\n",
    "this_data_dir = './data/betas/'\n",
    "os.makedirs(this_data_dir,exist_ok=True)\n",
    "r_range = [0,50]\n",
    "n_bin = 7\n",
    "n_bs = 25\n",
    "show_plots = True\n",
    "\n",
    "unique_particle_ids = []\n",
    "\n",
    "for i in range(n_mw):\n",
    "    # if i > 0: continue\n",
    "    if verbose: print(f'Plotting MW {i+1}/{n_mw}')\n",
    "\n",
    "    # Get the primary\n",
    "    primary = tree_primaries[i]\n",
    "    z0_sid = primary.subfind_id[0]\n",
    "    n_snap = len(primary.snapnum)\n",
    "    n_major = primary.n_major_mergers\n",
    "\n",
    "    co = pcutout.TNGCutout(\n",
    "        primary.get_cutout_filename(mw_analog_dir,snapnum=primary.snapnum[0]))\n",
    "    co.center_and_rectify()\n",
    "    pid = co.get_property('stars','ParticleIDs')\n",
    "\n",
    "    # Loop over the major mergers, collect unique particle IDs for plotting\n",
    "    _unique_particle_ids = []\n",
    "    for j in range(n_major):\n",
    "        if verbose: print(f'Plotting merger {j+1}/{n_major}')\n",
    "\n",
    "        # Get the major merger\n",
    "        #print(primary.tree_major_mergers[j])\n",
    "        major_merger = primary.tree_major_mergers[j]\n",
    "        _unique_particle_ids.append(\n",
    "            major_merger.get_unique_particle_ids('stars',data_dir=data_dir)\n",
    "            )\n",
    "\n",
    "        # # Get the indices of the unique particles in the z=0 snapshot\n",
    "        pid = co.get_property('stars','ParticleIDs')\n",
    "        indx = np.where(np.isin(pid,_unique_particle_ids[j]))[0]\n",
    "        orbs = co.get_orbs('stars')[indx]\n",
    "        pe = co.get_potential_energy('stars')[indx]\n",
    "\n",
    "        Js,rs,qs = pkin.calculate_spherical_jeans(orbs,pot=None,pe=pe,\n",
    "            n_bootstrap=n_bs,r_range=r_range,n_bin=n_bin)\n",
    "        beta = 1-(qs[4]+qs[5])/(2*qs[3])\n",
    "        rs = rs[0]\n",
    "        lbeta,mbeta,ubeta = np.percentile(beta,[16,50,84],axis=0)\n",
    "        sbeta = (ubeta-lbeta)/2\n",
    "        \n",
    "        filename = this_data_dir+str(major_merger.secondary_mlpid)+'.pkl'\n",
    "        with open(filename,'wb') as handle:\n",
    "            pickle.dump([rs,mbeta,sbeta,lbeta,ubeta],handle)\n",
    "\n",
    "        # # Make the figure\n",
    "        # fig = plt.figure()\n",
    "        # ax = fig.add_subplot(111)\n",
    "        # ax.plot(rs, mbeta, color='Black')\n",
    "        # ax.fill_between(rs, mbeta-sbeta, mbeta+sbeta, color='Black', alpha=0.5)\n",
    "\n",
    "        # # Do the fit\n",
    "        # try:\n",
    "        #     popt,pcov = scipy.optimize.curve_fit(pkin.beta_any_alpha_cuddeford91,\n",
    "        #         rs, mbeta, sigma=sbeta, absolute_sigma=True, p0=[1,0], \n",
    "        #         maxfev=1000)\n",
    "        #     ra,alpha = popt\n",
    "        #     ra_err,alpha_err = np.sqrt(np.diag(pcov))\n",
    "        #     tbeta = pkin.beta_any_alpha_cuddeford91(rs,ra,alpha)\n",
    "        #     ax.plot(rs, tbeta, color='Red', linestyle='dashed')\n",
    "        # except RuntimeError:\n",
    "        #     # Plot text saying fit did not converge\n",
    "        #     ax.text(0.5,0.5,'Fit did not converge',transform=ax.transAxes,\n",
    "        #         horizontalalignment='center',verticalalignment='center')\n",
    "\n",
    "        # # fig.savefig(this_fig_dir+str(z0_sid)+'_'+str(j)+'.png',dpi=300)\n",
    "        # if not show_plots: plt.close(fig)\n",
    "\n",
    "    unique_particle_ids.append(_unique_particle_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make plots of the path of the major mergers compared with the primary, \n",
    "# checks for consistency.\n",
    "verbose = True\n",
    "this_fig_dir = fig_dir+'major_merger_fits/'\n",
    "os.makedirs(this_fig_dir,exist_ok=True)\n",
    "this_data_dir = './data/halo/betas/'\n",
    "os.makedirs(this_data_dir,exist_ok=True)\n",
    "r_range = [0,50]\n",
    "n_bin = 7\n",
    "n_bs = 25\n",
    "show_plots = True\n",
    "\n",
    "unique_particle_ids = []\n",
    "\n",
    "for i in range(n_mw):\n",
    "    if i > 10: continue\n",
    "    if verbose: print(f'Plotting MW {i+1}/{n_mw}')\n",
    "\n",
    "    # Get the primary\n",
    "    primary = tree_primaries[i]\n",
    "    z0_sid = primary.subfind_id[0]\n",
    "    n_snap = len(primary.snapnum)\n",
    "    n_major = primary.n_major_mergers\n",
    "    primary_filename = primary.get_cutout_filename(mw_analog_dir,\n",
    "        snapnum=primary.snapnum[0])\n",
    "    co = pcutout.TNGCutout(primary_filename)\n",
    "    co.center_and_rectify()\n",
    "    \n",
    "    # Get properties, energy, angular momentum\n",
    "    orbs = co.get_orbs('PartType4')\n",
    "    rs = orbs.r().value\n",
    "    vels = co.get_velocities('PartType4', physical=True)\n",
    "    pot = co.get_potential_energy('PartType4', physical=True)\n",
    "    kin = 0.5*np.sum(np.square(vels),axis=1)\n",
    "    E = (pot+kin)\n",
    "    J,Jz,Jp = co.get_J_Jz_Jp('PartType4',physical=True)\n",
    "    co.get_E_Jcirc_spline('PartType4',angmom='J')\n",
    "    Jcirc = co.Jcirc(E)\n",
    "    Enorm = E/np.abs(E).max()\n",
    "    Jz_Jcirc = Jz / Jcirc\n",
    "    Jp_Jcirc = Jp / Jcirc\n",
    "    \n",
    "    # Mask the halo using these quantities\n",
    "    Jz_Jcirc_halo_bound = 0.5\n",
    "    Enorm_bulge_bound = -0.75\n",
    "    halo_mask = (Jz_Jcirc < Jz_Jcirc_halo_bound) &\\\n",
    "                (Enorm > Enorm_bulge_bound)\n",
    "    \n",
    "    orbs = orbs[halo_mask]\n",
    "    pe = pot[halo_mask]\n",
    "\n",
    "    Js,rs,qs = pkin.calculate_spherical_jeans(orbs,pot=None,pe=pe,\n",
    "        n_bootstrap=n_bs,r_range=r_range,n_bin=n_bin)\n",
    "    beta = 1-(qs[4]+qs[5])/(2*qs[3])\n",
    "    rs = rs[0]\n",
    "    lbeta,mbeta,ubeta = np.percentile(beta,[16,50,84],axis=0)\n",
    "    sbeta = (ubeta-lbeta)/2\n",
    "    \n",
    "    filename = this_data_dir+str(z0_sid)+'.pkl'\n",
    "    with open(filename,'wb') as handle:\n",
    "        pickle.dump([rs,mbeta,sbeta,lbeta,ubeta],handle)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "james",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "nteract": {
   "version": "0.28.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "39281e2d1d208f5d5f10b92e49c40383b657448f443f22dc78686b7e0f8179a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
